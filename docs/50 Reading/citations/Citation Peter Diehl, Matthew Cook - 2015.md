---
Topics: 
aliases: [@diehlUnsupervisedLearningDigit2015,]
type:  citation
citetype: 
title: Unsupervised learning of digit recognition using spike-timing-dependent plasticity
author2: [object Object]
authors: [Peter Diehl, Matthew Cook]
year: 2015
URL: "https://www.frontiersin.org/article/10.3389/fncom.2015.00099"
citekey: diehlUnsupervisedLearningDigit2015
infotags: []

---

[[@diehlUnsupervisedLearningDigit2015]]

[Zotero Link](zotero://select/items/@diehlUnsupervisedLearningDigit2015)
PDF: 
Files: 

# Unsupervised learning of digit recognition using spike-timing-dependent plasticity
# Abstract
In order to understand how the mammalian neocortex is performing computations, two things are necessary; we need to have a good understanding of the available neuronal processing units and mechanisms, and we need to gain a better understanding of how those mechanisms are combined to build functioning systems. Therefore, in recent years there is an increasing interest in how spiking neural networks (SNN) can be used to perform complex computations or solve pattern recognition tasks. However, it remains a challenging task to design SNNs which use biologically plausible mechanisms (especially for learning new patterns), since most such SNN architectures rely on training in a rate-based network and subsequent conversion to a SNN. We present a SNN for digit recognition which is based on mechanisms with increased biological plausibility, i.e., conductance-based instead of current-based synapses, spike-timing-dependent plasticity with time-dependent weight change, lateral inhibition, and an adaptive spiking threshold. Unlike most other systems, we do not use a teaching signal and do not present any class labels to the network. Using this unsupervised learning scheme, our architecture achieves 95% accuracy on the MNIST benchmark, which is better than previous SNN implementations without supervision. The fact that we used no domain-specific knowledge points toward the general applicability of our network design. Also, the performance of our network scales well with the number of neurons used and shows similar performance for four different learning rules, indicating robustness of the full combination of mechanisms, which suggests applicability in heterogeneous biological neural networks.



---
type: glossary
status: open
priority: p4
creationtag: 2023-04-11 11:15
infotags:
citekey: petterIntegratingModelsInterval2018
---

#  Pavlovian Conditioning Protocol
![[1-s2.0-S1364661318301931-gr1.jpg]]
> **Figure 1.** Predicting Reward with Temporal Representations. 
> 
> (A) Learning to anticipate a reward that follows a predictive cue can be accomplished by using a set of ‘microstimulus’ representations (temporal basis functions; see [24](https://www.sciencedirect.com/science/article/pii/S1364661318301931?via%3Dihub#bib0120), [25](https://www.sciencedirect.com/science/article/pii/S1364661318301931?via%3Dihub#bib0125)). 
> 
> (B) These basis functions are activated by salient events (e.g., a tone signaling trial start), and peak at a characteristic delay from event onset. They have the benefit of naturally allowing for generalization of value across time. 
> 
> Specifically, the overlapping nature of the basis functions allows partial credit when rewards are received at times of less than maximal activation. Here the width of each basis function scales in proportion to its preferred duration, thus increasing the amount of generalization with longer durations. ISI, interstimulus interval; ITI, intertrial interval.

## Conditioned Stimulus (CS)
Consider, for example, a simple Pavlovian conditioning protocol in which a **conditioned stimulus (CS**; e.g., tone) is followed by a fixed **interstimulus interval (ISI**) that terminates with the delivery of an **unconditioned stimulus (US**; e.g., food). The US is then followed by a fixed **intertrial interval (ITI**).

## Interstimulus Interval (ISI)

## unconditioned stimulus (US)

## intertrial interval (ITI)


# Reward prediction error (RPE)
the discrepancy between received and expected reward. This error is often attributed to the firing patterns of midbrain dopamine neurons (e.g., [89]). Recent findings, however, have challenged this long-held view by attributing the role of striatal dopamine to movement kinematics (e.g., head velocity) in unrestrained subjects performing in behavioral tasks involving the delivery of reward [90].

See the relation to Temporal Difference Learning in RL
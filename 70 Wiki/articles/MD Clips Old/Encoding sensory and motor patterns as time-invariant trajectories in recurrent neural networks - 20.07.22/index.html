
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../Design%20of%20deep%20echo%20state%20networks%20-%2009.05.22/">
      
      
        <link rel="next" href="../Ensemble%20Coding%20of%20Vocal%20Control%20in%20Birdsong%20-%2021.06.22/">
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.1.6">
    
    
      
        <title>Encoding sensory and motor patterns as time invariant trajectories in recurrent neural networks 20.07.22 - obsidian-mkdocs template</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.ded33207.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.a0c5b2b5.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="pink" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#abstract" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="obsidian-mkdocs template" class="md-header__button md-logo" aria-label="obsidian-mkdocs template" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            obsidian-mkdocs template
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Encoding sensory and motor patterns as time invariant trajectories in recurrent neural networks   20.07.22
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="pink" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
            </label>
          
        
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="pink" data-md-color-accent="blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="obsidian-mkdocs template" class="md-nav__button md-logo" aria-label="obsidian-mkdocs template" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    obsidian-mkdocs template
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          10 Projects
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          10 Projects
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/10%20Projects/" class="md-nav__link">
        10 Projects
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Active%20Projects%20Overview/" class="md-nav__link">
        Active Projects Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/All%20Projects%20Overview/" class="md-nav__link">
        All Projects Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Open%20Projects%20Overview/" class="md-nav__link">
        Open Projects Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Projects%20Overview%20Template/" class="md-nav__link">
        Projects Overview Template
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Projects%20Table/" class="md-nav__link">
        Projects Table
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7" id="__nav_2_7_label" tabindex="0">
          1 Main Research
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7">
          <span class="md-nav__icon md-icon"></span>
          1 Main Research
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_1" id="__nav_2_7_1_label" tabindex="0">
          Global Trigger Local Back Propagation
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_7_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_1">
          <span class="md-nav__icon md-icon"></span>
          Global Trigger Local Back Propagation
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Global%20Trigger%20Local%20Back-Propagation/Global%20Trigger%20Local%20Back-Propagation/" class="md-nav__link">
        Global Trigger Local Back Propagation
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_2" id="__nav_2_7_2_label" tabindex="0">
          Make the fucking timing figure
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_7_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_2">
          <span class="md-nav__icon md-icon"></span>
          Make the fucking timing figure
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Make%20the%20fucking%20timing%20figure/Figure%20Descriptions/" class="md-nav__link">
        Figure Descriptions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Make%20the%20fucking%20timing%20figure/Make%20the%20fucking%20timing%20figure/" class="md-nav__link">
        Make the fucking timing figure
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_3" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_3" id="__nav_2_7_3_label" tabindex="0">
          PhD Proposal
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_7_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_3">
          <span class="md-nav__icon md-icon"></span>
          PhD Proposal
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/Nicolai%27s%20Comments%20on%20Draft%205/" class="md-nav__link">
        Nicolai's Comments on Draft 5
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20Proposal%20tasks/" class="md-nav__link">
        PhD Proposal tasks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20Proposal/" class="md-nav__link">
        PhD Proposal
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Outline/" class="md-nav__link">
        PhD proposal Outline
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_3_5" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_3_5" id="__nav_2_7_3_5_label" tabindex="0">
          PhD proposal Drafts
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_7_3_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_3_5">
          <span class="md-nav__icon md-icon"></span>
          PhD proposal Drafts
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20%20Draft%208%20Research%20Plan/" class="md-nav__link">
        PhD Proposal  Draft 8 Research Plan
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%201/" class="md-nav__link">
        1 Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%202%20-%20cut%20and%20paste%20palette/" class="md-nav__link">
        1 Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%202/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%204/" class="md-nav__link">
        PhD Proposal Draft 4
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%205%20CUT%20AND%20PASTE%20PALETTE/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%205.1/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%205/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%206.1/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%206/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%207%20latex%20conversion/" class="md-nav__link">
        PhD Proposal Draft 7 latex conversion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Draft%207/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20Mega%20Frakenstein%20Collage%20Draft%203/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20Proposal%20draft%202%20-%20outline/" class="md-nav__link">
        1 Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/PhD%20proposal%20Drafts/" class="md-nav__link">
        PhD proposal Drafts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/PhD%20Proposal/PhD%20proposal%20Drafts/Research%20Question%20Section%20Draft%202/" class="md-nav__link">
        Research Question Section Draft 2
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_4" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_4" id="__nav_2_7_4_label" tabindex="0">
          Recreating SBF Model
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_7_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_4">
          <span class="md-nav__icon md-icon"></span>
          Recreating SBF Model
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Recreating%20SBF%20Model/Abstract%20for%20SBFA%20-%2027.03.23/" class="md-nav__link">
        Abstract for SBFA   27.03.23
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Recreating%20SBF%20Model/Brief%20Overview%20of%20SBF%20Model/" class="md-nav__link">
        Brief Overview of SBF Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Recreating%20SBF%20Model/Outline%20of%20SBF%20Model%20for%20Supervision%20Meeting/" class="md-nav__link">
        Outline of SBF Model for Supervision Meeting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Recreating%20SBF%20Model/Outline%20of%20SBF%20Model/" class="md-nav__link">
        Outline of SBF Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Recreating%20SBF%20Model/Recreating%20SBF%20Model/" class="md-nav__link">
        Recreating SBF Model
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_5" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_5" id="__nav_2_7_5_label" tabindex="0">
          SBF   Automata Experiment
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_7_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_5">
          <span class="md-nav__icon md-icon"></span>
          SBF   Automata Experiment
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/Algorithm%20Outline/" class="md-nav__link">
        Algorithm Outline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/Experiment%20Environment%20Variants/" class="md-nav__link">
        Experiment Environment Variants
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/First%20python%20implementation%20-%20conditions%20and%20results/" class="md-nav__link">
        First python implementation   conditions and results
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/Pseudocode%20for%20Modular%20Arrangement/" class="md-nav__link">
        Pseudocode for Modular Arrangement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/Pseudocode%20for%20SBF%20Automata/" class="md-nav__link">
        Pseudocode for SBF Automata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/SBF%20-%20Automata%20-%20Design%201/" class="md-nav__link">
        The SBF Automata Design
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/SBF%20-%20Automata%20Algorithm%20Formalized/" class="md-nav__link">
        SBF   Automata Algorithm Formalized
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/SBF%20-%20Automata%20Experiment/" class="md-nav__link">
        SBF   Automata Experiment
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/SBFA%20-%20Normalized%20Automata%20Vote/" class="md-nav__link">
        SBFA   Normalized Automata Vote
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/SBFA%20Development%20Log/" class="md-nav__link">
        SBFA Development Log
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/SBFA%20Experiment%20Development/" class="md-nav__link">
        SBFA Experiment Development
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/SBFA%20Experiment%20Results%2010.02.23/" class="md-nav__link">
        SBFA Experiment Results 10.02.23
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/Weighted%20Majority%20Vote%20Version%2027.01.23/" class="md-nav__link">
        Weighted Majority Vote Version [[27.01.23]]
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_5_14" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_5_14" id="__nav_2_7_5_14_label" tabindex="0">
          Ooman Collab
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_7_5_14_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_5_14">
          <span class="md-nav__icon md-icon"></span>
          Ooman Collab
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SBF%20-%20Automata%20Experiment/Ooman%20Collab/Ooman%20Collab/" class="md-nav__link">
        Formerly the Automata Oscilllators Project
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_6" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_6" id="__nav_2_7_6_label" tabindex="0">
          SNN Models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_7_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_6">
          <span class="md-nav__icon md-icon"></span>
          SNN Models
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/SNN%20Models/SNN%20Models%20/" class="md-nav__link">
        Statement
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_7" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_7" id="__nav_2_7_7_label" tabindex="0">
          Survey Paper
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_7_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_7">
          <span class="md-nav__icon md-icon"></span>
          Survey Paper
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Survey%20Paper/Survey%20Paper%20Tasks/" class="md-nav__link">
        Tasks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Survey%20Paper/Survey%20Paper/" class="md-nav__link">
        Survey Paper
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_7_3" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_7_3" id="__nav_2_7_7_3_label" tabindex="0">
          How to Conduct Survey
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_7_7_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_7_3">
          <span class="md-nav__icon md-icon"></span>
          How to Conduct Survey
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Survey%20Paper/How%20to%20Conduct%20Survey/How%20to%20Conduct%20Survey%20/" class="md-nav__link">
        How to Conduct Survey 
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_8" >
      
      
      
        <label class="md-nav__link" for="__nav_2_7_8" id="__nav_2_7_8_label" tabindex="0">
          Timing Tasks
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_7_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_7_8">
          <span class="md-nav__icon md-icon"></span>
          Timing Tasks
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/1%20Main%20Research/Timing%20Tasks/Timing%20Tasks%20Research/" class="md-nav__link">
        Statement
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_8" >
      
      
      
        <label class="md-nav__link" for="__nav_2_8" id="__nav_2_8_label" tabindex="0">
          2 Alt. Research
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_8">
          <span class="md-nav__icon md-icon"></span>
          2 Alt. Research
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_8_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_8_1" id="__nav_2_8_1_label" tabindex="0">
          Stable Diffusion Project
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_8_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_8_1">
          <span class="md-nav__icon md-icon"></span>
          Stable Diffusion Project
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/2%20Alt.%20Research/Stable%20Diffusion%20Project/Stable%20Diffusion%20Project/" class="md-nav__link">
        Stable Diffusion Project
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_8_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_8_2" id="__nav_2_8_2_label" tabindex="0">
          Vicente Collab
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_8_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_8_2">
          <span class="md-nav__icon md-icon"></span>
          Vicente Collab
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/2%20Alt.%20Research/Vicente%20Collab/Vicente%20Collab/" class="md-nav__link">
        Vicente Collab
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_9" >
      
      
      
        <label class="md-nav__link" for="__nav_2_9" id="__nav_2_9_label" tabindex="0">
          3 PhD Administrative Stuff
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_9">
          <span class="md-nav__icon md-icon"></span>
          3 PhD Administrative Stuff
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/3%20PhD%20Administrative%20Stuff/Applying%20for%20trip%20expenses/" class="md-nav__link">
        How to apply for trip expenses
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/3%20PhD%20Administrative%20Stuff/PhD%20Administrative%20Stuff/" class="md-nav__link">
        [Resources for Ph.D. candidates at TKD](https://ansatt.oslomet.no/en/ressursside-for-phd-kandidater-ved-tkd1)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/3%20PhD%20Administrative%20Stuff/PhD%20Courses/" class="md-nav__link">
        PhD Courses
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/3%20PhD%20Administrative%20Stuff/welcome%20letter/" class="md-nav__link">
        ![[Velkomstbrev ph.d.-kandidater internt - engelsk 1.pdf]]
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10" >
      
      
      
        <label class="md-nav__link" for="__nav_2_10" id="__nav_2_10_label" tabindex="0">
          4 Conferences & Schools
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_10_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_10">
          <span class="md-nav__icon md-icon"></span>
          4 Conferences & Schools
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_10_1" id="__nav_2_10_1_label" tabindex="0">
          DeepLearn 2022
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_10_1">
          <span class="md-nav__icon md-icon"></span>
          DeepLearn 2022
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/DeepLearn%202022/DeepLearn%202022%20Travel/" class="md-nav__link">
        DeepLearn 2022 budget proposal
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/DeepLearn%202022/DeepLearn%202022/" class="md-nav__link">
        DeepLearn 2022
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/DeepLearn%202022/DeepLearn%20Lecture%20Selections/" class="md-nav__link">
        [[DeepLearn 2022]]
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/DeepLearn%202022/Sean%20Meyn%20-%20DeepLearn%202022%20summer%20-%2025.07.22/" class="md-nav__link">
        Sean Meyn   DeepLearn 2022 summer   25.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_1_5" >
      
      
      
        <label class="md-nav__link" for="__nav_2_10_1_5" id="__nav_2_10_1_5_label" tabindex="0">
          Schuller
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_10_1_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_10_1_5">
          <span class="md-nav__icon md-icon"></span>
          Schuller
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/DeepLearn%202022/schuller/Bjorn%20Schuller%20-%20DeepLearn%202022%20summer%20-%2025.07.22/" class="md-nav__link">
        Motivations
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_10_2" id="__nav_2_10_2_label" tabindex="0">
          MLSS^N 2022 Krakow
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_10_2">
          <span class="md-nav__icon md-icon"></span>
          MLSS^N 2022 Krakow
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/MLSSN%20Review/" class="md-nav__link">
        MLSSN Review
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/MLSS%5EN%202022%20Krakow/" class="md-nav__link">
        Dataview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Our%20Contribution%20to%20Continual%20Learning/" class="md-nav__link">
        PDF
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_2_4" >
      
      
      
        <label class="md-nav__link" for="__nav_2_10_2_4" id="__nav_2_10_2_4_label" tabindex="0">
          Talk Notes
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_10_2_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_10_2_4">
          <span class="md-nav__icon md-icon"></span>
          Talk Notes
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Andrea%20Tagliasacchi/" class="md-nav__link">
        Andrea Tagliasacchi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Andrew%20Saxe/" class="md-nav__link">
        Andrew Saxe
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Ewa%20Szczurek/" class="md-nav__link">
        Materials
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Friedemann%20Zenke%20MLSSN%20Lecture%20-%2030.06.22/" class="md-nav__link">
        Lecture Material
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Grabaska-Barwinska%20MLSSN%20Lecture%20-%2001.07.22/" class="md-nav__link">
        A rapid and efficient learning rule
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Jan%20Chorowski%20MLSSN%20%20-%2002.07.22/" class="md-nav__link">
        Jan Chorowski MLSSN    02.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Joao%20Henriques/" class="md-nav__link">
        Materials
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Joao%20Sacremento%20Lecture%20-%2029.06.22/" class="md-nav__link">
        Materials
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Piotr%20Milos%20Lecture%20MLSS%20-%2002.07.22/" class="md-nav__link">
        Piotr Milos Lecture MLSS   02.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Poster%20Session%20notes/" class="md-nav__link">
        Poster Session notes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Rafal%20Bogcaz/" class="md-nav__link">
        Materials
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Razvan%20Pascnau%20Lecture%20-%2027.06.22/" class="md-nav__link">
        None
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Rianne%20Van%20Den%20Berg%20Lecture/" class="md-nav__link">
        None
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Tomasz%20Trzcinski%20MLSS%20-%2002.07.22/" class="md-nav__link">
        Tomasz Trzcinski MLSS   02.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/4%20Conferences%20%26%20Schools/MLSS%5EN%202022%20Krakow/Talk%20Notes/Zieba%20MLSSN%20Lecture%20-%2001.07.22/" class="md-nav__link">
        Discrete normalizing flows
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_11" >
      
      
      
        <label class="md-nav__link" for="__nav_2_11" id="__nav_2_11_label" tabindex="0">
          5 Presentations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_11_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_11">
          <span class="md-nav__icon md-icon"></span>
          5 Presentations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/5%20Presentations/5%20Presentations/" class="md-nav__link">
        5 Presentations
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_11_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_11_2" id="__nav_2_11_2_label" tabindex="0">
          Present on SNN MAB
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_11_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_11_2">
          <span class="md-nav__icon md-icon"></span>
          Present on SNN MAB
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/5%20Presentations/Present%20on%20SNN%20MAB/Present%20on%20SNN%20MAB/" class="md-nav__link">
        Present on SNN MAB
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_11_3" >
      
      
      
        <label class="md-nav__link" for="__nav_2_11_3" id="__nav_2_11_3_label" tabindex="0">
          Presenting on Petter 2018
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_11_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_11_3">
          <span class="md-nav__icon md-icon"></span>
          Presenting on Petter 2018
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/5%20Presentations/Presenting%20on%20Petter%202018/Petter%202018%20Slides%20-%20Draft%201/" class="md-nav__link">
        Petter 2018 Slides   Draft 1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/5%20Presentations/Presenting%20on%20Petter%202018/Petter%202018%20Slides%20-%20Draft%202/" class="md-nav__link">
        Petter 2018 Slides   Draft 2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/5%20Presentations/Presenting%20on%20Petter%202018/Presenting%20on%20Petter%202018/" class="md-nav__link">
        Presenting on Petter 2018
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_11_4" >
      
      
      
        <label class="md-nav__link" for="__nav_2_11_4" id="__nav_2_11_4_label" tabindex="0">
          Presenting to Ooman
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_11_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_11_4">
          <span class="md-nav__icon md-icon"></span>
          Presenting to Ooman
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/5%20Presentations/Presenting%20to%20Ooman/Presenting%20to%20Oomman/" class="md-nav__link">
        RL, SNNs, and Representing time
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_11_5" >
      
      
      
        <label class="md-nav__link" for="__nav_2_11_5" id="__nav_2_11_5_label" tabindex="0">
          Templates
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_11_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_11_5">
          <span class="md-nav__icon md-icon"></span>
          Templates
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/5%20Presentations/templates/tpl/" class="md-nav__link">
        Tpl
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/5%20Presentations/templates/tpl2/" class="md-nav__link">
        Tpl2
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_12" >
      
      
      
        <label class="md-nav__link" for="__nav_2_12" id="__nav_2_12_label" tabindex="0">
          6 Teaching
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_12_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_12">
          <span class="md-nav__icon md-icon"></span>
          6 Teaching
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_12_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_12_1" id="__nav_2_12_1_label" tabindex="0">
          ACIT4420   Python Programming Course Autumn 2022
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_12_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_12_1">
          <span class="md-nav__icon md-icon"></span>
          ACIT4420   Python Programming Course Autumn 2022
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/6%20Teaching/ACIT4420%20-%20Python%20Programming%20Course%20Autumn%202022/ACIT4420%20-%20Python%20Programming%20Course%20Autumn%202022/" class="md-nav__link">
        ACIT4420 - Python Scripting
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_12_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_12_2" id="__nav_2_12_2_label" tabindex="0">
          ACIT4620   Comp. Intel Course Autmun 2022
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_12_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_12_2">
          <span class="md-nav__icon md-icon"></span>
          ACIT4620   Comp. Intel Course Autmun 2022
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/6%20Teaching/ACIT4620%20-%20Comp.%20Intel%20Course%20Autmun%202022/ACIT4620%20-%20Comp.%20Intel%20Course%20Autmun%202022/" class="md-nav__link">
        [[ACIT4620 Log]]
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/6%20Teaching/ACIT4620%20-%20Comp.%20Intel%20Course%20Autmun%202022/ACIT4620%20Log/" class="md-nav__link">
        [[04.10.22]]
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/6%20Teaching/ACIT4620%20-%20Comp.%20Intel%20Course%20Autmun%202022/Recommended%20Changes%20to%20Course/" class="md-nav__link">
        Statement
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_12_3" >
      
      
      
        <label class="md-nav__link" for="__nav_2_12_3" id="__nav_2_12_3_label" tabindex="0">
          DATA3900 Bachelors Thesis Supervision
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_12_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_12_3">
          <span class="md-nav__icon md-icon"></span>
          DATA3900 Bachelors Thesis Supervision
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/6%20Teaching/DATA3900%20Bachelors%20Thesis%20Supervision/DATA%203900%20Group%20-%20Microsoft%20Norge%20AS/" class="md-nav__link">
        DATA 3900 Group   Microsoft Norge AS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/6%20Teaching/DATA3900%20Bachelors%20Thesis%20Supervision/DATA3900%20Bachelors%20Thesis%20Supervision/" class="md-nav__link">
        DATA3900 Bachelors Thesis Supervision
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/6%20Teaching/DATA3900%20Bachelors%20Thesis%20Supervision/Group%20-%20Intility%20AS/" class="md-nav__link">
        Group   Intility AS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/6%20Teaching/DATA3900%20Bachelors%20Thesis%20Supervision/MSFT%20Bacheloroppgave/" class="md-nav__link">
        MSFT Bacheloroppgave
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_12_4" >
      
      
      
        <label class="md-nav__link" for="__nav_2_12_4" id="__nav_2_12_4_label" tabindex="0">
          TA courses Autumn 2022
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_12_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_12_4">
          <span class="md-nav__icon md-icon"></span>
          TA courses Autumn 2022
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/6%20Teaching/TA%20courses%20Autumn%202022/TA%20courses%20Autumn%202022%20/" class="md-nav__link">
        TA Course for Fall 2022
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_13" >
      
      
      
        <label class="md-nav__link" for="__nav_2_13" id="__nav_2_13_label" tabindex="0">
          7 Obsidian Vault Meta
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_13_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_13">
          <span class="md-nav__icon md-icon"></span>
          7 Obsidian Vault Meta
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/7%20Obsidian%20Vault%20Meta/Body%20of%20Knowledge%20Without%20Organs/" class="md-nav__link">
        Body of Knowledge without Organs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/7%20Obsidian%20Vault%20Meta/Obsidian%20Vault%20Meta/" class="md-nav__link">
        Obsidian Vault Meta
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/7%20Obsidian%20Vault%20Meta/Obsidian%20web%20browsing%20-12.01.23/" class="md-nav__link">
        Obsidian web browsing  12.01.23
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/7%20Obsidian%20Vault%20Meta/obsidian%20meta%20log/" class="md-nav__link">
        Obsidian meta log
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_13_5" >
      
      
      
        <label class="md-nav__link" for="__nav_2_13_5" id="__nav_2_13_5_label" tabindex="0">
          Better Reading
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_13_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_13_5">
          <span class="md-nav__icon md-icon"></span>
          Better Reading
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/7%20Obsidian%20Vault%20Meta/Better%20Reading/Better%20Reading%20%20/" class="md-nav__link">
        Better Reading  
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_13_6" >
      
      
      
        <label class="md-nav__link" for="__nav_2_13_6" id="__nav_2_13_6_label" tabindex="0">
          Showing off my obsidian wokflow
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_13_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_13_6">
          <span class="md-nav__icon md-icon"></span>
          Showing off my obsidian wokflow
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/7%20Obsidian%20Vault%20Meta/Showing%20off%20my%20obsidian%20wokflow/Showing%20off%20my%20obsidian%20wokflow/" class="md-nav__link">
        Showing off my obsidian wokflow
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_13_7" >
      
      
      
        <label class="md-nav__link" for="__nav_2_13_7" id="__nav_2_13_7_label" tabindex="0">
          Tracking People
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_13_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_13_7">
          <span class="md-nav__icon md-icon"></span>
          Tracking People
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/7%20Obsidian%20Vault%20Meta/Tracking%20People/Tracking%20People/" class="md-nav__link">
        Tracking People
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_14" >
      
      
      
        <label class="md-nav__link" for="__nav_2_14" id="__nav_2_14_label" tabindex="0">
          AI Movie Series
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_14_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_14">
          <span class="md-nav__icon md-icon"></span>
          AI Movie Series
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/AI%20Movie%20Series/AI%20Movie%20Series/" class="md-nav__link">
        AI Movie Series
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_15" >
      
      
      
        <label class="md-nav__link" for="__nav_2_15" id="__nav_2_15_label" tabindex="0">
          AI Art Fair Project
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_15_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_15">
          <span class="md-nav__icon md-icon"></span>
          AI Art Fair Project
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/AI-Art%20Fair%20Project/AI-Art%20Fair%20Project/" class="md-nav__link">
        AI Art Fair Project
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_16" >
      
      
      
        <label class="md-nav__link" for="__nav_2_16" id="__nav_2_16_label" tabindex="0">
          AI Lab Retreat Dec. 5 7 2022
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_16_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_16">
          <span class="md-nav__icon md-icon"></span>
          AI Lab Retreat Dec. 5 7 2022
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/AI-Lab%20Retreat%20Dec.%205-7%202022/AI-Lab%20Retreat%20Dec.%205-7%202022/" class="md-nav__link">
        AI Lab Retreat Dec. 5 7 2022
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/AI-Lab%20Retreat%20Dec.%205-7%202022/Contributions%20Challenge/" class="md-nav__link">
        Contributions Challenge
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/AI-Lab%20Retreat%20Dec.%205-7%202022/Free%20writing%20test%202/" class="md-nav__link">
        Free writing assignment
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/AI-Lab%20Retreat%20Dec.%205-7%202022/Group%20collaboration%20for%20living%20documents/" class="md-nav__link">
        A New Publication Method for a Future of Shared Knowledge
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/AI-Lab%20Retreat%20Dec.%205-7%202022/Problem%20challenge/" class="md-nav__link">
        So here is a problem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/AI-Lab%20Retreat%20Dec.%205-7%202022/test%20free%20writing/" class="md-nav__link">
        Free writing exercises
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_17" >
      
      
      
        <label class="md-nav__link" for="__nav_2_17" id="__nav_2_17_label" tabindex="0">
          AI Lab Wiki
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_17_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_17">
          <span class="md-nav__icon md-icon"></span>
          AI Lab Wiki
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/AI-Lab%20Wiki/AI-Lab%20Wiki%20/" class="md-nav__link">
        Statement
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_18" >
      
      
      
        <label class="md-nav__link" for="__nav_2_18" id="__nav_2_18_label" tabindex="0">
          Hugging Face Deep Reinforcement Learning Course
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_18_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_18">
          <span class="md-nav__icon md-icon"></span>
          Hugging Face Deep Reinforcement Learning Course
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Hugging%20Face%20Deep%20Reinforcement%20Learning%20Course/HF%20DRL%20-%20Unit%201/" class="md-nav__link">
        RL Framework
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Hugging%20Face%20Deep%20Reinforcement%20Learning%20Course/HF%20DRL%20-%20Unit%202/" class="md-nav__link">
        HF DRL   Unit 2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Hugging%20Face%20Deep%20Reinforcement%20Learning%20Course/HF%20DRL%20-%20Unit%203/" class="md-nav__link">
        HF DRL   Unit 3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Hugging%20Face%20Deep%20Reinforcement%20Learning%20Course/HF%20DRL%20-%20Unit%204/" class="md-nav__link">
        HF DRL   Unit 4
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Hugging%20Face%20Deep%20Reinforcement%20Learning%20Course/HF%20DRL%20-%20Unit%205/" class="md-nav__link">
        HF DRL   Unit 5
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Hugging%20Face%20Deep%20Reinforcement%20Learning%20Course/HF%20DRL%20Coding%20-%20Unit%204/" class="md-nav__link">
        HF DRL Coding   Unit 4
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Hugging%20Face%20Deep%20Reinforcement%20Learning%20Course/Hugging%20Face%20Deep%20Reinforcement%20Learning%20Course/" class="md-nav__link">
        Hugging Face Deep Reinforcement Learning Course
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_19" >
      
      
      
        <label class="md-nav__link" for="__nav_2_19" id="__nav_2_19_label" tabindex="0">
          IKT460 G Reinforcement Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_19_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_19">
          <span class="md-nav__icon md-icon"></span>
          IKT460 G Reinforcement Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/IKT460-G%20Reinforcement%20Learning/IKT460%20Lecture%201/" class="md-nav__link">
        IKT460 Lecture 1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/IKT460-G%20Reinforcement%20Learning/IKT460%20Lecture%202/" class="md-nav__link">
        Top Comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/IKT460-G%20Reinforcement%20Learning/IKT460-G%20Reinforcement%20Learning/" class="md-nav__link">
        IKT460 G Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/IKT460-G%20Reinforcement%20Learning/Project%20Proposal%20Outline/" class="md-nav__link">
        Project Proposal Outline
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_20" >
      
      
      
        <label class="md-nav__link" for="__nav_2_20" id="__nav_2_20_label" tabindex="0">
          Lab Social Media
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_20_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_20">
          <span class="md-nav__icon md-icon"></span>
          Lab Social Media
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Lab%20Social%20Media/Lab%20Social%20Media/" class="md-nav__link">
        Lab Social Media
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_21" >
      
      
      
        <label class="md-nav__link" for="__nav_2_21" id="__nav_2_21_label" tabindex="0">
          Laptop Environemnt
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_21_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_21">
          <span class="md-nav__icon md-icon"></span>
          Laptop Environemnt
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Laptop%20Environemnt/Laptop%20Environment/" class="md-nav__link">
        Laptop Environment
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_22" >
      
      
      
        <label class="md-nav__link" for="__nav_2_22" id="__nav_2_22_label" tabindex="0">
          Learning Python
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_22_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_22">
          <span class="md-nav__icon md-icon"></span>
          Learning Python
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Learning%20Python/Learning%20Python/" class="md-nav__link">
        Learning Python
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_23" >
      
      
      
        <label class="md-nav__link" for="__nav_2_23" id="__nav_2_23_label" tabindex="0">
          Making Posters
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_23_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_23">
          <span class="md-nav__icon md-icon"></span>
          Making Posters
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Making%20Posters/Making%20Posters/" class="md-nav__link">
        Making Posters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Making%20Posters/Neuromorphics%20Poster%20-%20Staging/" class="md-nav__link">
        Neuromorphics Poster   Staging
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Making%20Posters/Neuromorphics%20Poster%202nd%20draft/" class="md-nav__link">
        Title
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_24" >
      
      
      
        <label class="md-nav__link" for="__nav_2_24" id="__nav_2_24_label" tabindex="0">
          New Business
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_24_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_24">
          <span class="md-nav__icon md-icon"></span>
          New Business
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/New%20Business/New%20Business%20/" class="md-nav__link">
        New Business 
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_25" >
      
      
      
        <label class="md-nav__link" for="__nav_2_25" id="__nav_2_25_label" tabindex="0">
          Norwegian Courses A1 and A2
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_25_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_25">
          <span class="md-nav__icon md-icon"></span>
          Norwegian Courses A1 and A2
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Norwegian%20Courses%20A1%20and%20A2/Norwegian%20Courses%20A1%20and%20A2%20/" class="md-nav__link">
        Norwegian Courses A1 and A2 
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_26" >
      
      
      
        <label class="md-nav__link" for="__nav_2_26" id="__nav_2_26_label" tabindex="0">
          Obsidian Addons and Todos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_26_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_26">
          <span class="md-nav__icon md-icon"></span>
          Obsidian Addons and Todos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Obsidian%20Addons%20and%20Todos/Example%20Slides%20-%20Miniml/" class="md-nav__link">
        Example Slides   Miniml
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Obsidian%20Addons%20and%20Todos/Example%20Slides/" class="md-nav__link">
        Example Slides
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Obsidian%20Addons%20and%20Todos/MD%20Slides/" class="md-nav__link">
        MD Slides
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Obsidian%20Addons%20and%20Todos/Obsidian%20Addons%20and%20Todos/" class="md-nav__link">
        Obsidian Addons and Todos
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_27" >
      
      
      
        <label class="md-nav__link" for="__nav_2_27" id="__nav_2_27_label" tabindex="0">
          PENG9560 Topics in Artificial Intelligence and Machine Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_27_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_27">
          <span class="md-nav__icon md-icon"></span>
          PENG9560 Topics in Artificial Intelligence and Machine Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/Mandatory%20Assignment%20for%20Module%20I%20-%20Computational%20Intelligence/" class="md-nav__link">
        Mandatory Assignment for Module I   Computational Intelligence
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/PENG9560%20Assignment%20Draft%201/" class="md-nav__link">
        PENG9560 Assignment Draft 1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/PENG9560%20Assignment%20Draft%202/" class="md-nav__link">
        PENG9560 Assignment Draft 2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/PENG9560%20Assignment%20Draft%203/" class="md-nav__link">
        PENG9560 Assignment Draft 3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/PENG9560%20Assignment%20Draft%204/" class="md-nav__link">
        PENG9560 Assignment Draft 4
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/PENG9560%20Outline%20Assignment%201/" class="md-nav__link">
        Drafts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/" class="md-nav__link">
        PENG9560 Topics in Artificial Intelligence and Machine Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_27_8" >
      
      
      
        <label class="md-nav__link" for="__nav_2_27_8" id="__nav_2_27_8_label" tabindex="0">
          Presentation
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_27_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_27_8">
          <span class="md-nav__icon md-icon"></span>
          Presentation
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/Presentation/Presentation%20-%20Draft%201%20-%20PENG9560/" class="md-nav__link">
        Presentation   Draft 1   PENG9560
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/Presentation/Presentation%20-%20Draft%202%20-%20PENG9560/" class="md-nav__link">
        Presentation   Draft 2   PENG9560
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/Presentation/Presentation%20-%20Draft%203%20-%20PENG9560/" class="md-nav__link">
        Presentation   Draft 3   PENG9560
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/PENG9560%20Topics%20in%20Artificial%20Intelligence%20and%20Machine%20Learning/Presentation/Presentation%20Outline%20-%20PENG9560/" class="md-nav__link">
        Presentation Outline   PENG9560
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_28" >
      
      
      
        <label class="md-nav__link" for="__nav_2_28" id="__nav_2_28_label" tabindex="0">
          Video   How Critical is Brain Criticality
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_28_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_28">
          <span class="md-nav__icon md-icon"></span>
          Video   How Critical is Brain Criticality
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Video%20-%20How%20Critical%20is%20Brain%20Criticality/Video%20-%20How%20Critical%20is%20Brain%20Criticality/" class="md-nav__link">
        Statement
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_29" >
      
      
      
        <label class="md-nav__link" for="__nav_2_29" id="__nav_2_29_label" tabindex="0">
          Video Production
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_29_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_29">
          <span class="md-nav__icon md-icon"></span>
          Video Production
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Video%20Production/Video%20Production%20/" class="md-nav__link">
        Statement
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_30" >
      
      
      
        <label class="md-nav__link" for="__nav_2_30" id="__nav_2_30_label" tabindex="0">
          Workplan 2022 23 for Gustavo
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_30_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_30">
          <span class="md-nav__icon md-icon"></span>
          Workplan 2022 23 for Gustavo
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../10%20Projects/Workplan%202022-23%20for%20Gustavo/Workplan%202022-23%20for%20Gustavo/" class="md-nav__link">
        Workplan 2022 23 for Gustavo
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          50 Reading
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          50 Reading
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/50%20Reading/" class="md-nav__link">
        50 Reading
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
      
      
      
        <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
          PDF Searches
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          PDF Searches
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/PDF%20Searches/PDF%20Searches/" class="md-nav__link">
        Searching in pdfs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/PDF%20Searches/fixed%20interval%201/" class="md-nav__link">
        Paton_Buonomano_2018_The Neural Basis of Timing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/PDF%20Searches/fixed%20interval/" class="md-nav__link">
        Fixed interval
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/PDF%20Searches/interval/" class="md-nav__link">
        Interval
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/PDF%20Searches/time%20interval/" class="md-nav__link">
        Time interval
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
          Reading Lists
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          Reading Lists
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Lists/Recent%20Reading/" class="md-nav__link">
        Recent Reading
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
          Reading Notes
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4">
          <span class="md-nav__icon md-icon"></span>
          Reading Notes
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Gerstner%20et%20al.%202018/" class="md-nav__link">
        Gerstner et al. 2018
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Mehonic%202022/" class="md-nav__link">
        Mehonic 2022
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Oomen%202017/" class="md-nav__link">
        Oomen 2017
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Parent%202004/" class="md-nav__link">
        Parent 2004
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Payeur%20et%20al.%202021/" class="md-nav__link">
        Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_6" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_6" id="__nav_3_4_6_label" tabindex="0">
          Buzsáki and Vöröslakos (2023)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_6">
          <span class="md-nav__icon md-icon"></span>
          Buzsáki and Vöröslakos (2023)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Buzs%C3%A1ki%20and%20V%C3%B6r%C3%B6slakos%20%282023%29/Brain%20rhythms%20have%20come%20of%20age%20-%20comments/" class="md-nav__link">
        Brain rhythms have come of age   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Buzs%C3%A1ki%20and%20V%C3%B6r%C3%B6slakos%20%282023%29/Brain%20rhythms%20have%20come%20of%20age%20-%20glossary/" class="md-nav__link">
        Brain rhythms have come of age   glossary
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Buzs%C3%A1ki%20and%20V%C3%B6r%C3%B6slakos%20%282023%29/Brain%20rhythms%20have%20come%20of%20age%20-%20topics/" class="md-nav__link">
        Brain rhythms have come of age   topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Buzs%C3%A1ki%20and%20V%C3%B6r%C3%B6slakos%20%282023%29/Buzs%C3%A1ki%20and%20V%C3%B6r%C3%B6slakos%20%282023%29/" class="md-nav__link">
        Buzsáki and Vöröslakos (2023)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_7" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_7" id="__nav_3_4_7_label" tabindex="0">
          Chen 2022
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_7">
          <span class="md-nav__icon md-icon"></span>
          Chen 2022
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Chen%202022/Chen%202022%20-%20comments/" class="md-nav__link">
        Chen 2022   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Chen%202022/Chen%202022%20-%20glossary/" class="md-nav__link">
        Formulae
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Chen%202022/Chen%202022%20-%20topics/" class="md-nav__link">
        Chen 2022   topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Chen%202022/Chen%202022/" class="md-nav__link">
        Deep Reinforcement Learning with Spiking Q-learning
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_8" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_8" id="__nav_3_4_8_label" tabindex="0">
          Granmo 2010
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_8">
          <span class="md-nav__icon md-icon"></span>
          Granmo 2010
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Granmo%202010/Granmo%202010%20Comments/" class="md-nav__link">
        Personal Summary
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Granmo%202010/Granmo%202010%20Topics/" class="md-nav__link">
        Learning Automata (LA)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Granmo%202010/Granmo%202010/" class="md-nav__link">
        Granmo 2010
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_9" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_9" id="__nav_3_4_9_label" tabindex="0">
          Hartcher O'Brien, Brighouse, Levitan (2016)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_9">
          <span class="md-nav__icon md-icon"></span>
          Hartcher O'Brien, Brighouse, Levitan (2016)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Hartcher-O%27Brien%2C%20Brighouse%2C%20Levitan%20%282016%29/Hartcher-O%27Brien%2C%20Brighouse%2C%20Levitan%20%282016%29%20-%20comments/" class="md-nav__link">
        Hartcher O'Brien, Brighouse, Levitan (2016)   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Hartcher-O%27Brien%2C%20Brighouse%2C%20Levitan%20%282016%29/Hartcher-O%27Brien%2C%20Brighouse%2C%20Levitan%20%282016%29%20-%20glossary/" class="md-nav__link">
        Glossary
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Hartcher-O%27Brien%2C%20Brighouse%2C%20Levitan%20%282016%29/Hartcher-O%27Brien%2C%20Brighouse%2C%20Levitan%20%282016%29%20-%20topics/" class="md-nav__link">
        Hartcher O'Brien, Brighouse, Levitan (2016)   topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Hartcher-O%27Brien%2C%20Brighouse%2C%20Levitan%20%282016%29/Hartcher-O%27Brien%2C%20Brighouse%2C%20Levitan%20%282016%29/" class="md-nav__link">
        Hartcher O'Brien, Brighouse, Levitan (2016)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_10" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_10" id="__nav_3_4_10_label" tabindex="0">
          Hasegawa and Sakata 2015
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_10_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_10">
          <span class="md-nav__icon md-icon"></span>
          Hasegawa and Sakata 2015
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Hasegawa%20and%20Sakata%202015/Hasegawa%20and%20Sakata%202015/" class="md-nav__link">
        Hasegawa and Sakata 2015
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Hasegawa%20and%20Sakata%202015/Hasegawa%2C%20and%20Sakata%202015%20-%20comments/" class="md-nav__link">
        Hasegawa, and Sakata 2015   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Hasegawa%20and%20Sakata%202015/Hasegawa%2C%20and%20Sakata%202015%20-%20topics/" class="md-nav__link">
        Hasegawa, and Sakata 2015   topics
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_11" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_11" id="__nav_3_4_11_label" tabindex="0">
          Mello 2016
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_11_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_11">
          <span class="md-nav__icon md-icon"></span>
          Mello 2016
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Mello%202016/Mello%202016%20-%20Glossary/" class="md-nav__link">
        ABBREVIATIONS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Mello%202016/Mello%202016%20-%20Topics/" class="md-nav__link">
        Mello 2016   Topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Mello%202016/Mello%202016%20-%20comments/" class="md-nav__link">
        Mello 2016   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Mello%202016/Mello%202016/" class="md-nav__link">
        Mello 2016
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_12" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_12" id="__nav_3_4_12_label" tabindex="0">
          Mello, Soares, Paton 2015
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_12_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_12">
          <span class="md-nav__icon md-icon"></span>
          Mello, Soares, Paton 2015
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Mello%2C%20Soares%2C%20Paton%202015/Mello%2C%20Soares%2C%20Paton%202015%20-%20comments/" class="md-nav__link">
        Mello, Soares, Paton 2015   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Mello%2C%20Soares%2C%20Paton%202015/Mello%2C%20Soares%2C%20Paton%202015%20-%20glossary/" class="md-nav__link">
        Mello, Soares, Paton 2015   glossary
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Mello%2C%20Soares%2C%20Paton%202015/Mello%2C%20Soares%2C%20Paton%202015%20-%20topics/" class="md-nav__link">
        Mello, Soares, Paton 2015   topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Mello%2C%20Soares%2C%20Paton%202015/Mello%2C%20Soares%2C%20Paton%202015/" class="md-nav__link">
        Mello, Soares, Paton 2015
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_13" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_13" id="__nav_3_4_13_label" tabindex="0">
          O’Byrne & Jerbi (2022)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_13_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_13">
          <span class="md-nav__icon md-icon"></span>
          O’Byrne & Jerbi (2022)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/O%E2%80%99Byrne%20%26%20Jerbi%20%282022%29/O%27Byrne%20%26%20Jerbi%20%282022%29%20-%20comments/" class="md-nav__link">
        O'Byrne & Jerbi (2022)   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/O%E2%80%99Byrne%20%26%20Jerbi%20%282022%29/O%27Byrne%20%26%20Jerbi%20%282022%29%20-%20topics/" class="md-nav__link">
        Topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/O%E2%80%99Byrne%20%26%20Jerbi%20%282022%29/O%E2%80%99Byrne%20%26%20Jerbi%20%282022%29/" class="md-nav__link">
        O’Byrne & Jerbi (2022)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_14" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_14" id="__nav_3_4_14_label" tabindex="0">
          Petter, Gershman, Meck (2018)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_14_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_14">
          <span class="md-nav__icon md-icon"></span>
          Petter, Gershman, Meck (2018)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Petter%2C%20Gershman%2C%20Meck%20%282018%29/Petter%2C%20Gershman%2C%20Meck%20%282018%29%20-%20comments/" class="md-nav__link">
        Petter, Gershman, Meck (2018)   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Petter%2C%20Gershman%2C%20Meck%20%282018%29/Petter%2C%20Gershman%2C%20Meck%20%282018%29%20-%20glossary/" class="md-nav__link">
        Pavlovian Conditioning Protocol
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Petter%2C%20Gershman%2C%20Meck%20%282018%29/Petter%2C%20Gershman%2C%20Meck%20%282018%29%20-%20topics/" class="md-nav__link">
        Reward prediction error (RPE)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Petter%2C%20Gershman%2C%20Meck%20%282018%29/Petter%2C%20Gershman%2C%20Meck%20%282018%29/" class="md-nav__link">
        Petter, Gershman, Meck (2018)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_15" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_15" id="__nav_3_4_15_label" tabindex="0">
          Ponulak 2011
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_15_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_15">
          <span class="md-nav__icon md-icon"></span>
          Ponulak 2011
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Ponulak%202011/Ponulak%202011%20-%20comments/" class="md-nav__link">
        Ponulak 2011   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Ponulak%202011/Ponulak%202011%20-%20topics/" class="md-nav__link">
        Ponulak 2011   topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Ponulak%202011/Ponulak%202011/" class="md-nav__link">
        Introduction to spiking neural networks: Information processing, learning and applications
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_16" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_16" id="__nav_3_4_16_label" tabindex="0">
          Sun 2020
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_16_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_16">
          <span class="md-nav__icon md-icon"></span>
          Sun 2020
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Sun%202020/Sun%202020%20-%20comments/" class="md-nav__link">
        Sun 2020   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Sun%202020/Sun%202020%20-%20glossary/" class="md-nav__link">
        Sun 2020   glossary
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Sun%202020/Sun%202020%20-%20topics/" class="md-nav__link">
        Sun 2020   topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Sun%202020/Sun%202020/" class="md-nav__link">
        A Review of Designs and Applications of Echo State Networks
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_17" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_17" id="__nav_3_4_17_label" tabindex="0">
          Voelkner 2019
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_17_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_17">
          <span class="md-nav__icon md-icon"></span>
          Voelkner 2019
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Voelkner%202019/Voelkner%202019%20-%20comments/" class="md-nav__link">
        Voelkner 2019   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Voelkner%202019/Voelkner%202019%20-%20topics/" class="md-nav__link">
        Voelkner 2019   topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Voelkner%202019/Voelkner%202019/" class="md-nav__link">
        Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_18" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_18" id="__nav_3_4_18_label" tabindex="0">
          Yazidi 2021
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_18_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_18">
          <span class="md-nav__icon md-icon"></span>
          Yazidi 2021
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Yazidi%202021/Yazidi%202021%20-%20Comments/" class="md-nav__link">
        Yazidi 2021   Comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Yazidi%202021/Yazidi%202021%20-%20Topics/" class="md-nav__link">
        load balancing (LB)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Yazidi%202021/Yazidi%202021/" class="md-nav__link">
        Yazidi 2021
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_19" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_19" id="__nav_3_4_19_label" tabindex="0">
          Yin 2017
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_19_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_19">
          <span class="md-nav__icon md-icon"></span>
          Yin 2017
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Yin%202017/Yin%202017%20-%20comments/" class="md-nav__link">
        Yin 2017   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Yin%202017/Yin%202017%20-%20topics/" class="md-nav__link">
        Yin 2017   topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Yin%202017/Yin%202017/" class="md-nav__link">
        Yin 2017
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_20" >
      
      
      
        <label class="md-nav__link" for="__nav_3_4_20" id="__nav_3_4_20_label" tabindex="0">
          Yin et al. (2022)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_20_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_4_20">
          <span class="md-nav__icon md-icon"></span>
          Yin et al. (2022)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Yin%20et%20al.%20%282022%29/Yin%20et%20al.%20%282022%29%20-%20comments/" class="md-nav__link">
        Yin et al. (2022)   comments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Yin%20et%20al.%20%282022%29/Yin%20et%20al.%20%282022%29%20-%20glossary/" class="md-nav__link">
        Glossary
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Yin%20et%20al.%20%282022%29/Yin%20et%20al.%20%282022%29%20-%20topics/" class="md-nav__link">
        Topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Reading%20Notes/Yin%20et%20al.%20%282022%29/Yin%20et%20al.%20%282022%29/" class="md-nav__link">
        Yin et al. (2022)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
      
      
      
        <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
          Videos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_5">
          <span class="md-nav__icon md-icon"></span>
          Videos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Videos/Cosyne%202022%20Tutorial%20on%20Spiking%20Neural%20Networks/" class="md-nav__link">
        Cosyne 2022 Tutorial on Spiking Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Videos/Eliasmith%20%20-%20Spiking%20Neural%20Networks%20for%20More%20Efficient%20AI%20Algorithms/" class="md-nav__link">
        https://www.youtube.com/watch?v=PeW-TN3P1hk
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Videos/Hopfield%20Networks%20is%20All%20You%20Need/" class="md-nav__link">
        Hopfield Networks is All You Need
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Videos/JNS%20Lecture%20Will%20Dabney%20-%20A%20Distributional%20Code%20for%20Value%20in%20Dopamine-Based%20Reinforcement%20Learning/" class="md-nav__link">
        A Distributional Code for Value in Dopamine-Based Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Videos/Neural%20representations%20of%20time%2C%20space%20and%20other%20continuous%20variables/" class="md-nav__link">
        Neural representations of time, space and other continuous variables
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
      
      
      
        <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
          Zotero Papers
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_6">
          <span class="md-nav__icon md-icon"></span>
          Zotero Papers
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/Zotero%20Papers/Zotero%20Papers/" class="md-nav__link">
        Zotero Papers
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
      
      
      
        <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0">
          Citations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_7">
          <span class="md-nav__icon md-icon"></span>
          Citations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/citations/%40pateriaHierarchicalReinforcementLearning2021/" class="md-nav__link">
        @pateriaHierarchicalReinforcementLearning2021
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/citations/%40voelkerLegendreMemoryUnits2019/" class="md-nav__link">
        @voelkerLegendreMemoryUnits2019
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/citations/Citation%20Anand%20Subramoney%2C%20Franz%20Scherr%2C%20Guillaume%20Bellec%2C%20Elias%20Hajek%2C%20Darjan%20Salaj%2C%20Robert%20Legenstein%2C%20Wolfgang%20Maass%20-%20/" class="md-nav__link">
        Citation Anand Subramoney, Franz Scherr, Guillaume Bellec, Elias Hajek, Darjan Salaj, Robert Legenstein, Wolfgang Maass   
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/citations/Citation%20Eleni%20Vasilaki%2C%20Nicolas%20Fr%C3%A9maux%2C%20Robert%20Urbanczik%2C%20Walter%20Senn%2C%20Wulfram%20Gerstner%20-%202009/" class="md-nav__link">
        Citation Eleni Vasilaki, Nicolas Frémaux, Robert Urbanczik, Walter Senn, Wulfram Gerstner   2009
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/citations/Citation%20Peter%20Diehl%2C%20Matthew%20Cook%20-%202015/" class="md-nav__link">
        Citation Peter Diehl, Matthew Cook   2015
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/citations/Citation%20SlowProcessesNeurons/" class="md-nav__link">
        Citation SlowProcessesNeurons
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_8" >
      
      
      
        <label class="md-nav__link" for="__nav_3_8" id="__nav_3_8_label" tabindex="0">
          Tweets
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_8">
          <span class="md-nav__icon md-icon"></span>
          Tweets
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/tweets/Twitter%20-%20VnVrinda%20-%20How%20to%20search%20and%20read%20papers%20-%2011.07.22/" class="md-nav__link">
        Twitter   VnVrinda   How to search and read papers   11.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/tweets/Twitter%20-%20YanliangShi%20-%2020.07.22/" class="md-nav__link">
        Twitter   YanliangShi   20.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/tweets/Twitter%20-%20hisspikeness%20-%2023.07.22/" class="md-nav__link">
        Twitter   hisspikeness   23.07.22
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_9" >
      
      
      
        <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
          Zot2
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_9">
          <span class="md-nav__icon md-icon"></span>
          Zot2
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40abelesCorticonicsNeuralCircuits1991/" class="md-nav__link">
        Corticonics: Neural Circuits of the Cerebral Cortex
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40allmanPathophysiologicalDistortionsTime2012/" class="md-nav__link">
        Pathophysiological distortions in time perception and timed performance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40balciPeakIntervalProcedure2020/" class="md-nav__link">
        The Peak Interval Procedure in Rodents: A Tool for Studying the Neurobiological Basis of Interval Timing and Its Alterations in Models of Human Disease
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40beggsCortexCriticalPoint2022/" class="md-nav__link">
        The Cortex and the Critical Point: Understanding the Power of Emergence.
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40bellecSolutionLearningDilemma2020/" class="md-nav__link">
        A solution to the learning dilemma for recurrent networks of spiking neurons
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40bendorBiasingContentHippocampal2012/" class="md-nav__link">
        Biasing the content of hippocampal replay during sleep
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40bengioBiologicallyPlausibleDeep2016/" class="md-nav__link">
        Towards Biologically Plausible Deep Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40biTimeRepresentationNeural2019/" class="md-nav__link">
        Time representation in neural network models trained to perform interval timing tasks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40botvinickDeepReinforcementLearning2020/" class="md-nav__link">
        Deep Reinforcement Learning and its Neuroscientific Implications
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40brahlekTransportPropertiesTopological2015/" class="md-nav__link">
        @brahlekTransportPropertiesTopological2015
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40bretteSimulationNetworksSpiking2007/" class="md-nav__link">
        Simulation of networks of spiking neurons: A review of tools and strategies
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40bronsteinGeometricDeepLearning2021/" class="md-nav__link">
        Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40buzsakiBrainRhythmsHave2023/" class="md-nav__link">
        Brain rhythms have come of age
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40caoExplanatoryModelsNeuroscience2021/" class="md-nav__link">
        Explanatory models in neuroscience: Part 1 -- taking mechanistic abstraction seriously
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40carvalhoTemporalBisectionProcedure2019/" class="md-nav__link">
        Temporal Bisection Procedure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40chenDeepReinforcementLearning2022/" class="md-nav__link">
        Deep Reinforcement Learning with Spiking Q-learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40chilkuriParallelizingLegendreMemory2021/" class="md-nav__link">
        Parallelizing Legendre Memory Unit Training
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40cramerSurrogateGradientsAnalog2022/" class="md-nav__link">
        Surrogate gradients for analog neuromorphic computing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40cruzActionSuppressionReveals2022/" class="md-nav__link">
        Action suppression reveals opponent parallel control via striatal circuits
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40deverettIntervalTimingDeep2019/" class="md-nav__link">
        Interval timing in deep reinforcement learning agents
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40erdemExploringRelationshipsEffort2020/" class="md-nav__link">
        Exploring relationships between effort, motion, and sound in new musical instruments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40eshraghianIntroduction2022/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40fangwei123456SpikingJelly2022/" class="md-nav__link">
        SpikingJelly
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40fremauxNeuromodulatedSpikeTimingDependentPlasticity2016/" class="md-nav__link">
        Neuromodulated Spike-Timing-Dependent Plasticity, and Theory of Three-Factor Learning Rules
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40furberSpiNNakerProject2014/" class="md-nav__link">
        The SpiNNaker Project
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40gallonialessandroSNUFA2022Behavioral/" class="md-nav__link">
        SNUFA 2022 - Behavioral Timescale Synaptic Plasticity (BTSP) for credit assignment
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40gaoCorticalColumnWholebrain/" class="md-nav__link">
        Cortical column and whole-brain imaging with molecular contrast and nanoscale resolution
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40gershmanReinforcementLearningEpisodic2017/" class="md-nav__link">
        Reinforcement learning and episodic memory in humans and animals: an integrative framework
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40gershmanTimeRepresentationReinforcement2014/" class="md-nav__link">
        Time representation in reinforcement learning models of the basal ganglia
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40gerstnerEligibilityTracesPlasticity2018/" class="md-nav__link">
        @gerstnerEligibilityTracesPlasticity2018
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40goudarEncodingSensoryMotor2018/" class="md-nav__link">
        Encoding sensory and motor patterns as time-invariant trajectories in recurrent neural networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40grondinTimingTimePerception2010/" class="md-nav__link">
        Timing and time perception: A review of recent behavioral and neuroscience findings and theoretical directions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40guOscillatoryMultiplexingNeural2015a/" class="md-nav__link">
        Oscillatory multiplexing of neural population codes for interval timing and working memory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40hamedaniDeepSpikingDelayed2020/" class="md-nav__link">
        Deep Spiking Delayed Feedback Reservoirs and Its Application in Spectrum Sensing of MIMO-OFDM Dynamic Spectrum Sharing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40hardyEncodingTimeFeedforward2018/" class="md-nav__link">
        Encoding Time in Feedforward Trajectories of a Recurrent Neural Network Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40hartcher-obrienSingleMechanismAccount2016/" class="md-nav__link">
        A single mechanism account of duration and rate processing via the pacemaker-accumulator and beat frequency models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40hasegawaModelMultisecondTiming2015/" class="md-nav__link">
        A model of multisecond timing behaviour under peak-interval procedures
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40hesselRainbowCombiningImprovements2017/" class="md-nav__link">
        Rainbow: Combining Improvements in Deep Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40howardEfficientNeuralComputation2019/" class="md-nav__link">
        Efficient Neural Computation in the Laplace Domain
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40jazayeriNeuralMechanismSensing2015/" class="md-nav__link">
        @jazayeriNeuralMechanismSensing2015
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40jensenSelfOrganizedCriticalityEmergent1998/" class="md-nav__link">
        Self-Organized Criticality: Emergent Complex Behavior in Physical and Biological Systems
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40jirsaEntropyFreeEnergy2022/" class="md-nav__link">
        @jirsaEntropyFreeEnergy2022
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40khajehabdollahiWhenBeCritical2022/" class="md-nav__link">
        When to Be Critical? Performance and Evolvability in Different Regimes of Neural Ising Agents
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40kononowiczTimingTimePerception2018/" class="md-nav__link">
        Timing and Time Perception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40kumarSpikingActivityPropagation2010/" class="md-nav__link">
        Spiking activity propagation in neuronal networks: reconciling different perspectives on neural coding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40lentResourceSelectionCognitive2018/" class="md-nav__link">
        Resource Selection in Cognitive Networks With Spiking Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40liMiceInferProbabilistic2013/" class="md-nav__link">
        Mice infer probabilistic models for timing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40liuHumanLevelControlDirectly2022/" class="md-nav__link">
        Human-Level Control Through Directly Trained Deep Spiking $Q$-Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40liuMultiobjectiveReinforcementLearning2015/" class="md-nav__link">
        Multiobjective Reinforcement Learning: A Comprehensive Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40loefflerModularityMultitaskingNeuromemristive2021a/" class="md-nav__link">
        Modularity and multitasking in neuro-memristive reservoir networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40maassNetworksSpikingNeurons1997/" class="md-nav__link">
        Networks of spiking neurons: The third generation of neural network models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40marsiliQuantifyingRelevanceLearning2022/" class="md-nav__link">
        Quantifying Relevance in Learning and Inference
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40matellNeuropsychologicalMechanismsInterval2000/" class="md-nav__link">
        Neuropsychological mechanisms of interval timing behavior
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40mehonicBraininspiredComputingNeeds2022/" class="md-nav__link">
        Brain-inspired computing needs a master plan
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40melloNeuralBehavioralMechanisms2016/" class="md-nav__link">
        Neural and Behavioral Mechanisms of Interval Timing in the Striatum
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40melloScalablePopulationCode2015/" class="md-nav__link">
        A Scalable Population Code for Time in the Striatum
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40mnihHumanlevelControlDeep2015/" class="md-nav__link">
        Human-level control through deep reinforcement learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40montanoGridgraphModelingEmergent2022/" class="md-nav__link">
        Grid-graph modeling of emergent neuromorphic dynamics and heterosynaptic plasticity in memristive nanonetworks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40montemurroPhaseofFiringCodingNatural2008/" class="md-nav__link">
        Phase-of-Firing Coding of Natural Visual Stimuli in Primary Visual Cortex
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40murrayLearningMultipleVariablespeed2017/" class="md-nav__link">
        Learning multiple variable-speed sequences in striatum via cortical tutoring
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40naudBurstdependentSynapticPlasticity/" class="md-nav__link">
        Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40neftciSurrogateGradientLearning2019/" class="md-nav__link">
        Surrogate Gradient Learning in Spiking Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40nicolaSupervisedLearningSpiking2017/" class="md-nav__link">
        Supervised learning in spiking neural networks with FORCE training
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40obyrneHowCriticalBrain2022/" class="md-nav__link">
        How critical is brain criticality?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40oneillPlayItAgain2010/" class="md-nav__link">
        Play it again: reactivation of waking experience and memory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40parisottoStabilizingTransformersReinforcement2020/" class="md-nav__link">
        Stabilizing Transformers for Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40patelImprovedRobustnessReinforcement2019/" class="md-nav__link">
        Improved robustness of reinforcement learning policies upon conversion to spiking neuronal network platforms applied to Atari Breakout game
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40patonNeuralBasisTiming2018/" class="md-nav__link">
        The Neural Basis of Timing: Distributed Mechanisms for Diverse Functions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40payeurBurstdependentSynapticPlasticity2021/" class="md-nav__link">
        Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40petterIntegratingModelsInterval2018/" class="md-nav__link">
        Integrating Models of Interval Timing and Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40petterTemporalProcessingIntrinsic2016/" class="md-nav__link">
        Temporal Processing by Intrinsic Neural Network Dynamics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40pfeifferDeepLearningSpiking2018/" class="md-nav__link">
        Deep Learning With Spiking Neurons: Opportunities and Challenges
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40phuongFormalAlgorithmsTransformers2022/" class="md-nav__link">
        Formal Algorithms for Transformers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40pontes-filhoAssessingRobustnessCritical2022/" class="md-nav__link">
        Assessing the robustness of critical behavior in stochastic cellular automata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40pontes-filhoBidirectionalLearningRobust2019%20%282%29/" class="md-nav__link">
        Bidirectional Learning for Robust Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40pontes-filhoBidirectionalLearningRobust2019/" class="md-nav__link">
        Bidirectional Learning for Robust Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40pontes-filhoGeneralRepresentationDynamical2019/" class="md-nav__link">
        A general representation of dynamical systems for reservoir computing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40ponulakIntroductionSpikingNeural2011/" class="md-nav__link">
        Introduction to spiking neural networks: Information processing, learning and applications
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40princeCurrentStateFuture2022/" class="md-nav__link">
        Current State and Future Directions for Learning in Biological Recurrent Neural Networks: A Perspective Piece
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40ramsauerHopfieldNetworksAll2020/" class="md-nav__link">
        Hopfield Networks is All You Need
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40rolnickExperienceReplayContinual2019a/" class="md-nav__link">
        Experience Replay for Continual Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40rossbroichFluctuationdrivenInitializationSpiking2022/" class="md-nav__link">
        Fluctuation-driven initialization for spiking neural network training
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40rueckauerConversionContinuousValuedDeep2017/" class="md-nav__link">
        Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40schmittNeuromorphicHardwareLoop2017/" class="md-nav__link">
        Neuromorphic hardware in the loop: Training a deep spiking network on the BrainScaleS wafer-scale system
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40shankarScaleInvariantInternalRepresentation2012/" class="md-nav__link">
        A Scale-Invariant Internal Representation of Time
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40shiScalarTimingTheory2022/" class="md-nav__link">
        Beyond Scalar Timing Theory: Integrating Neural Oscillators with Computational Accessibility in Memory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40shiSpatialTemporalCorrelations2022/" class="md-nav__link">
        Spatial and temporal correlations in neural networks with structured connectivity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40songRewardbasedTrainingRecurrent2017/" class="md-nav__link">
        Reward-based training of recurrent neural networks for cognitive and value-based tasks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40spinolaWhatHumansLearn2013/" class="md-nav__link">
        What do humans learn in a double, temporal bisection task: Absolute or relative stimulus durations?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40sunReviewDesignsApplications2020/" class="md-nav__link">
        A Review of Designs and Applications of Echo State Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40sungSimultaneousEmulationSynaptic2022/" class="md-nav__link">
        Simultaneous emulation of synaptic and intrinsic plasticity using a memristive synapse
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40suvrathanSTDPDiverseFunctionally2019a/" class="md-nav__link">
        Beyond STDP—towards diverse and functionally relevant plasticity rules
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40swearingenPatternRespondingPeakInterval2010/" class="md-nav__link">
        The Pattern of Responding in the Peak-Interval Procedure with Gaps: An Individual-Trials Analysis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40tallotNeuralEncodingTime2020/" class="md-nav__link">
        Neural encoding of time in the animal brain
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40tanStrategyBenchmarkConverting2020/" class="md-nav__link">
        Strategy and Benchmark for Converting Deep Q-Networks to Event-Driven Spiking Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40tangDeepReinforcementLearning2020/" class="md-nav__link">
        Deep Reinforcement Learning with Population-Coded Spiking Neural Network for Continuous Control
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40tavanaeiDeepLearningSpiking2019/" class="md-nav__link">
        Deep learning in spiking neural networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40tekiPersistenceMemoryHow2017/" class="md-nav__link">
        The Persistence of Memory: How the Brain Encodes Time in Memory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40tello-ramosTimePlaceLearning2015/" class="md-nav__link">
        Time–place learning in wild, free-living hummingbirds
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40varellaModelPeakintervalTask2019/" class="md-nav__link">
        A model for the peak-interval task based on neural oscillation-delimited states
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40vasilakiSpikeBasedReinforcementLearning2009/" class="md-nav__link">
        Spike-Based Reinforcement Learning in Continuous State and Action Space: When Policy Gradient Methods Fail
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40vigneronCriticalSurveySTDP2020/" class="md-nav__link">
        A critical survey of STDP in Spiking Neural Networks for Pattern Recognition
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40voelkerDynamicalSystemsSpiking2019/" class="md-nav__link">
        Dynamical Systems in Spiking Neuromorphic Hardware
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40voelkerLegendreMemoryUnits2019/" class="md-nav__link">
        Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40voelkerSpikePerformanceTraining2021/" class="md-nav__link">
        A Spike in Performance: Training Hybrid-Spiking Neural Networks with Quantized Activation Functions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40vogelsSignalPropagationLogic2005/" class="md-nav__link">
        Signal Propagation and Logic Gating in Networks of Integrate-and-Fire Neurons
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40wangConvergentEfficientDeep2022/" class="md-nav__link">
        Convergent and Efficient Deep Q Network Algorithm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40wangDeepReinforcementLearning2022/" class="md-nav__link">
        Deep Reinforcement Learning: A Survey
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40wengTianshouHighlyModularized2022/" class="md-nav__link">
        Tianshou: a Highly Modularized Deep Reinforcement Learning Library
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40wiesnerMeasuringComplexity2020/" class="md-nav__link">
        Measuring complexity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40williamsNeuralBurstCodes2021/" class="md-nav__link">
        Neural burst codes disguised as rate codes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40wilsonInfluenceMultipleTemporal2015/" class="md-nav__link">
        The influence of multiple temporal memories in the peak-interval procedure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40wimmerRewardLearningWorking2022/" class="md-nav__link">
        Reward learning and working memory: Effects of massed versus spaced training and post-learning delay period
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40yinAccurateOnlineTraining2022/" class="md-nav__link">
        Accurate online training of dynamical spiking neural networks through Forward Propagation Through Time
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40yinEffectiveEfficientComputation2020/" class="md-nav__link">
        Effective and Efficient Computation with Multiple-timescale Spiking Recurrent Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40yinIntervaltimingProtocolsTheir2017/" class="md-nav__link">
        Interval-timing Protocols and Their Relevancy to the Study of Temporal Cognition and Neurobehavioral Genetics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40yinOscillationCoincidenceDetectionModels2022/" class="md-nav__link">
        Oscillation/Coincidence-Detection Models of Reward-Related Timing in Corticostriatal Circuits
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40zenkeSuperSpikeSupervisedLearning2018/" class="md-nav__link">
        SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40zenkeSynapticPlasticityNeural2013/" class="md-nav__link">
        Synaptic Plasticity in Neural Networks Needs Homeostasis with a Fast Rate Detector
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40zenkeVisualizingJointFuture2021/" class="md-nav__link">
        Visualizing a joint future of neuroscience and neuromorphic engineering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/%40zhouEncodingTimeNeural2022/" class="md-nav__link">
        Encoding time in neural dynamic regimes with distinct computational tradeoffs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/Diehl%20and%20Cook%202015/" class="md-nav__link">
        Unsupervised learning of digit recognition using spike-timing-dependent plasticity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/goldwasserPlantingUndetectableBackdoors2022/" class="md-nav__link">
        goldwasserPlantingUndetectableBackdoors2022
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../50%20Reading/zot2/wiesnerMeasuringComplexity2020/" class="md-nav__link">
        ['Measuring complexity']
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
      
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          70 Wiki
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          70 Wiki
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
          Articles
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          Articles
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../A%20Comprehensive%20Guide%20to%20Convolutional%20Neural%20Networks%20%E2%80%94%20the%20ELI5%20way%20-%2003.04.22/" class="md-nav__link">
        A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way   03.04.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Strange%20Illusion%20Shows%20The%20Human%20Brain%20Mess%20With%20Time%20to%20Maintain%20Our%20Expectations%20-%2008.04.22/" class="md-nav__link">
        Strange Illusion Shows The Human Brain Mess With Time to Maintain Our Expectations   08.04.22
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_3" checked>
      
      
      
        <label class="md-nav__link" for="__nav_4_1_3" id="__nav_4_1_3_label" tabindex="0">
          MD Clips Old
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_3_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_4_1_3">
          <span class="md-nav__icon md-icon"></span>
          MD Clips Old
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../A%20Neural%20Mechanism%20for%20Sensing%20and%20Reproducing%20a%20Time%20Interval%20-%2023.06.22/" class="md-nav__link">
        A Neural Mechanism for Sensing and Reproducing a Time Interval   23.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../A%20Neural%20Mechanism%20for%20Sensing%20and%20Reproducing%20a%20Time%20Interval%20-%20PubMed%20-%2023.06.22/" class="md-nav__link">
        A Neural Mechanism for Sensing and Reproducing a Time Interval   PubMed   23.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../A%20Scalable%20Population%20Code%20for%20Time%20in%20the%20Striatum%20-%2008.06.22/" class="md-nav__link">
        A Scalable Population Code for Time in the Striatum - ScienceDirect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../A%20model%20of%20multisecond%20timing%20behaviour%20under%20peak-interval%20procedures%20-%2011.07.22/" class="md-nav__link">
        A model of multisecond timing behaviour under peak interval procedures   11.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../A%20review%20of%20learning%20in%20biologically%20plausible%20spiking%20neural%20networks%20-%2011.05.22/" class="md-nav__link">
        A review of learning in biologically plausible spiking neural networks - ScienceDirect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Action%20suppression%20reveals%20opponent%20parallel%20control%20via%20striatal%20circuits%20-%2012.07.22/" class="md-nav__link">
        Action suppression reveals opponent parallel control via striatal circuits   12.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../An%20experimental%20unification%20of%20reservoir%20computing%20methods%20-%2011.05.22/" class="md-nav__link">
        An experimental unification of reservoir computing methods - ScienceDirect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Computational%20roles%20of%20plastic%20probabilistic%20synapses%20-%2010.05.22/" class="md-nav__link">
        Computational roles of plastic probabilistic synapses - ScienceDirect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Deep%20Learning%20With%20Spiking%20Neurons%20Opportunities%20and%20Challenges%20-%2011.05.22/" class="md-nav__link">
        Frontiers | Deep Learning With Spiking Neurons: Opportunities and Challenges | Neuroscience
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Design%20of%20deep%20echo%20state%20networks%20-%2009.05.22/" class="md-nav__link">
        Design of deep echo state networks - ScienceDirect
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Encoding sensory and motor patterns as time invariant trajectories in recurrent neural networks   20.07.22
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Encoding sensory and motor patterns as time invariant trajectories in recurrent neural networks   20.07.22
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#abstract" class="md-nav__link">
    Abstract
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    Introduction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    Results
  </a>
  
    <nav class="md-nav" aria-label="Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trained-rnns-perform-a-sensorimotor-spoken-to-handwritten-digit-transcription-task" class="md-nav__link">
    Trained RNNs perform a sensorimotor spoken-to-handwritten digit transcription task
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a-trained-rnn-performs-the-sensorimotor-spoken-to-handwritten-digit-transcription-task-on-novel-utterances" class="md-nav__link">
    A trained RNN performs the sensorimotor spoken-to-handwritten digit transcription task on novel utterances.
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stability-of-the-neural-trajectories" class="md-nav__link">
    Stability of the neural trajectories
  </a>
  
    <nav class="md-nav" aria-label="Stability of the neural trajectories">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#digit-transcription-is-robust-to-perturbations-during-the-sensory-and-motor-epochs" class="md-nav__link">
    Digit transcription is robust to perturbations during the sensory and motor epochs.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-training-sculpts-network-dynamics-to-enhance-discrimination" class="md-nav__link">
    RNN training sculpts network dynamics to enhance discrimination
  </a>
  
    <nav class="md-nav" aria-label="RNN training sculpts network dynamics to enhance discrimination">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trained-rnns-generate-convergent-continuous-neural-trajectories-in-response-to-different-instances-of-the-same-spatiotemporal-object" class="md-nav__link">
    Trained RNNs generate convergent continuous neural trajectories in response to different instances of the same spatiotemporal object.
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trained-rnns-encode-both-sensory-and-motor-objects-as-well-separated-neural-trajectories" class="md-nav__link">
    Trained RNNs encode both sensory and motor objects as well separated neural trajectories.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#balance-between-recurrent-and-input-dynamics-is-crucial-for-discrimination" class="md-nav__link">
    Balance between recurrent and input dynamics is crucial for discrimination
  </a>
  
    <nav class="md-nav" aria-label="Balance between recurrent and input dynamics is crucial for discrimination">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trajectory-separation-in-reservoir-and-trained-rnns-as-a-function-of-input-amplitude" class="md-nav__link">
    Trajectory separation in reservoir and trained RNNs as a function of input amplitude.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mechanisms-underlying-spatial-spectral-generalization" class="md-nav__link">
    Mechanisms underlying spatial (Spectral) Generalization
  </a>
  
    <nav class="md-nav" aria-label="Mechanisms underlying spatial (Spectral) Generalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#robustness-to-spectral-noise-depends-on-the-spatiotemporal-structure-of-the-inputs-that-the-network-is-exposed-to-during-training" class="md-nav__link">
    Robustness to spectral noise depends on the spatiotemporal structure of the inputs that the network is exposed to during training.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoding-stimuli-as-neural-trajectories-allows-for-temporal-generalization-scaling" class="md-nav__link">
    Encoding stimuli as neural trajectories allows for temporal generalization (Scaling)
  </a>
  
    <nav class="md-nav" aria-label="Encoding stimuli as neural trajectories allows for temporal generalization (Scaling)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#invariance-of-encoding-trajectories-to-temporally-warped-spoken-digits" class="md-nav__link">
    Invariance of encoding trajectories to temporally warped spoken digits.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mechanisms-underlying-temporal-generalization-temporal-scaling" class="md-nav__link">
    Mechanisms underlying temporal generalization (temporal scaling)
  </a>
  
    <nav class="md-nav" aria-label="Mechanisms underlying temporal generalization (temporal scaling)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mechanism-of-temporal-scaling-invariance" class="md-nav__link">
    Mechanism of temporal scaling invariance.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#discussion" class="md-nav__link">
    Discussion
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#materials-and-methods" class="md-nav__link">
    Materials and methods
  </a>
  
    <nav class="md-nav" aria-label="Materials and methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#network-model" class="md-nav__link">
    Network model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#simulations-and-training" class="md-nav__link">
    Simulations and training
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#input-structure" class="md-nav__link">
    Input structure
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#innate-trajectories-and-rnn-training" class="md-nav__link">
    Innate trajectories and RNN training
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-training" class="md-nav__link">
    Output training
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-descent-training" class="md-nav__link">
    Gradient descent training
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trajectory-analysis" class="md-nav__link">
    Trajectory analysis
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-decomposition" class="md-nav__link">
    RNN decomposition
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#analysis-of-parallel-trajectories" class="md-nav__link">
    Analysis of parallel trajectories
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trajectory-visualization" class="md-nav__link">
    Trajectory visualization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#source-code" class="md-nav__link">
    Source code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decision-letter" class="md-nav__link">
    Decision letter
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#author-response" class="md-nav__link">
    Author response
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#article-and-author-information" class="md-nav__link">
    Article and author information
  </a>
  
    <nav class="md-nav" aria-label="Article and author information">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#author-details" class="md-nav__link">
    Author details
  </a>
  
    <nav class="md-nav" aria-label="Author details">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dean-v-buonomano" class="md-nav__link">
    Dean V Buonomano
  </a>
  
    <nav class="md-nav" aria-label="Dean V Buonomano">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contribution" class="md-nav__link">
    Contribution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-correspondence" class="md-nav__link">
    For correspondence
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#competing-interests" class="md-nav__link">
    Competing interests
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#funding" class="md-nav__link">
    Funding
  </a>
  
    <nav class="md-nav" aria-label="Funding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#national-science-foundation-nsf-iis-1420897" class="md-nav__link">
    National Science Foundation (NSF IIS-1420897)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#google-google-faculty-research-award" class="md-nav__link">
    Google (Google Faculty Research Award)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#national-institutes-of-health-mh60163" class="md-nav__link">
    National Institutes of Health (MH60163)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#acknowledgements" class="md-nav__link">
    Acknowledgements
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reviewing-editor" class="md-nav__link">
    Reviewing Editor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#publication-history" class="md-nav__link">
    Publication history
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#copyright" class="md-nav__link">
    Copyright
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#metrics" class="md-nav__link">
    Metrics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#download-links" class="md-nav__link">
    Download links
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Ensemble%20Coding%20of%20Vocal%20Control%20in%20Birdsong%20-%2021.06.22/" class="md-nav__link">
        Ensemble Coding of Vocal Control in Birdsong   21.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Hopfield%20network%20-%20Scholarpedia%20-%2022.06.22/" class="md-nav__link">
        Hopfield network   Scholarpedia   22.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../How%20to%20Review%20Articles%20-%2009.06.22/" class="md-nav__link">
        How to Review Articles   09.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../How%20to%20conduct%20a%20review%20-%2009.06.22/" class="md-nav__link">
        How to conduct a review   09.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../How%20to%20write%20a%20review%20article%20%20Writing%20your%20paper%20%20Author%20Services%20-%2009.06.22/" class="md-nav__link">
        How to write a review article  Writing your paper  Author Services   09.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../How%20to%20write%20a%20superb%20literature%20review%20-%2009.06.22/" class="md-nav__link">
        How to write a superb literature review
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Human-level%20control%20through%20deep%20reinforcement%20learning%20-%2013.05.22/" class="md-nav__link">
        Human-level control through deep reinforcement learning | Nature
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Integrating%20Models%20of%20Interval%20Timing%20and%20Reinforcement%20Learning%20-%2011.07.22/" class="md-nav__link">
        Integrating Models of Interval Timing and Reinforcement Learning   11.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../L0%20Norm%2C%20L1%20Norm%2C%20L2%20Norm%20%26%20L-Infinity%20Norm%20-%20Sara%20Iris%20Garcia%20-%20Medium%20-%2013.06.22/" class="md-nav__link">
        L0 Norm, L1 Norm, L2 Norm & L Infinity Norm   Sara Iris Garcia   Medium   13.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Learning%20multiple%20variable-speed%20sequences%20in%20striatum%20via%20cortical%20tutoring%20-%2020.07.22/" class="md-nav__link">
        Learning multiple variable speed sequences in striatum via cortical tutoring   20.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Learning%20offline%20memory%20replay%20in%20biological%20and%20artificial%20reinforcement%20learning%20-%2010.05.22/" class="md-nav__link">
        Learning offline: memory replay in biological and artificial reinforcement learning - ScienceDirect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Local%20Lyapunov%20exponents%20of%20deep%20echo%20state%20networks%20-%2009.05.22/" class="md-nav__link">
        Local Lyapunov exponents of deep echo state networks - ScienceDirect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Pad%C3%A9%20approximant%20-%20Scholarpedia%20-%2009.05.22/" class="md-nav__link">
        Padé approximant   Scholarpedia   09.05.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Peer%20Review%20Writing%20Guide%20-%20Reviewer%20Resources%20-%20Volunteer%20-%2009.06.22/" class="md-nav__link">
        Peer Review Writing Guide   Reviewer Resources   Volunteer   09.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../RNN%2C%20LSTM%20%26%20GRU%20-%2009.05.22/" class="md-nav__link">
        RNN, LSTM & GRU
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Reinforcement%20learning%20and%20episodic%20memory%20in%20humans%20and%20animals%20an%20integrative%20framework%20-%2020.07.22/" class="md-nav__link">
        Reinforcement learning and episodic memory in humans and animals an integrative framework   20.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Reinforcement%20learning%20with%20Marr%20-%2020.07.22/" class="md-nav__link">
        Reinforcement learning with Marr   20.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Research%20Guides%20Publishing%20in%20the%20Sciences%20How%20to%20Write%20a%20Scientific%20Literature%20Review%20-%2009.06.22/" class="md-nav__link">
        Research Guides Publishing in the Sciences How to Write a Scientific Literature Review   09.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Reservoir%20computing%20and%20extreme%20learning%20machines%20for%20non-linear%20time-series%20data%20analysis%20-%2011.05.22/" class="md-nav__link">
        Reservoir computing and extreme learning machines for non-linear time-series data analysis - ScienceDirect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Reservoir%20computing%20approaches%20to%20recurrent%20neural%20network%20training%20-%2009.05.22/" class="md-nav__link">
        Reservoir computing approaches to recurrent neural network training - ScienceDirect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Scientists%20discover%20how%20the%20brain%20keeps%20the%20urge%20to%20act%20in%20check%20%20Champalimaud%20Foundation%20-%2012.07.22/" class="md-nav__link">
        Scientists discover how the brain keeps the urge to act in check  Champalimaud Foundation   12.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Spiking%20Neural%20Networks%20and%20online%20learning%20An%20overview%20and%20perspectives%20-%2010.05.22/" class="md-nav__link">
        Spiking Neural Networks and online learning: An overview and perspectives - ScienceDirect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action%20-%2006.05.22/" class="md-nav__link">
        State–action–reward–state–action   06.05.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Temporal%20Bisection%20Procedure%20-%2020.06.22/" class="md-nav__link">
        Temporal Bisection Procedure   20.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../The%20Pattern%20of%20Responding%20in%20the%20Peak-Interval%20Procedure%20with%20Gaps%20An%20Individual-Trials%20Analysis%20-%2011.07.22/" class="md-nav__link">
        The Pattern of Responding in the Peak Interval Procedure with Gaps An Individual Trials Analysis   11.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../The%20influence%20of%20multiple%20temporal%20memories%20in%20the%20peak-interval%20procedure%20-%2011.07.22%20%281%29/" class="md-nav__link">
        The influence of multiple temporal memories in the peak interval procedure   11.07.22 (1)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../The%20influence%20of%20multiple%20temporal%20memories%20in%20the%20peak-interval%20procedure%20-%2011.07.22/" class="md-nav__link">
        The influence of multiple temporal memories in the peak interval procedure   11.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Time%20representation%20in%20reinforcement%20learning%20models%20of%20the%20basal%20ganglia%20-%2020.07.22/" class="md-nav__link">
        Time representation in reinforcement learning models of the basal ganglia   20.07.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Unified%20pre-%20and%20postsynaptic%20long-term%20plasticity%20enables%20reliable%20and%20flexible%20learning%20-%2011.05.22/" class="md-nav__link">
        Unified pre- and postsynaptic long-term plasticity enables reliable and flexible learning | eLife
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../What%20do%20humans%20learn%20in%20a%20double%2C%20temporal%20bisection%20task%20Absolute%20or%20relative%20stimulus%20durations%20-%2020.06.22/" class="md-nav__link">
        What do humans learn in a double, temporal bisection task Absolute or relative stimulus durations   20.06.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Wikipedia%20-%20Adiabatic%20process%20-%2022.06.22/" class="md-nav__link">
        Wikipedia   Adiabatic process   22.06.22
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4_1_4" id="__nav_4_1_4_label" tabindex="0">
          MD webclips
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_1_4">
          <span class="md-nav__icon md-icon"></span>
          MD webclips
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_4_1" >
      
      
      
        <label class="md-nav__link" for="__nav_4_1_4_1" id="__nav_4_1_4_1_label" tabindex="0">
          MD Clips New
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_1_4_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_1_4_1">
          <span class="md-nav__icon md-icon"></span>
          MD Clips New
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../MD_webclips/MD_Clips_New/Surrogate%20gradients%20for%20analog%20neuromorphic%20computing%20-%2006.12.22/" class="md-nav__link">
        Surrogate gradients for analog neuromorphic computing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../MD_webclips/MD_Clips_New/What%20is%20the%20Difference%20Between%20Gradient%20Descent%20and%20Gradient%20Ascent%20-%2012.01.23/" class="md-nav__link">
        What is the Difference Between Gradient Descent and Gradient Ascent?
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_5" >
      
      
      
        <label class="md-nav__link" for="__nav_4_1_5" id="__nav_4_1_5_label" tabindex="0">
          Markdown Clips
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_1_5">
          <span class="md-nav__icon md-icon"></span>
          Markdown Clips
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips/A%20Gentle%20Introduction%20to%20Cross-Entropy%20for%20Machine%20Learning%20-%20MachineLearningMastery.com%20-%2008.02.23.md/" class="md-nav__link">
        A Gentle Introduction to Cross-Entropy for Machine Learning - MachineLearningMastery.com
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips/Human-level%20control%20through%20deep%20reinforcement%20learning%20-%2020.02.23.md/" class="md-nav__link">
        Human-level control through deep reinforcement learning
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_6" >
      
      
      
        <label class="md-nav__link" for="__nav_4_1_6" id="__nav_4_1_6_label" tabindex="0">
          Markdown Clips old
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_1_6">
          <span class="md-nav__icon md-icon"></span>
          Markdown Clips old
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/A%20model%20for%20the%20peak-interval%20task%20based%20on%20neural%20oscillation-delimited%20states%20-%2017.11.22.md/" class="md-nav__link">
        A model for the peak-interval task based on neural oscillation-delimited states
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/A%20single%20mechanism%20account%20of%20duration%20and%20rate%20processing%20via%20the%20pacemaker-accumulator%20and%20beat%20frequency%20models%20-%2016.11.22.md/" class="md-nav__link">
        A single mechanism account of duration and rate processing via the pacemaker-accumulator and beat frequency models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/Beyond%20STDP%20%E2%80%94%20towards%20diverse%20and%20functionally%20relevant%20plasticity%20rules%20-%2012.10.22/" class="md-nav__link">
        Beyond STDP — towards diverse and functionally relevant plasticity rules
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/Geometric%20foundations%20of%20Deep%20Learning%20-%20Towards%20Data%20Science%20-%2006.10.22/" class="md-nav__link">
        Geometric foundations of Deep Learning - Towards Data Science
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/Grid-graph%20modeling%20of%20emergent%20neuromorphic%20dynamics%20and%20heterosynaptic%20plasticity%20in%20memristive%20nanonetworks%20-%2007.10.22/" class="md-nav__link">
        Grid-graph modeling of emergent neuromorphic dynamics and heterosynaptic plasticity in memristive nanonetworks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/How%20critical%20is%20brain%20criticality%20-%20%20Original/" class="md-nav__link">
        How critical is brain criticality?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/How%20critical%20is%20brain%20criticality%20-%2020.10.22/" class="md-nav__link">
        How critical is brain criticality?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/How%20critical%20is%20brain%20criticality%20-%2022.10.22/" class="md-nav__link">
        How critical is brain criticality?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/Modularity%20and%20multitasking%20in%20neuro-memristive%20reservoir%20networks%20-%2007.10.22/" class="md-nav__link">
        Modularity and multitasking in neuro-memristive reservoir networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/Oscillatory%20multiplexing%20of%20neural%20population%20codes%20for%20interval%20timing%20and%20working%20memory%20-%2021.11.22.md/" class="md-nav__link">
        Oscillatory multiplexing of neural population codes for interval timing and working memory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/The%20Persistence%20of%20Memory%20How%20the%20Brain%20Encodes%20Time%20in%20Memory%20-%2021.11.22.md/" class="md-nav__link">
        The Persistence of Memory: How the Brain Encodes Time in Memory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/Timing%20Intervals%20Using%20Population%20Synchrony%20and%20Spike%20Timing%20Dependent%20Plasticity%20-%2017.11.22.md/" class="md-nav__link">
        Timing Intervals Using Population Synchrony and Spike Timing Dependent Plasticity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Markdown%20Clips_old/Weighted%20Majority%20Algorithm%20-%20A%20beautiful%20algorithm%20for%20Learning%20from%20Experts/" class="md-nav__link">
        Weighted Majority Algorithm: A beautiful algorithm for Learning from Experts
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
      
      
      
        <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
          Pages
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          Pages
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Apical%20Dendrite/" class="md-nav__link">
        Apical Dendrite
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Echo%20State%20Networks/" class="md-nav__link">
        Echo State Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Grid%20Cell%20-%20Time%20Cell%20Interactions/" class="md-nav__link">
        Statement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Hierarchical%20Reinforcement%20Learning/" class="md-nav__link">
        Hierarchical Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Legendre%20Memory%20Unit%20%28LMU%29/" class="md-nav__link">
        Legendre Memory Unit (LMU)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Liquid%20State%20Machine/" class="md-nav__link">
        Liquid State Machine
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Recurrent%20Neural%20Network%20%28RNN%29/" class="md-nav__link">
        Nomenclature around degree of recurrence or moment
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Reservoir%20Computing/" class="md-nav__link">
        Reservoir Computing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Spiking%20Neural%20Networks%20%28SNN%29/" class="md-nav__link">
        Spiking Neural Networks (SNN)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Striatal%20Beat%20Frequency%20Model/" class="md-nav__link">
        Striatal Beat Frequency Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Striatal%20Beat%20Frequency/" class="md-nav__link">
        Striatal Beat Frequency
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pages/Three-Factor%20Learning%20Rule/" class="md-nav__link">
        Search
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
      
      
      
        <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
          People
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          People
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../people/Anna%20Levina/" class="md-nav__link">
        Anna Levina
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../people/Friedemann%20Zenke/" class="md-nav__link">
        Friedemann Zenke
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../people/Jan%20Tore%20L%C3%B8nning/" class="md-nav__link">
        Jan Tore Lønning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../people/Jeffrey%20Allan%20Lugowe/" class="md-nav__link">
        Jeffrey Allan Lugowe
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../people/Kai%20Olav%20Ellefsen/" class="md-nav__link">
        Kai Olav Ellefsen
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../people/Katalin%20Vertes/" class="md-nav__link">
        Katalin Vertes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../people/Klas%20Henning%20Pettersen/" class="md-nav__link">
        Klas Henning Pettersen
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../people/Sven%20Peter%20N%C3%A4sholm/" class="md-nav__link">
        Sven Peter Näsholm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../people/people/" class="md-nav__link">
        In this folder
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
          Topics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          Topics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/ADAM%20Optimizer/" class="md-nav__link">
        ADAM Optimizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Adiabatic%20Process/" class="md-nav__link">
        Adiabatic Process
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Bellman%20Equation/" class="md-nav__link">
        From [[HF DRL - Unit 2]]
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Chaos/" class="md-nav__link">
        Chaos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Complexity/" class="md-nav__link">
        Reading
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Continuous%20Markov%20Decision%20Process/" class="md-nav__link">
        Continuous Markov Decision Process
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Convolutional%20Neural%20Network%20%28CNN%29/" class="md-nav__link">
        Convolutional Neural Network (CNN)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Cortico-basal%20ganglia-thalamo-cortical%20loop/" class="md-nav__link">
        Cortico basal ganglia thalamo cortical loop
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Credit%20Assignment%20Problem/" class="md-nav__link">
        Credit Assignment Problem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Criticality/" class="md-nav__link">
        Criticality
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Cross%20Entropy/" class="md-nav__link">
        Cross Entropy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Deep%20Q-Learning/" class="md-nav__link">
        Deep Q Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Double%20DQN/" class="md-nav__link">
        Double DQN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Dyna-Q/" class="md-nav__link">
        Dyna Q
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Echo%20State%20Property%20%28ESP%29/" class="md-nav__link">
        Echo State Property (ESP)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Eligibility%20Trace/" class="md-nav__link">
        Commentary
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/End-to-End%20Reinforcement-Learning/" class="md-nav__link">
        End to End Reinforcement Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Epsilon%20Decay/" class="md-nav__link">
        ϵ-Decay Strategies
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Ergodicity/" class="md-nav__link">
        Ergodicity / Ergodic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Excitatory%20-%20Inhibitory%20Oscillation%20%28EIO-SBF%29/" class="md-nav__link">
        Excitatory   Inhibitory Oscillation (EIO SBF)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Excitatory%20-%20Inhibitory%20postsynaptic%20potential%20%28EPSP%29%20-%20%28IPSP%29/" class="md-nav__link">
        Excitatory   Inhibitory postsynaptic potential (EPSP)   (IPSP)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Firing-Rate%20RNN%20Model/" class="md-nav__link">
        Firing Rate RNN Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Fixed%20Interval%20%28FI%29%20procedure/" class="md-nav__link">
        Main
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Geometric%20Deep%20Learning/" class="md-nav__link">
        Geometric Deep Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Impairment%20effect/" class="md-nav__link">
        Impairment effect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Interval%20Timing/" class="md-nav__link">
        Interval Timing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Izhikevich%20%20simple%20spiking%20neurons/" class="md-nav__link">
        Izhikevich  simple spiking neurons
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Kernel/" class="md-nav__link">
        Kernel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/L2-Norm/" class="md-nav__link">
        L2 Norm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Leaky%20Integrate-and-Fire/" class="md-nav__link">
        Leaky Integrate and Fire
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Long%20Short-Term%20Memory%20%28LSTM%29/" class="md-nav__link">
        Long Short Term Memory (LSTM)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Marr%E2%80%99s%20three%20levels%20of%20analysis/" class="md-nav__link">
        Marr’s three levels of analysis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Membrane%20Time%20Constant/" class="md-nav__link">
        Membrane Time Constant
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Multi-Armed%20Bandit%20Problem/" class="md-nav__link">
        Multi Armed Bandit Problem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Multiplicative%20Weights%20Update%20Algorithm/" class="md-nav__link">
        About
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Neural%20Cellular%20Automata/" class="md-nav__link">
        Neural Cellular Automata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Neural%20Oscillations/" class="md-nav__link">
        Gamma
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Neuromorphics/" class="md-nav__link">
        Neuromorphics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Neuroscientific%20AI/" class="md-nav__link">
        Neuroscientific AI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Nomenclature%20for%20Experiments/" class="md-nav__link">
        Statement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Novelty%20Signal/" class="md-nav__link">
        Novelty Signal
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Nullcline/" class="md-nav__link">
        Nullcline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/On%20Off%20Policy/" class="md-nav__link">
        On Off Policy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Optuna/" class="md-nav__link">
        Optuna
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Pad%C3%A9%20approximants/" class="md-nav__link">
        Padé approximants
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Pareto%20Optimality/" class="md-nav__link">
        Pareto Optimality
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Peak%20Interval%20%28PI%29%20procedure/" class="md-nav__link">
        Peak Interval (PI) procedure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Physical%20Symbol%20System%20Hypothesis%20%28PSSH%29/" class="md-nav__link">
        Physical Symbol System Hypothesis (PSSH)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Power%20Law%20distribution/" class="md-nav__link">
        Power Law distribution
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Q-Learning%20v.%20SARSA/" class="md-nav__link">
        Q Learning v. SARSA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Q-Learning/" class="md-nav__link">
        Q Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/REINFORCE/" class="md-nav__link">
        REINFORCE
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Randomness%2C%20Disorder%2C%20and%20Noise/" class="md-nav__link">
        Randomness, Disorder, and Noise
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/ReLU/" class="md-nav__link">
        ReLU
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Relevance/" class="md-nav__link">
        Relevance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Reward%20Prediction%20Error/" class="md-nav__link">
        Reward Prediction Error
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/SARSA%20Algorithm/" class="md-nav__link">
        SARSA Algorithm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Scalar%20Expectancy%20Theory/" class="md-nav__link">
        Scalar Expectancy Theory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Semi-Markov%20Decision%20Process%20%28SMDP%29/" class="md-nav__link">
        Semi Markov Decision Process (SMDP)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Separation%20Property/" class="md-nav__link">
        Separation Property
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Softmax/" class="md-nav__link">
        Softmax
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Spike%20Response%20Model%20neuron/" class="md-nav__link">
        Extracts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Stochastic%20Gradient%20Descent/" class="md-nav__link">
        Stochastic Gradient Descent
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Striatal%20Beat%20Frequency%20model%20%28SBF%29/" class="md-nav__link">
        Referenced in:
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Surrogate%20Gradient%20Learning/" class="md-nav__link">
        Surrogate Gradient Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Target%20v%20behavior%20Policy/" class="md-nav__link">
        Target v behavior Policy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Temporal%20Bisection%20Task/" class="md-nav__link">
        Temporal Bisection Task
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Temporal%20Difference%20%28TD%29/" class="md-nav__link">
        Temporal Difference (TD)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Three-Factor%20Learning%20Rule/" class="md-nav__link">
        Three Factor Learning Rule
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Three-Factor%20Learning/" class="md-nav__link">
        Three Factor Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Tigerprop/" class="md-nav__link">
        Tigerprop
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Time%20Invariance/" class="md-nav__link">
        Definition
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Timing%20Tasks/" class="md-nav__link">
        Timing Tasks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Topics%20-%20Striatal%20Beat%20Frequency%20model%20%28SBF%29/" class="md-nav__link">
        Referenced in:
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Vogels-Abbott%20Benchmark/" class="md-nav__link">
        Vogels Abbott Benchmark
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Weber%27s%20Law/" class="md-nav__link">
        (Weber’s law):
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Weighted%20majority%20algorithm/" class="md-nav__link">
        Weighted majority algorithm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/Wilson-Cowan%20rate%20model/" class="md-nav__link">
        Wilson Cowan rate model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/behavior%20theory%20of%20timing%20%28BeT%29/" class="md-nav__link">
        [[@hasegawaModelMultisecondTiming2015|Takayuki Hasegawa, Shogo Sakata 2015]]
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/bias-variance%20trade-off/" class="md-nav__link">
        Bias variance trade off
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/catastrophic%20forgetting/" class="md-nav__link">
        Catastrophic forgetting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/central%20tendency%20effects/" class="md-nav__link">
        Central tendency effects
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/derivative%20log%20trick/" class="md-nav__link">
        Derivative log trick
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/discount%20factor/" class="md-nav__link">
        Discount factor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/e-prop/" class="md-nav__link">
        E prop
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/learned%20embedding/" class="md-nav__link">
        Learned embedding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/local%20plasticity/" class="md-nav__link">
        Local plasticity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/multiple%20clock%20or%20flexible%20clock%20hypothesis/" class="md-nav__link">
        Multiple clock or flexible clock hypothesis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/pacemaker%20accumulator%20models%20%28PA%29/" class="md-nav__link">
        Reading
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/perceptual%20aliasing/" class="md-nav__link">
        Perceptual aliasing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/primitive%20actions/" class="md-nav__link">
        Primitive actions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/rescaling/" class="md-nav__link">
        Rescaling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/stride/" class="md-nav__link">
        Stride
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../topics/temporal%20abstraction/" class="md-nav__link">
        Temporal abstraction
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          AZ. Assets
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          AZ. Assets
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../AZ.%20Assets/Outline%20or%20Goals%20Draft/" class="md-nav__link">
        Outline or Goals Draft
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          Features
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Features
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../Features/LaTeX%20Math%20Support/" class="md-nav__link">
        LaTeX Math Support
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../Features/Mermaid%20Diagrams/" class="md-nav__link">
        Mermaid diagrams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../Features/Text%20Formatting/" class="md-nav__link">
        Text Formatting
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
      
      
      
        <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
          Topic 1
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Topic 1
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../Topic%201/Note%201/" class="md-nav__link">
        Note 1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../Topic%201/Note%202/" class="md-nav__link">
        Note 2
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#abstract" class="md-nav__link">
    Abstract
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    Introduction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    Results
  </a>
  
    <nav class="md-nav" aria-label="Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trained-rnns-perform-a-sensorimotor-spoken-to-handwritten-digit-transcription-task" class="md-nav__link">
    Trained RNNs perform a sensorimotor spoken-to-handwritten digit transcription task
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a-trained-rnn-performs-the-sensorimotor-spoken-to-handwritten-digit-transcription-task-on-novel-utterances" class="md-nav__link">
    A trained RNN performs the sensorimotor spoken-to-handwritten digit transcription task on novel utterances.
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stability-of-the-neural-trajectories" class="md-nav__link">
    Stability of the neural trajectories
  </a>
  
    <nav class="md-nav" aria-label="Stability of the neural trajectories">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#digit-transcription-is-robust-to-perturbations-during-the-sensory-and-motor-epochs" class="md-nav__link">
    Digit transcription is robust to perturbations during the sensory and motor epochs.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-training-sculpts-network-dynamics-to-enhance-discrimination" class="md-nav__link">
    RNN training sculpts network dynamics to enhance discrimination
  </a>
  
    <nav class="md-nav" aria-label="RNN training sculpts network dynamics to enhance discrimination">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trained-rnns-generate-convergent-continuous-neural-trajectories-in-response-to-different-instances-of-the-same-spatiotemporal-object" class="md-nav__link">
    Trained RNNs generate convergent continuous neural trajectories in response to different instances of the same spatiotemporal object.
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trained-rnns-encode-both-sensory-and-motor-objects-as-well-separated-neural-trajectories" class="md-nav__link">
    Trained RNNs encode both sensory and motor objects as well separated neural trajectories.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#balance-between-recurrent-and-input-dynamics-is-crucial-for-discrimination" class="md-nav__link">
    Balance between recurrent and input dynamics is crucial for discrimination
  </a>
  
    <nav class="md-nav" aria-label="Balance between recurrent and input dynamics is crucial for discrimination">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trajectory-separation-in-reservoir-and-trained-rnns-as-a-function-of-input-amplitude" class="md-nav__link">
    Trajectory separation in reservoir and trained RNNs as a function of input amplitude.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mechanisms-underlying-spatial-spectral-generalization" class="md-nav__link">
    Mechanisms underlying spatial (Spectral) Generalization
  </a>
  
    <nav class="md-nav" aria-label="Mechanisms underlying spatial (Spectral) Generalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#robustness-to-spectral-noise-depends-on-the-spatiotemporal-structure-of-the-inputs-that-the-network-is-exposed-to-during-training" class="md-nav__link">
    Robustness to spectral noise depends on the spatiotemporal structure of the inputs that the network is exposed to during training.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoding-stimuli-as-neural-trajectories-allows-for-temporal-generalization-scaling" class="md-nav__link">
    Encoding stimuli as neural trajectories allows for temporal generalization (Scaling)
  </a>
  
    <nav class="md-nav" aria-label="Encoding stimuli as neural trajectories allows for temporal generalization (Scaling)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#invariance-of-encoding-trajectories-to-temporally-warped-spoken-digits" class="md-nav__link">
    Invariance of encoding trajectories to temporally warped spoken digits.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mechanisms-underlying-temporal-generalization-temporal-scaling" class="md-nav__link">
    Mechanisms underlying temporal generalization (temporal scaling)
  </a>
  
    <nav class="md-nav" aria-label="Mechanisms underlying temporal generalization (temporal scaling)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mechanism-of-temporal-scaling-invariance" class="md-nav__link">
    Mechanism of temporal scaling invariance.
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#discussion" class="md-nav__link">
    Discussion
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#materials-and-methods" class="md-nav__link">
    Materials and methods
  </a>
  
    <nav class="md-nav" aria-label="Materials and methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#network-model" class="md-nav__link">
    Network model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#simulations-and-training" class="md-nav__link">
    Simulations and training
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#input-structure" class="md-nav__link">
    Input structure
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#innate-trajectories-and-rnn-training" class="md-nav__link">
    Innate trajectories and RNN training
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-training" class="md-nav__link">
    Output training
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-descent-training" class="md-nav__link">
    Gradient descent training
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trajectory-analysis" class="md-nav__link">
    Trajectory analysis
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rnn-decomposition" class="md-nav__link">
    RNN decomposition
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#analysis-of-parallel-trajectories" class="md-nav__link">
    Analysis of parallel trajectories
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trajectory-visualization" class="md-nav__link">
    Trajectory visualization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#source-code" class="md-nav__link">
    Source code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decision-letter" class="md-nav__link">
    Decision letter
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#author-response" class="md-nav__link">
    Author response
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#article-and-author-information" class="md-nav__link">
    Article and author information
  </a>
  
    <nav class="md-nav" aria-label="Article and author information">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#author-details" class="md-nav__link">
    Author details
  </a>
  
    <nav class="md-nav" aria-label="Author details">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dean-v-buonomano" class="md-nav__link">
    Dean V Buonomano
  </a>
  
    <nav class="md-nav" aria-label="Dean V Buonomano">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contribution" class="md-nav__link">
    Contribution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-correspondence" class="md-nav__link">
    For correspondence
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#competing-interests" class="md-nav__link">
    Competing interests
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#funding" class="md-nav__link">
    Funding
  </a>
  
    <nav class="md-nav" aria-label="Funding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#national-science-foundation-nsf-iis-1420897" class="md-nav__link">
    National Science Foundation (NSF IIS-1420897)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#google-google-faculty-research-award" class="md-nav__link">
    Google (Google Faculty Research Award)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#national-institutes-of-health-mh60163" class="md-nav__link">
    National Institutes of Health (MH60163)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#acknowledgements" class="md-nav__link">
    Acknowledgements
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reviewing-editor" class="md-nav__link">
    Reviewing Editor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#publication-history" class="md-nav__link">
    Publication history
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#copyright" class="md-nav__link">
    Copyright
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#metrics" class="md-nav__link">
    Metrics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#download-links" class="md-nav__link">
    Download links
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>Encoding sensory and motor patterns as time invariant trajectories in recurrent neural networks   20.07.22</h1>

<p><a href="../../../../50%20Reading/zot2/%40goudarEncodingSensoryMotor2018/">@goudarEncodingSensoryMotor2018</a></p>
<blockquote>
<p>[!Excerpt] Encoding sensory and motor patterns as time-invariant trajectories in recurrent neural networks | eLife
A recurrent network model trained to transcribe temporally scaled spoken digits into handwritten digits proposes that the brain flexibly encodes time-varying stimuli as neural trajectories that can be traversed at different speeds.</p>
</blockquote>
<hr />
<h2 id="abstract">Abstract<a class="headerlink" href="#abstract" title="Permanent link">&para;</a></h2>
<p>Much of the information the brain processes and stores is temporal in nature—a spoken word or a handwritten signature, for example, is defined by how it unfolds in time. However, it remains unclear how neural circuits encode complex time-varying patterns. We show that by tuning the weights of a recurrent neural network (RNN), it can recognize and then transcribe spoken digits. The model elucidates how neural dynamics in cortical networks may resolve three fundamental challenges: first, encode multiple time-varying sensory <em>and</em> motor patterns as stable neural trajectories; second, generalize across relevant spatial features; third, identify the same stimuli played at different speeds—we show that this temporal invariance emerges because the recurrent dynamics generate neural trajectories with appropriately modulated angular velocities. Together our results generate testable predictions as to how recurrent networks may use different mechanisms to generalize across the relevant spatial and temporal features of complex time-varying stimuli.</p>
<p><a href="https://doi.org/10.7554/eLife.31134.001">https://doi.org/10.7554/eLife.31134.001</a></p>
<p>[</p>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>](https://elifesciences.org/articles/31134#)</p>
<p>Many, if not most, of the tasks the brain performs are inherently temporal in nature: from recognizing and generating complex spatiotemporal patterns—such as a phoneme sequence that composes a word—to creating temporal expectations of when an event will occur (<a href="https://elifesciences.org/articles/31134#bib43">Mauk and Buonomano, 2004</a>; <a href="https://elifesciences.org/articles/31134#bib49">Nobre et al., 2007</a>; <a href="https://elifesciences.org/articles/31134#bib25">Ivry and Schlerf, 2008</a>; <a href="https://elifesciences.org/articles/31134#bib45">Merchant et al., 2013</a>; <a href="https://elifesciences.org/articles/31134#bib24">Hopfield, 2015</a>). In contrast to the representation of an object in a static image, such as a picture of a face, robust decoding and encoding of a time-varying patterns must rely on the spatiotemporal dependencies inherent to the pattern. How does the brain accomplish this? One highly influential theory in neuroscience holds that information is stored as fixed-point attractors that emerge in the dynamic activity of the brain’s recurrently connected circuits (<a href="https://elifesciences.org/articles/31134#bib23">Hopfield, 1982</a>; <a href="https://elifesciences.org/articles/31134#bib22">Hopfield and Tank, 1986</a>; <a href="https://elifesciences.org/articles/31134#bib3">Amit and Brunel, 1997</a>; <a href="https://elifesciences.org/articles/31134#bib66">Wang, 2001</a>). Two limitations of this framework are: (1) It fails to capture the temporal aspect of stored information, thus forcing many computational models to ‘spatialize’ time—that is, they treat the temporal component of time-varying patterns as additional spatial dimensions (<a href="https://elifesciences.org/articles/31134#bib52">Rabiner, 1989</a>; <a href="https://elifesciences.org/articles/31134#bib64">Waibel et al., 1989</a>; <a href="https://elifesciences.org/articles/31134#bib15">Elman, 1990</a>; <a href="https://elifesciences.org/articles/31134#bib21">Hinton et al., 2012</a>; <a href="https://elifesciences.org/articles/31134#bib47">Mnih et al., 2015</a>); (2) it does not capture a fundamental feature of how the brain processes temporal information: temporal invariance. For example, humans readily recognize temporally warped—compressed or dilated—speech or music.</p>
<p>While the mechanisms that underlie the brain’s ability to perform a broad range of spatiotemporal tasks in the sensory and motor domains are not known, there is mounting theoretical and experimental evidence that our ability to tell time on the sub-second scale, and represent time-varying patterns, relies on the inherent <em>continuous</em> dynamics, and computational potential, of recurrent neural networks (<a href="https://elifesciences.org/articles/31134#bib53">Rabinovich et al., 2008</a>; <a href="https://elifesciences.org/articles/31134#bib7">Buonomano and Maass, 2009</a>; <a href="https://elifesciences.org/articles/31134#bib40">Mante et al., 2013</a>; <a href="https://elifesciences.org/articles/31134#bib13">Crowe et al., 2014</a>; <a href="https://elifesciences.org/articles/31134#bib9">Carnevale et al., 2015</a>; <a href="https://elifesciences.org/articles/31134#bib36">Li et al., 2016</a>). This framework alleviates the restrictions imposed by traditional discrete-time or fixed-point attractor models, by relying on the recurrent connections to implicitly maintain an ongoing memory of the pattern. Indeed, recent computational studies have established that by tuning the weights within recurrent neural network (RNN) models, it is possible to <em>robustly</em> store and generate complex time-varying motor patterns (<a href="https://elifesciences.org/articles/31134#bib30">Laje and Buonomano, 2013</a>; <a href="https://elifesciences.org/articles/31134#bib2">Abbott et al., 2016</a>; <a href="https://elifesciences.org/articles/31134#bib57">Rajan et al., 2016</a>). What remains unknown is whether the same approach can be used to robustly discriminate time-varying sensory patterns. Indeed, this poses a challenging problem because in order to effectively process spatiotemporal stimuli the dynamics of an RNN must be sensitive to the relevant spatial and temporal features of the sensory stimuli, while being able to generalize across their natural spatial and temporal variations.</p>
<p>Neuroscientists have typically distinguished between sensory and motor areas; but it is well established that activity in sensory areas is strongly influenced by motor behavior, and that sensory stimuli can modulate activity in motor areas—furthermore, some brain areas are characterized as being sensorimotor (<a href="https://elifesciences.org/articles/31134#bib14">Doupe and Kuhl, 1999</a>; <a href="https://elifesciences.org/articles/31134#bib4">Ayaz et al., 2013</a>; <a href="https://elifesciences.org/articles/31134#bib10">Chang et al., 2013</a>; <a href="https://elifesciences.org/articles/31134#bib58">Schneider and Mooney, 2015</a>; <a href="https://elifesciences.org/articles/31134#bib11">Cheung et al., 2016</a>). Computationally, sensory and motor processing are understood to have disparate requirements—during sensory processing, network dynamics should primarily be driven by the sensory inputs; in contrast, during motor processing neural dynamics should be autonomous and driven primarily by recurrent interactions. It remains unclear how a single network could accomplish both tasks, and couple them when necessary. Indeed, to date, no previous models have shown that the same network can satisfy the requirements for both sensory and motor processing. Here we show that the same RNN can reliably function in both a sensory and motor regime. Specifically the same RNN can convert complex time-varying sensory patterns into motor patterns—thus performing a transcription task in which spoken digits are identified and read out as ‘handwritten’ digits.</p>
<p>In the temporal domain, understanding how the brain recognizes temporally compressed or dilated patterns represents a long-standing challenge. This temporal invariance is particularly evident in our ability to recognize temporally warped speech or music (<a href="https://elifesciences.org/articles/31134#bib46">Miller et al., 1984</a>; <a href="https://elifesciences.org/articles/31134#bib59">Sebastián-Gallés et al., 2000</a>). Our results suggest that one advantage of storing time-varying patterns as neural trajectories within RNNs is that, under the appropriate conditions, this strategy naturally accounts for temporal invariance.</p>
<p>[</p>
<h2 id="results">Results<a class="headerlink" href="#results" title="Permanent link">&para;</a></h2>
<p>](https://elifesciences.org/articles/31134#)</p>
<p>We first asked if a single RNN could perform a complex sensory-motor task: transcribing spoken digits into handwritten digits. A <em>continuous-time</em> firing-rate RNN with randomly assigned sparse recurrent connections was used (<a href="https://elifesciences.org/articles/31134#bib60">Sompolinsky et al., 1988</a>). The strengths of these recurrent connections were initialized to be relatively strong; thus, before training the network was in a so-called high-gain regime (<em>g</em> = 1.6) that is characterized by self-perpetuating and chaotic activity (Materials and Methods). The transcription task is divided into a sensory and a motor epoch. During the sensory epoch, the RNN is presented with a spoken digit, and over the ensuing motor epoch the RNN drives an output pattern transcribing the presented digit via three motor outputs <em>x</em>, <em>y</em>, and <em>z</em>—activity in the <em>x</em> and <em>y</em> units determines the 2D coordinates of a ‘pen on paper’, while <em>z</em> determines if the ‘pen’ is in contact with the ‘paper’ or not. <a href="https://elifesciences.org/articles/31134#fig1">Figure 1A</a> illustrates the network architecture and transcription task for the digit ‘2’. Successful performance of this transcription task requires that the RNN: 1) encode spoken digits with a set of neural trajectories in high-dimensional phase space; 2) autonomously generate digit-specific trajectories during the motor epoch, in order to drive the digit-specific output patterns; and most importantly 3) generate trajectories that are stable so they may encode each digit’s sensory pattern, sensory-motor transition, and motor pattern in a manner that is invariant not just to background noise but also to spatiotemporal variations of the spoken digits, including temporal warping.</p>
<p><a href="https://iiif.elifesciences.org/lax/31134%2Felife-31134-fig1-v1.tif/full/,1500/0/default.jpg"><img alt="70 Wiki/articles/MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.jpg" src="../MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.jpg" /></a></p>
<h6 id="trained-rnns-perform-a-sensorimotor-spoken-to-handwritten-digit-transcription-task">Trained RNNs perform a sensorimotor spoken-to-handwritten digit transcription task<a class="headerlink" href="#trained-rnns-perform-a-sensorimotor-spoken-to-handwritten-digit-transcription-task" title="Permanent link">&para;</a></h6>
<p>(<strong>A</strong>) Transcription task. The spectrogram of a spoken digit, e.g. ‘two’, is transformed to a 12-channel cochleogram that serves as the continuous-time input to a RNN during the sensory epoch of each …</p>
<p><a href="https://doi.org/10.7554/eLife.31134.002">https://doi.org/10.7554/eLife.31134.002</a></p>
<p><img alt="70 Wiki/articles/MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.1.jpg" src="../MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.1.jpg" /></p>
<p>This video cannot be played in place because your browser does support HTML5 video. You may still download the video for offline viewing.  </p>
<h6 id="a-trained-rnn-performs-the-sensorimotor-spoken-to-handwritten-digit-transcription-task-on-novel-utterances">A trained RNN performs the sensorimotor spoken-to-handwritten digit transcription task on novel utterances.<a class="headerlink" href="#a-trained-rnn-performs-the-sensorimotor-spoken-to-handwritten-digit-transcription-task-on-novel-utterances" title="Permanent link">&para;</a></h6>
<p>A trained RNN (N = 4000) and its output units perform the transcription task on five novel utterances (five different speakers). The last two utterances illustrate RNN performance on same-digit …</p>
<p><a href="https://doi.org/10.7554/eLife.31134.004">https://doi.org/10.7554/eLife.31134.004</a></p>
<p>We attempted to satisfy these three conditions by training the RNN using a supervised learning rule, in which the recurrent units were trained to robustly reproduce their ‘innate’ patterns of activity (<a href="https://elifesciences.org/articles/31134#bib30">Laje and Buonomano, 2013</a>)—that is, those generated in the untrained network—using the recursive-least-squares learning rule (<a href="https://elifesciences.org/articles/31134#bib20">Haykin, 2002</a>; <a href="https://elifesciences.org/articles/31134#bib61">Sussillo and Abbott, 2009</a>). In essence, the RNN is trained to reproduce one digit-specific ‘innate’ trajectory in response to all training utterances of a given digit. For example, the pattern of activity produced in response to a ‘template’ utterance of a given digit from the beginning of the sensory epoch to the end of the motor epoch is taken as the innate trajectory; the network is then trained to reproduce this trajectory in response to other utterances of the same digit. Furthermore, it is trained to do so regardless of the initial state of the network’s units, and in the presence of continuous background noise (Materials and Methods). Only after training the RNN (<em>recurrent training</em>), are the output units trained to generate the handwriting patterns representing each of the digits during the motor epoch (<em>output training</em>)—this separation of the recurrent and output training phases, while not necessary, allows for rapid training and retraining of the outputs to produce arbitrary motor patterns, without retraining the recurrent weights. Notably, the temporal separation of sensory and motor learning is observed in some forms of sensori-motor learning (<a href="https://elifesciences.org/articles/31134#bib14">Doupe and Kuhl, 1999</a>). The output training phase is performed using standard supervised methods (Materials and Methods). <a href="https://elifesciences.org/articles/31134#fig1">Figure 1B</a> shows the outputs of a trained network cross-tested on ten digits (0–9) across five speakers. Following training, the network successfully transcribes the utterances used during training (marked by asterisks). More importantly, performance generalizes to novel utterances and speakers in the dataset despite significant variations in the duration and spatiotemporal structure across utterances (<a href="https://elifesciences.org/articles/31134#video1">Video 1</a>).</p>
<p>To quantify performance, we need an objective measure of the quality of the motor output for each test utterance. This itself represents a classification task, wherein images of RNN-generated transcriptions must be assigned to one of the ten possible digits. Rather than use a human-based performance measure, we used a standard deep convolutional neural network (CNN) (<a href="https://elifesciences.org/articles/31134#bib32">LeCun et al., 2015</a>) to rate the performance of trained RNNs (Materials and Methods)—i.e., the CNN was used to determine if each ‘handwritten’ digit was correct or not. Performance of trained RNNs was 98.7% on a test set of 410 novel stimuli (<a href="https://elifesciences.org/articles/31134#fig1">Figure 1C</a>). Since untrained RNNs (‘reservoir networks’) are in and of themselves capable of performing many interesting computations (<a href="https://elifesciences.org/articles/31134#bib39">Maass et al., 2002</a>; <a href="https://elifesciences.org/articles/31134#bib26">Jaeger and Haas, 2004</a>; <a href="https://elifesciences.org/articles/31134#bib37">Lukoševičius and Jaeger, 2009</a>), it is important to determine how much of this performance is dependent on the training of the RNNs. We thus examined a control group wherein the three output units are trained as they were for the trained RNNs, but the RNN itself was not trained (the ‘reservoir’). The performance was very poor (20%), in large part because during the motor epoch a reservoir RNN is operating in an autonomous mode that is chaotic—making it difficult for the output units to learn to produce the target output patterns. We also examined the effects of training an RNN only during the motor epoch, resulting in a performance of 71%. This significant improvement over the reservoir networks is a consequence of the fact that a network driven by external inputs can encode sensory stimuli despite a lack of sensory epoch training, due to the intrinsic ability of RNNs to encode sensory stimuli and the stabilizing influence of the external inputs (see below). Yet, despite the improvement in performance, some digits were almost always misclassified (<a href="https://elifesciences.org/articles/31134/figures#fig1s1">Figure 1—figure supplement 1</a>). The difference in performance between the trained RNNs (sensory and motor training) and the exclusively motor trained RNNs, confirms the importance of tuning the recurrent weights to the sensory discrimination component of the task (see below).</p>
<h3 id="stability-of-the-neural-trajectories">Stability of the neural trajectories<a class="headerlink" href="#stability-of-the-neural-trajectories" title="Permanent link">&para;</a></h3>
<p>RNNs operating in high-gain regimes are prone to chaotic behavior (<a href="https://elifesciences.org/articles/31134#bib60">Sompolinsky et al., 1988</a>; <a href="https://elifesciences.org/articles/31134#bib55">Rajan et al., 2010a</a>) because the strong recurrent feedback of these networks rapidly amplifies any noise or perturbations. It is thus critical to demonstrate that the above performance is robust to background noise and perturbations during the sensory and motor epochs. The distinction between epochs is critical since the RNN is operating in fundamentally different regimes during the sensory and motor epochs. During the sensory epoch the recurrently generated internal dynamics are partially suppressed (or ‘clamped’) as a result of the external input, yet during the motor epoch all activity is internally generated. To examine the stability of these sensory and motor ‘object’ representations, we briefly perturbed the internal dynamics of the RNN during either the sensory or motor epochs. Sensory epoch perturbations were introduced half way through the presentation of each utterance, while motor epoch perturbations were introduced at the 10% mark of the motor epoch. <a href="https://elifesciences.org/articles/31134#fig2">Figure 2A</a> shows the activity of a hundred units from a trained RNN (and the resulting output), when it is presented with the digit ‘three’ and strongly perturbed (amplitude = 2) in the motor epoch. The resulting transcription briefly deviates from an unperturbed one (grey backdrop), but recovers mid-voyage. The sensory epoch is less sensitive to perturbations—as would be expected because the presence of the external input serves as a stabilizing influence (<a href="https://elifesciences.org/articles/31134#bib55">Rajan et al., 2010a</a>). During the motor epoch the RNN is operating autonomously as a ‘dynamic attractor’, that is, once bumped off its trajectory it maintains a memory of its current voyage and is able to return to the original trajectory (<a href="https://elifesciences.org/articles/31134#bib30">Laje and Buonomano, 2013</a>) (<a href="https://elifesciences.org/articles/31134#fig2">Figure 2B</a>). Performance measurements using the CNN classifier reveal a graceful degradation across a wide range of perturbation magnitudes, and confirm the superior robustness of the sensory epoch (<a href="https://elifesciences.org/articles/31134#fig2">Figure 2C</a>).</p>
<p><a href="https://iiif.elifesciences.org/lax/31134%2Felife-31134-fig2-v1.tif/full/,1500/0/default.jpg"><img alt="70 Wiki/articles/MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.2.jpg" src="../MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.2.jpg" /></a></p>
<h6 id="digit-transcription-is-robust-to-perturbations-during-the-sensory-and-motor-epochs">Digit transcription is robust to perturbations during the sensory and motor epochs.<a class="headerlink" href="#digit-transcription-is-robust-to-perturbations-during-the-sensory-and-motor-epochs" title="Permanent link">&para;</a></h6>
<p>(<strong>A</strong>) Schematic of a perturbation experiment. The motor trajectory of a trained RNN (<em>N</em> = 2100; 100 sample units shown) for the spoken digit ‘three’, is perturbed with a 25 ms pulse (amplitude = 2). …</p>
<p><a href="https://doi.org/10.7554/eLife.31134.005">https://doi.org/10.7554/eLife.31134.005</a></p>
<h3 id="rnn-training-sculpts-network-dynamics-to-enhance-discrimination">RNN training sculpts network dynamics to enhance discrimination<a class="headerlink" href="#rnn-training-sculpts-network-dynamics-to-enhance-discrimination" title="Permanent link">&para;</a></h3>
<p>How does tuning the recurrent weights allow the RNN to stably encode both sensory and motor information in neural trajectories, despite considerable spatiotemporal differences between digit utterances (<a href="https://elifesciences.org/articles/31134#fig1">Figure 1B</a>, insets)? Firing rate traces of sample units in a trained RNN show more similar patterns of activity in response to different utterances of the same digit, when compared to a reservoir RNN (<a href="https://elifesciences.org/articles/31134#fig3">Figure 3A–B</a>). To better examine the structure of the population representations, we can visualize and compare the neural trajectories in response to multiple utterances (learned and novel) of the same digit, during the sensory and motor epochs, in principal component analysis (PCA) subspace. The trajectories produced in the untrained network by utterances of the digits ‘six’ and ‘eight’, during the sensory epoch, occupied a fairly large abutting volume of PCA subspace (<a href="https://elifesciences.org/articles/31134#fig3">Figure 3C</a>); and during the motor epoch the trajectories were highly variable—the network strongly and perpetually amplifies the differences between utterances, because it is in a chaotic regime. In contrast, in the trained RNN, sensory epoch trajectories of each digit were restricted to a narrower volume, and better separated from the volume representing the other digit (<a href="https://elifesciences.org/articles/31134#fig3">Figure 3D</a>). During the motor epoch, the trajectories for different utterances of the same digit were constrained to a much narrower tube—reflecting the dynamic attractor—and better separated from the motor trajectories of the other digit. The set of all within-digit trajectories can be thought of as populating a hypertube that delimits the volume of phase space traversed by the digit. During the sensory epoch, this hypertube of trajectories represents a memory of a family of related spatiotemporal objects: the spoken digit. During the motor epoch the network is autonomous, and the hypertube of all within-digit trajectories narrows to a dynamic attractor that represents the ‘motor memory’ of the corresponding handwritten digit.</p>
<p><a href="https://iiif.elifesciences.org/lax/31134%2Felife-31134-fig3-v1.tif/full/,1500/0/default.jpg"><img alt="70 Wiki/articles/MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.3.jpg" src="../MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.3.jpg" /></a></p>
<h6 id="trained-rnns-generate-convergent-continuous-neural-trajectories-in-response-to-different-instances-of-the-same-spatiotemporal-object">Trained RNNs generate convergent continuous neural trajectories in response to different instances of the same spatiotemporal object.<a class="headerlink" href="#trained-rnns-generate-convergent-continuous-neural-trajectories-in-response-to-different-instances-of-the-same-spatiotemporal-object" title="Permanent link">&para;</a></h6>
<p>(<strong>A–B</strong>) Neural activity patterns of three sample units of a reservoir (<strong>A</strong>) and trained (<strong>B</strong>) network, in response to a trained and a novel utterance each of the digits ‘six’ (red traces) and ‘eight’ …</p>
<p><a href="https://doi.org/10.7554/eLife.31134.006">https://doi.org/10.7554/eLife.31134.006</a></p>
<p>It is well established that cortical circuits undergo experience-dependent plasticity—a process that seems to result in the optimization or specialization of those circuits to the tasks the animal is exposed to (<a href="https://elifesciences.org/articles/31134#bib8">Buonomano and Merzenich, 1998</a>; <a href="https://elifesciences.org/articles/31134#bib12">Crist et al., 2001</a>; <a href="https://elifesciences.org/articles/31134#bib16">Feldman and Brecht, 2005</a>; <a href="https://elifesciences.org/articles/31134#bib28">Karmarkar and Dan, 2006</a>). The above results establish that training the RNN does improve discrimination performance—the recurrent weights are tuned to the task at hand—but leaves open the question of how exactly this is accomplished. To answer this question, we asked if the Euclidean distances between trajectories in response to different utterances of the same digit (within-digit distance), and utterances of different digits (between-digit distance), were significantly altered in comparison to the reservoir (untrained) RNN. Training significantly decreases the mean within-digit distances during the sensory epoch (<a href="https://elifesciences.org/articles/31134#fig4">Figure 4A</a>). Importantly, in doing so, it does not diminish the large separations between trajectories of different digits. The same effect, much enhanced, is observed during the motor epoch, a consequence of the formation of dynamic attractors. Successful formation of these attractors is strongly influenced by an unambiguous and stable sensory epoch-motor epoch transition of the network dynamics. Such a transition relies on two factors: (i) a low within-digit separation at the end of the sensory epoch trajectory, ensuring initial conditions at the beginning of the motor epoch that lie within the initial basin of attraction of the motor pattern-encoding dynamic attractor; (ii) a between-digit separation that is substantially larger than the within-digit separation of sensory epoch trajectories, particularly at the end of the sensory epoch, to ensure robust and divergent sensory-epoch-motor epoch transitions for different digits.</p>
<p><a href="https://iiif.elifesciences.org/lax/31134%2Felife-31134-fig4-v1.tif/full/1500,/0/default.jpg"><img alt="70 Wiki/articles/MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.4.jpg" src="../MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.4.jpg" /></a></p>
<h6 id="trained-rnns-encode-both-sensory-and-motor-objects-as-well-separated-neural-trajectories">Trained RNNs encode both sensory and motor objects as well separated neural trajectories.<a class="headerlink" href="#trained-rnns-encode-both-sensory-and-motor-objects-as-well-separated-neural-trajectories" title="Permanent link">&para;</a></h6>
<p>(<strong>A</strong>) Euclidean distance between trajectories of the same digit (within-digit) versus those of different digits (between-digit). At each time step, the trajectory distances represent the mean and SD …</p>
<p><a href="https://doi.org/10.7554/eLife.31134.007">https://doi.org/10.7554/eLife.31134.007</a></p>
<p>The finding that training sculpts the dynamics of the RNN during the sensory epoch is also a critical one because it shows that even though RNN activity is governed in part by the external input, the internal connections are critical: tuning them effectively improves the interaction between the sensory input and the internally generated dynamics. This improvement is expressed as a collapsing of the family of trajectories representing a digit into a narrower hypertube. These results follow as a direct consequence of the supervised recurrent training paradigm (Materials and Methods)—a single innate trajectory serves as a common target for different training utterances of a digit, thereby inducing changes in the network’s recurrent dynamics that are necessary to encode the different utterances along similar neural trajectories; However, different digits are encoded in rapidly divergent trajectories because the target trajectories for each digit are generated by an untrained chaotic network. Further evidence that training dramatically influences the weight matrix of the RNN is demonstrated by the change in its eigenspectrum (<a href="https://elifesciences.org/articles/31134#fig4">Figure 4B</a>). Because the network is initialized with normally distributed weights with a gain of 1.6 (Materials and Methods), the eigenspectrum of the reservoir’s weight matrix lies in a circle of radius approximately 1.6. Training results in a compression of those eigenvalues with real part larger than one, bringing the maximal real part of the eigenvalues closer to one. In a linear network, when all eigenvalues have a real part less than one, it implies that the network’s activity will decay to zero when it operates autonomously; however our network is nonlinear and does not operate exclusively in the autonomous mode, so interpretations of the eigenspectrum of the weight matrix are not straightforward—nevertheless the compression of the eigenspectrum is consistent with the increased stability of the network during the sensory and motor epochs (<a href="https://elifesciences.org/articles/31134#bib56">Rajan and Abbott, 2006</a>; <a href="https://elifesciences.org/articles/31134#bib50">Ostojic, 2014</a>).</p>
<h3 id="balance-between-recurrent-and-input-dynamics-is-crucial-for-discrimination">Balance between recurrent and input dynamics is crucial for discrimination<a class="headerlink" href="#balance-between-recurrent-and-input-dynamics-is-crucial-for-discrimination" title="Permanent link">&para;</a></h3>
<p>The above results provide insights as to how a single neural circuit can function in two seemingly distinct computational modes: sensory and motor. Sensory discrimination requires circuits to be highly responsive to external stimuli in order to categorize inputs into discrete classes. In contrast, motor tasks require autonomous generation of spatiotemporal patterns, and thus need the network dynamics to be somewhat resistant to external inputs. In the network described here, this balance depends on the recurrent weights and the magnitude of the external drive.</p>
<p>The recurrent weights must be strong—that is the network must be in a high-gain regime—for two reasons. First, network dynamics in high-gain regimes are high-dimensional (<a href="https://elifesciences.org/articles/31134#bib54">Rajan et al., 2010b</a>), which naturally yields well-separated trajectories for different digits. A goal of training then, is to achieve recurrent suppression of within-digit separation, while retaining the large between-digit separation (<a href="https://elifesciences.org/articles/31134#fig4">Figure 4</a>). Second, as noted earlier, a network operating in a high-gain regime is inherently capable of generating the self-perpetuating activity required in the motor epoch, which is then stabilized by the training procedure. Thus during the sensory epoch, the RNN is operating in a regime that is both sensitive to external input and influenced by strong internal recurrent dynamics. In the motor mode, the RNN operates autonomously, generating locally stable trajectories that serve as a high-dimensional ‘engine’ that drives arbitrary low dimensional output patterns.</p>
<p>The ability of the network to meaningfully process input patterns during the sensory epoch, so that they are easy to discriminate, also depends on the strength of the inputs. To better understand the impact of input amplitude on the encoding trajectories and their discriminability, before and after training, we parametrically varied the input amplitude and studied the resulting RNN dynamics during the sensory epoch. In the reservoir, both within and between-digit distances diminish as the input amplitude increases (<a href="https://elifesciences.org/articles/31134#fig5">Figure 5A</a>, left panel), consistent with a previous study showing that strong inputs can progressively dominate and override the internal dynamics of an RNN (<a href="https://elifesciences.org/articles/31134#bib55">Rajan et al., 2010a</a>). In the extreme, input-dominated regimes effectively void the recurrent weights and render training useless (<a href="https://elifesciences.org/articles/31134#fig5">Figure 5A</a>, right panel). The poor discriminability at high input amplitudes is further confirmed by dimensionality measurements of sensory epoch trajectories (Materials and Methods), which mirror the low-dimensionality of the input cochleograms, regardless of training (<a href="https://elifesciences.org/articles/31134#fig5">Figure 5B</a>). In contrast, low-input amplitude regimes are dominated by the RNN’s internal dynamics. Reservoirs in this regime produce chaotic high-dimensional dynamics and are insufficiently sensitivity to external inputs; thus the within- and between-digit distances are similarly high (<a href="https://elifesciences.org/articles/31134#fig5">Figure 5A</a>, left). Training strongly alters these dynamics, lowering its dimensionality (<a href="https://elifesciences.org/articles/31134#fig5">Figure 5B</a>). However, as a consequence of poor input-sensitivity, these changes fail to improve discrimination—trained RNNs in this regime still sustain similar within and between-digit distances (<a href="https://elifesciences.org/articles/31134#fig5">Figure 5B</a>, right). RNNs trained at intermediate input amplitudes (0.5, 5) are both sensitive to the input and able to discriminate between digits, because their sensory epoch trajectories are shaped both by the input and internal dynamics. It is thus critical that the input drive be strong enough to influence ongoing activity but not strong enough to ‘erase’ recent information encoded in the current trajectory.</p>
<p><a href="https://iiif.elifesciences.org/lax/31134%2Felife-31134-fig5-v1.tif/full/,1500/0/default.jpg"><img alt="70 Wiki/articles/MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.5.jpg" src="../MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.5.jpg" /></a></p>
<h6 id="trajectory-separation-in-reservoir-and-trained-rnns-as-a-function-of-input-amplitude">Trajectory separation in reservoir and trained RNNs as a function of input amplitude.<a class="headerlink" href="#trajectory-separation-in-reservoir-and-trained-rnns-as-a-function-of-input-amplitude" title="Permanent link">&para;</a></h6>
<p>(<strong>A</strong>) Comparison of mean within- and between-digit distances of the sensory epoch trajectories in reservoir and trained networks (N = 2100) at different input amplitudes. Bars represent mean of the …</p>
<p><a href="https://doi.org/10.7554/eLife.31134.008">https://doi.org/10.7554/eLife.31134.008</a></p>
<h3 id="mechanisms-underlying-spatial-spectral-generalization">Mechanisms underlying spatial (Spectral) Generalization<a class="headerlink" href="#mechanisms-underlying-spatial-spectral-generalization" title="Permanent link">&para;</a></h3>
<p>The attracting dynamics of the network result in each digit being represented in a narrow hypertube. These representations must be robust across both spectral and temporal (changes in speed) differences in the utterances of each digit. Next, we separately examine the mechanisms underlying spatial and temporal generalization. Variation in the spectral structure of digits—spectral noise (<a href="https://elifesciences.org/articles/31134#fig6">Figure 6A</a>)—is qualitatively different from background noise. First, spectral noise exhibits time-dependent structured relationships with the input signal (they may be correlated, anti-correlated or tend to occur along specific directions during specific parts of the input). For example, the spectral differences between utterances of one phoneme within a digit will be different than those of another. Invariance then requires the network to isolate and integrate the signal while suppressing signal-dependent spectral noise. Second, spectral noise is a form of correlated noise. The noise in each input channel is simultaneously delivered to multiple recurrent units via common input projections. Moreover, the spectral noise in different channels, particularly neighboring ones, exhibit structured time-dependent relationships. Third, spectral noise is proportional in magnitude to the input amplitude, and therefore tends to be much stronger than the background noise that is typically injected during training and testing.</p>
<p><a href="https://iiif.elifesciences.org/lax/31134%2Felife-31134-fig6-v1.tif/full/,1500/0/default.jpg"><img alt="70 Wiki/articles/MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.6.jpg" src="../MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.6.jpg" /></a></p>
<h6 id="robustness-to-spectral-noise-depends-on-the-spatiotemporal-structure-of-the-inputs-that-the-network-is-exposed-to-during-training">Robustness to spectral noise depends on the spatiotemporal structure of the inputs that the network is exposed to during training.<a class="headerlink" href="#robustness-to-spectral-noise-depends-on-the-spatiotemporal-structure-of-the-inputs-that-the-network-is-exposed-to-during-training" title="Permanent link">&para;</a></h6>
<p>(<strong>A</strong>) Spectral noise in the inputs to an RNN (N = 2100) during presentations of digit zero. Sample noise is the difference between the external input (each row reflects net external input to a unit in …</p>
<p><a href="https://doi.org/10.7554/eLife.31134.009">https://doi.org/10.7554/eLife.31134.009</a></p>
<p>To better characterize how spectral noise invariance emerges during training, we measured network responses while naturally and artificially varying the structure of the spectral noise. Any confounding effects from temporal invariance were avoided by training and testing the network on temporally normalized utterances, by warping them to the duration of the template utterance for the respective digit. Responses to standard natural test utterances (those not presented during training) were contrasted with two types of artificially created utterances: those with shuffled spectral noise and orthogonal spectral noise (<a href="https://elifesciences.org/articles/31134#fig6">Figure 6B</a>). Shuffled spectral noise was created by shuffling the PCA axes (basis) of the spectral noise (Materials and Methods). In other words, novel utterances were generated by reordering the directions of spectral noise in phase space (<a href="https://elifesciences.org/articles/31134#fig6">Figure 6C</a>). This procedure scrambled the relationships between input signal and noise, while constraining the artificial spectral noise to the same subspace as natural spectral noise. Orthogonal spectral noise was composed of linear bases that were orthogonal to natural spectral noise (<a href="https://elifesciences.org/articles/31134#fig6">Figure 6D</a>, see Materials and Methods). In addition to scrambling the input signal-noise relationships, this procedure also scrambled the relationships between input channels. Care was taken while constructing these artificial inputs, to ensure that the temporal structure, dimensionality and magnitude of the spectral noise were identical to that observed in natural utterances.</p>
<p>Measurements of the within-digit trajectory distances revealed a progressive increase from trained utterances, to untrained utterances, to utterances with shuffled noise, to utterances with orthogonal noise (<a href="https://elifesciences.org/articles/31134#fig6">Figure 6E</a>). In contrast, the untrained (reservoir) network exhibited deviations that were large and fairly similar across all conditions, implying that the trained network was able to identify and suppress natural spectral noise present in the utterances, but not artificial noise of similar magnitude and structure. We further dissected these results with a novel analysis based on the decomposition of the RNN drive into its input and recurrent components, which allowed trajectories to be decomposed into the subspaces wherein the network integrates external (input subspace) and recurrent (recurrent subspace) inputs (Materials and Methods). The analysis showed that in untrained networks, both natural and artificial spectral noise introduced deviations in the recurrent subspace that were large and unsuppressed (<a href="https://elifesciences.org/articles/31134#fig6">Figure 6F</a>). In contrast, in trained RNNs the recurrent dynamics suppressed natural spectral noise, but not artificial noise (<a href="https://elifesciences.org/articles/31134#fig6">Figure 6G</a>). Training also resulted in a recurrent subspace that suppressed spectral noise induced deviations in the input subspace. Whereas the untrained network integrated recurrent and external inputs in orthogonal subspaces, training the network rotated the recurrent subspace such that spectral noise induced trajectory deviations in the recurrent subspace were anti-correlated with the deviations in the input subspace, thereby resulting in their suppression (Recurrent-Input interaction in <a href="https://elifesciences.org/articles/31134#fig6">Figure 6F–G</a>).</p>
<p>Together, these results suggest that recurrent plasticity may play a crucial role in identifying and suppressing the natural spatial variations of stimuli. In our model, this is achieved via supervised training with a common within-digit target trajectory, which exposes the spatiotemporal distribution of the spectral noise in the sensory input, and in doing so, allows for effective sampling from this distribution. Training then shapes the basins of attraction or hypertubes around the spoken digit-encoding trajectories based on this distribution, resulting in effective, recurrently-driven suppression of naturally occurring spectral noise.</p>
<h3 id="encoding-stimuli-as-neural-trajectories-allows-for-temporal-generalization-scaling">Encoding stimuli as neural trajectories allows for temporal generalization (Scaling)<a class="headerlink" href="#encoding-stimuli-as-neural-trajectories-allows-for-temporal-generalization-scaling" title="Permanent link">&para;</a></h3>
<p>As mentioned above, a signature and little understood feature of how the brain processes time-varying patterns pertains to temporal warping (temporal invariance), whereby temporally compressed or dilated input signals can be identified as the same pattern. Thus, an important test for computational models of sensory processing of time-varying stimuli, is whether they are able to account for temporal invariance. We hypothesized that one advantage of encoding time-varying stimuli as continuous neural trajectories, is that it naturally addresses the problem of temporal warping; specifically, that compressed or dilated stimuli generate similar neural trajectories that play out at different ‘speeds’ (<a href="https://elifesciences.org/articles/31134#bib35">Lerner et al., 2014</a>; <a href="https://elifesciences.org/articles/31134#bib44">Mello et al., 2015</a>). To test this hypothesis, we trained and tested an RNN on a dataset of temporally warped spoken digits.</p>
<p>Specifically, the input pattern, <strong><em>y</em></strong>(<em>t</em>), of a single utterance of each digit from a speaker of the TI-46 dataset was artificially stretched or compressed by a time warp factor α (<strong><em>y</em></strong>(<span class="arithmatex">\(&lt;math id="inf4"&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;\)</span><em>t)</em>), while retaining its spatial structure. <a href="https://elifesciences.org/articles/31134#fig7">Figure 7A</a> (left panel) shows the input structure for two utterances of the digit ‘nine’, one warped to twice (α = 2, 2x or 200% warp) and the other to half (α = 0.5, 0.5x or 50% warp) the duration of the original utterance.</p>
<p><a href="https://iiif.elifesciences.org/lax/31134%2Felife-31134-fig7-v1.tif/full/,1500/0/default.jpg"><img alt="70 Wiki/articles/MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.7.jpg" src="../MD_webclips/MD Clips Old/Learning multiple variable-speed sequences in striatum via cortical tutoring/default.7.jpg" /></a></p>
<h6 id="invariance-of-encoding-trajectories-to-temporally-warped-spoken-digits">Invariance of encoding trajectories to temporally warped spoken digits.<a class="headerlink" href="#invariance-of-encoding-trajectories-to-temporally-warped-spoken-digits" title="Permanent link">&para;</a></h6>
<p>(<strong>A</strong>) Temporally warped input cochleograms for an utterance of the digit ‘nine’ (left panel), warped by a factor of 2x (upper row) and 0.5x (lower row). Distance matrices between the trajectories …</p>
<p><a href="https://doi.org/10.7554/eLife.31134.011">https://doi.org/10.7554/eLife.31134.011</a></p>
<p>The RNN was trained on three warped utterances of each digit (warp factors of 0.7, 1 and 1.4) and tested on warp factors in the range 0.5 to 2 (a four-fold factor that approximates the natural speed variation of speech). To discern the effect of a temporally warped input on the encoding trajectory, we constructed a matrix of the distances between trajectories produced by the reference (α = 1) and a warped utterance (<a href="https://elifesciences.org/articles/31134#fig7">Figure 7A</a>). Each element of such a matrix measures the distance between the two trajectories at a corresponding pair of time points. In the case of perfect warping (e.g., when the reference trajectory and the trajectory at an α≠1 overlap exactly in phase space), a diagonal line of zero distances (deep blue) would be observed during the sensory epoch (shaded region), with slope proportional to the warp factor. Trajectories produced by temporally warped inputs in the sensorimotor trained RNN were closer to the reference compared to their counterparts in the reservoir or motor-trained RNN. In other words, tuning the recurrent weights dramatically improved the ability of the network to reproduce the same neural trajectories, despite being driven by inputs at different speeds. We quantified this effect by measuring the average distance between the reference and warped trajectories during the sensory epoch over different warp factors (<a href="https://elifesciences.org/articles/31134#fig7">Figure 7B</a>). In comparison to the two control networks, the trained RNN maintains a much smaller distance between trajectories across the four-fold range of temporal warping—including warp factors outside the range used during training. These results confirm the hypothesis that training produces a modulation of the internal dynamics by the external input that renders the encoding trajectories invariant to temporal warping of the input patterns. The impact of this result is borne out in the network’s performance on the digit transcription task, as measured by the CNN classifier (<a href="https://elifesciences.org/articles/31134#fig7">Figure 7C</a>). Training during the sensory and motor epochs dramatically improves ‘extrapolation’—that is generalization to speeds outside the range of training speeds; however, training during the motor epoch alone is sufficient to produce very good ‘interpolation’ (novel speeds within the training set range) generalization.</p>
<h3 id="mechanisms-underlying-temporal-generalization-temporal-scaling">Mechanisms underlying temporal generalization (temporal scaling)<a class="headerlink" href="#mechanisms-underlying-temporal-generalization-temporal-scaling" title="Permanent link">&para;</a></h3>
<p>It is surprising that a RNN with strong recurrent dynamics can represent temporally scaled stimuli with similar trajectories. Specifically, the strong intrinsic dynamics of the network (governed by the recurrent weights) must somehow match the temporal scale of the input. One possibility is that the network achieves this by scaling the linear speed of its trajectories (i.e. the magnitude of <span class="arithmatex">\(&lt;math id="inf5"&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi mathvariant="bold-italic"&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;\)</span> in <a href="https://elifesciences.org/articles/31134#equ1">Equation 1</a>) in inverse proportion to the warp factor. However, a comparison of the time-averaged linear speed of trajectories encoding digits at different warps deviates from this relationship in both the untrained and trained networks (<a href="https://elifesciences.org/articles/31134#fig8">Figure 8A</a>), which, in contrast to our earlier results (<a href="https://elifesciences.org/articles/31134#fig4">Figures 4A</a> and <a href="https://elifesciences.org/articles/31134#fig7">7A</a>), suggests that the trajectories may not be temporally invariant. This contradiction arises from the incorrect assumption that the trajectories have little or no curvature. <a href="https://elifesciences.org/articles/31134#fig8">Figure 8B</a> schematizes the two alternatives for temporal scaling of trajectories with curvature: constant speed/variable distance traversed, versus variable speed/constant distance traversed. At one extreme, a reference trajectory (black curve) can be slowed down while conserving its linear speed by increasing its radius of curvature, and therefore the distance it traverses through phase space (green curve). At the other extreme, the reference may be slowed by appropriately scaling down its linear speed while conserving its radius of curvature (yellow curve), thereby generating temporally invariant trajectories that traverse identical distances.</p>
<p><a href="https://iiif.elifesciences.org/lax/31134%2Felife-31134-fig8-v1.tif/full/,1500/0/default.jpg"><img alt="default.8.jpg" src="../Encoding%20sensory%20and%20motor%20patterns%20as%20time-invariant%20trajectories%20in%20recurrent%20neural%20networks/default.8.jpg" /></a></p>
<h6 id="mechanism-of-temporal-scaling-invariance">Mechanism of temporal scaling invariance.<a class="headerlink" href="#mechanism-of-temporal-scaling-invariance" title="Permanent link">&para;</a></h6>
<p>(<strong>A</strong>) Time-averaged linear speed (<strong>v</strong>) during the sensory epoch trajectories in the reservoir and trained networks (N = 2100) compared to the ideal linear speed, over a range of warp factors. The speeds …</p>
<p><a href="https://doi.org/10.7554/eLife.31134.012">https://doi.org/10.7554/eLife.31134.012</a></p>
<p>Temporally-scaled utterances produce overlapping trajectories in PCA subspace (<a href="https://elifesciences.org/articles/31134#fig8">Figure 8C</a>, left panel)—reflecting the scaling of their linear velocities while traversing constant distances (a direct consequence of how the artificially warped utterances were constructed). In contrast, the RNN trajectories produced by these scaled utterances are spatially distinct with warp-dependent separations (<a href="https://elifesciences.org/articles/31134#fig8">Figure 8C</a>, right panel). Moreover, they exhibit warp-dependent curvature, with slower trajectories incurring larger curvature radii. Together with the results in <a href="https://elifesciences.org/articles/31134#fig8">Figure 8A</a>, this suggests that the mechanisms underlying temporal scaling in our model fall between the two extreme hypotheses, implying that: (i) that the average linear speed and curvature radius of trajectories encoding utterances at different warps adjust in a manner that appropriately modulates their angular speed and therefore their timescale; and (ii) that the trajectories are parallel to each other, demonstrating that they encode the digit similarly. <a href="https://elifesciences.org/articles/31134#fig8">Figure 8D</a> presents measurements of the time-averaged linear speed and the total distance traversed in the recurrent subspace of phase space, by the trajectories in the trained and untrained networks over a range of warps. The latter is a heuristic measure of the time-averaged curvature radius, hinging on the fact that the circumference (or distance traversed) linearly scales with the radius. A comparison of these measurements for the two networks to the expected values in constant speed- and constant distance trajectories, confirms that both networks produce trajectories that lie in between these two extremes. That is, temporal scaling is achieved by an approximate balance of both hypotheses, e.g., at low speeds (digits spoken slowly) the trajectories are slower and longer. Furthermore, training alters this balance to reduce the within-digit separation, by modulating the trajectory speeds more strongly. Measurements to establish whether the trajectories are parallel also agree with these results (<a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplement 1C</a>).</p>
<p>But how do identical inputs (except for their duration) generate these parallel trajectories (e.g., <a href="https://elifesciences.org/articles/31134#fig8">Figure 8C</a>)? To answer this question, we first measured the relationship between the input and recurrent subspaces in the trained network, and discovered that they are orthogonal to one another (data not shown), implying that the integration of the external inputs is independent of the integration of the recurrent inputs. In the absence of subspace interactions, it is easy to see that external inputs with different speeds are integrated into spatially distinct input subspace trajectories (e.g. <span class="arithmatex">\(&lt;math id="inf10"&gt;&lt;mrow&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;cos&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;ω&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;ω&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;sin&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;ω&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;\)</span>, wherein high speed/frequency signals integrate to produce trajectories with small magnitudes) (<a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplement 1A</a>). As with the recurrent subspace trajectories, the resulting input subspace trajectories are parallel to each other and modulate their angular speed via a combination of changes to their curvature radii and linear speed (<a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplement 1A–C</a>). Ultimately, the differentiated curvature and linear velocity that modulate the angular velocity and therefore the timescales of recurrent subspace trajectories, are directly shaped by these input subspace dynamics (<a href="https://elifesciences.org/articles/31134#bib55">Rajan et al., 2010a</a>).</p>
<p>To determine if this solution to the temporal invariance problem is specific to the ‘innate’ training algorithm, or likely a general property of trained RNNs, we trained a RNN with a gradient-descent approach in which the error was based solely on the output units (Materials and Methods, <a href="https://elifesciences.org/articles/31134/figures#fig8s2">Figure 8—figure supplement 2</a>). While the interpolation and extrapolation performance of this network was inferior to the network trained with ‘innate’ learning (<a href="https://elifesciences.org/articles/31134/figures#fig8s2">Figure 8—figure supplement 2B</a>), the underlying mechanism was the same: warped utterances were encoded along parallel trajectories (<a href="https://elifesciences.org/articles/31134/figures#fig8s2">Figure 8—figure supplement 2F–G</a>) with warp-dependent curvature and linear velocity (<a href="https://elifesciences.org/articles/31134/figures#fig8s2">Figure 8—figure supplement 2E</a>) that subserved temporal scaling. Thus, two very different training algorithms resulted in similar solutions to the temporal invariance problem.</p>
<p>In summary, these results demonstrate that the integration of inputs at different warps separates out the resulting trajectories in the input subspace, and consequently in the recurrent subspace. In both subspaces the network dynamics generate trajectories with warp-dependent linear velocities and curvature, which appropriately modulate their angular velocity, resulting in them traversing spatially distinct yet parallel paths at warp-dependent timescales. This confirms the hypothesis that an inherent computational advantage of encoding time-varying sensory stimuli in neural trajectories is that it can naturally address the temporal invariance problem.</p>
<p>[</p>
<h2 id="discussion">Discussion<a class="headerlink" href="#discussion" title="Permanent link">&para;</a></h2>
<p>](https://elifesciences.org/articles/31134#)</p>
<p>The brain naturally encodes, recognizes, and generates complex time-varying patterns, and can seamlessly process temporally scaled patterns. Despite our poor understanding of these processes, theoretical evidence increasingly suggests that the dynamics of recurrently connected circuits in the brain are critical to representing time-varying patterns. For example, so-called reservoir computing approaches propose that complex high-dimensional spatiotemporal patterns are represented in the dynamics inherent to randomly connected recurrent neural networks (<a href="https://elifesciences.org/articles/31134#bib26">Jaeger and Haas, 2004</a>; <a href="https://elifesciences.org/articles/31134#bib7">Buonomano and Maass, 2009</a>; <a href="https://elifesciences.org/articles/31134#bib61">Sussillo and Abbott, 2009</a>). A shortcoming of this approach, however, is that the recurrent connections in these networks are not plastic; thus in contrast to actual cortical circuits, the random recurrent neural network (the ‘reservoir’) does not adapt or optimize to the task at hand. Additionally, fully tapping into the computational potential of randomly connected RNNs has proven difficult because they are susceptible to chaos (<a href="https://elifesciences.org/articles/31134#bib60">Sompolinsky et al., 1988</a>; <a href="https://elifesciences.org/articles/31134#bib65">Wallace et al., 2013</a>). However, progress has been made on both accounts (<a href="https://elifesciences.org/articles/31134#bib42">Martens and Sutskever, 2011</a>; <a href="https://elifesciences.org/articles/31134#bib63">Vogels et al., 2011</a>; <a href="https://elifesciences.org/articles/31134#bib30">Laje and Buonomano, 2013</a>). Here, we extend these results to better understand well-known aspects of the brain’s ability to represent time-varying sensory <em>and</em> motor patterns—we demonstrate how experience-dependent plasticity could reshape the dynamics of reservoir RNNs to qualitatively improve representations by endowing them with such essential properties as generalization to novel exemplars, sensory-motor association and transformation, and temporal invariance.</p>
<p>Previous models of temporal scaling have enlisted neural and synaptic dynamics to achieve temporal invariance of both sensory stimuli (<a href="https://elifesciences.org/articles/31134#bib19">Gütig and Sompolinsky, 2009</a>) and the generation of motor responses (<a href="https://elifesciences.org/articles/31134#bib48">Murray and Escola, 2017</a>). In the model proposed by Gutig and Sompolinsky, temporally invariant recognition of compressed and dilated sensory stimuli is based on a synaptic shunting mechanism, wherein the effective integration time of a post-synaptic cell is modulated by the total conductance of its afferent synapses, which changes as a monotonic function of the input warp—thus temporal invariance is ultimately reduced to a cellular property. In contrast, in the model described here temporal invariance emerges from a network property: the formation of parallel neural trajectories traversed at different speeds. While the formation of such trajectories may be surprising given the sensitivity and nonlinear nature of RNNs, we show that this capacity is the consequence of scale-dependent angular velocities of the encoding trajectories. This property of RNN encoding, which is observable to a lesser extent even in reservoir networks (<a href="https://elifesciences.org/articles/31134#fig8">Figure 8D</a>), stems from its leaky integration of scaled inputs (<a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplement 1B</a>) and the input-driven suppression of its chaotic recurrent activity (<a href="https://elifesciences.org/articles/31134#bib55">Rajan et al., 2010a</a>). Indeed, network training enhances this property by suppressing recurrent amplification of scale-driven deviations in the encoding trajectories, producing proximal, parallel within-digit trajectories with linear velocities that are more strongly scale-dependent (<a href="https://elifesciences.org/articles/31134#fig8">Figure 8D</a>, <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplements 1C</a>, <a href="https://elifesciences.org/articles/31134/figures#fig8s2">2E and G</a>). The effects of such a suppression are evident even in networks subjected to motor-only training, where we observe a considerable decrease in the within-digit distances (<a href="https://elifesciences.org/articles/31134#fig7">Figure 7B</a>) and consequently strong interpolation generalization (<a href="https://elifesciences.org/articles/31134#fig7">Figure 7C</a>). Nevertheless, it remains the case that training across both the sensory and motor epochs, not only improves interpolation and extrapolation generalization, but also strongly enhances cross-utterance and cross-speaker generalization (<a href="https://elifesciences.org/articles/31134#fig1">Figure 1C</a>).</p>
<p>Our results also demonstrate how training an RNN reveals a computationally powerful pattern recognition regime, one that helps generalize the encoding of learned time-varying patterns to novel exemplars. As stated earlier, recognizing different instances of the same digit as one and the same, while discriminating between different digits requires that networks actively and differentially sculpt the within and between class trajectories—the separation between trajectories representing similar patterns must be kept to a minimum, while that between trajectories representing different patterns must be amplified. A previous study has analytically shown that untrained random recurrent networks (reservoir networks) process inputs in one of three computational regimes: a chaotic regime, wherein any separation between trajectories is strongly amplified by the network’s chaotic dynamics; a regime with weak recurrent weights that is input-dominated with little computational power; and a critical regime wherein the input and internal dynamics are balanced (<a href="https://elifesciences.org/articles/31134#bib6">Bertschinger and Natschläger, 2004</a>). Here, we show that training alters these regimes in very different ways (<a href="https://elifesciences.org/articles/31134#fig5">Figure 5</a>). Crucially, relative to the separation between the input patterns, reservoir networks in the critical regime amplify the separation between trajectories representing similar patterns more strongly than between different patterns. In contrast, trained networks separate trajectories according to the patterns they are representing (<a href="https://elifesciences.org/articles/31134#fig5">Figure 5A</a>). Tuning the recurrent weights reshapes the internal dynamics of the network, enabling it to redirect or suppress deviations from the target trajectories (<a href="https://elifesciences.org/articles/31134#fig6">Figure 6</a>). Ultimately, it is this property of trained networks that allows them to encode complex sensory patterns and effectively generalize across natural utterances and speakers.</p>
<p>Three experimentally tractable predictions emerge from the above results. First, neural trajectories will be stable in response to local perturbations potentially administered through optogenetic stimulation. Importantly, and in agreement with an earlier analysis (<a href="https://elifesciences.org/articles/31134#bib55">Rajan et al., 2010a</a>), the neural trajectories elicited during sensory stimuli will be more resistant to perturbations than the neural trajectories unfolding during the motor epoch of sensory-motor tasks. A second prediction, which to the best of our knowledge is a novel one, relates to the structure of noise. Specifically, trained networks fail at generalizing to unfamiliar spectral noise patterns, thereby generating the prediction that trajectories in sensory areas will diverge more when presented stimuli composed of artificial or unfamiliar spectral noise patterns. This would indicate that the stimulus-response function of complex sensory neurons are not just sensitive to natural stimulus features (<a href="https://elifesciences.org/articles/31134#bib62">Theunissen and Elie, 2014</a>), but also natural noise features. To test this, an animal could be trained to recognize natural sounds with noise injected along some principal components of the stimulus spectrogram but not others, and then tested on noise injected along the held-out PCA dimensions. A comparison of the trajectories encoding trained and tested sounds should reveal a larger divergence in the neural encoding of the test sounds. Third, and most specifically, the model predicts a clear neural correlate of the encoding of temporally scaled stimuli—the observation that slower stimuli yield trajectories with larger curvature radii implies that the neural population activity should exhibit larger fluctuations in their firing rates in response to slower stimuli; In other words, at the neuronal level the range of minimal to maximal firing rate should be larger (<a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplements 1D</a> and <a href="https://elifesciences.org/articles/31134/figures#fig8s2">2D</a>).</p>
<p>These experimental predictions are critical to validate the model’s implementation of complex and invariant sensorimotor computations as stable neural trajectories. However, even if validated a number questions remain to be addressed. Most notably, how can the recurrent synaptic strengths be tuned to develop stable trajectories in a biologically plausible manner? The learning rule used here, coupled with its requirement of an explicit target for each recurrent unit, make it biologically implausible. However, while it is important that the sensorimotor representations are encoded as locally stable trajectories, the structure of the target trajectories themselves are essentially arbitrary. It is therefore conceivable that arbitrary yet locally-stable encoding trajectories may emerge from unsupervised learning. A second related issue is that to achieve strong temporal invariance, our model had to be trained over a range of sensory stimuli speeds. Again, it is not clear if this would represent a biologically plausible scenario—to help address this question, it will be important for future research to determine if the ability to recognize stimuli independent of speed is learned through experience. Finally, questions relating to the learning capacity of networks capable of strong temporal invariance, and the expedience of sensory-epoch training for temporal invariance remain open.</p>
<p>The computational potential of continuous time RNNs in high-gain regimes has long been recognized, but it has been challenging to tap into this potential because of their inherently chaotic behavior and the difficulties in training them (<a href="https://elifesciences.org/articles/31134#bib5">Bengio et al., 1994</a>; <a href="https://elifesciences.org/articles/31134#bib51">Pearlmutter, 1995</a>). Step-by-step, progress has been made on how to capture the computational potential of RNNs (<a href="https://elifesciences.org/articles/31134#bib26">Jaeger and Haas, 2004</a>; <a href="https://elifesciences.org/articles/31134#bib61">Sussillo and Abbott, 2009</a>; <a href="https://elifesciences.org/articles/31134#bib42">Martens and Sutskever, 2011</a>; <a href="https://elifesciences.org/articles/31134#bib30">Laje and Buonomano, 2013</a>). Here, we establish that a further feature of trained RNNs is their ability to not only encode spatiotemporal objects, but also to perform complex sensorimotor tasks and address the long-standing problem of temporal warping. These results are consistent with the proposal that that spatiotemporal objects are not encoded as fixed-point attractors, but as locally stable neural trajectories (dynamic attractors).</p>
<p>[</p>
<h2 id="materials-and-methods">Materials and methods<a class="headerlink" href="#materials-and-methods" title="Permanent link">&para;</a></h2>
<p>](https://elifesciences.org/articles/31134#)</p>
<h3 id="network-model">Network model<a class="headerlink" href="#network-model" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-1">Request a detailed protocol</a></p>
<p>The dynamics of the RNN was comprised of <em>N</em> nonlinear continuous-time firing rate units modeled as:</p>
<p>(1) <span class="arithmatex">\(&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;τ&lt;/mi&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mstyle displaystyle="true"&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;/msubsup&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mstyle displaystyle="true"&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;/msubsup&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/math&gt;\)</span></p>
<p>(2) <span class="arithmatex">\(&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;tanh&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;\)</span></p>
<p><em>xi</em> represents the state of neuron <em>i</em>, and <em>ri</em> its ‘firing rate’. The time constant, <span class="arithmatex">\(&lt;math id="inf11"&gt;&lt;mi&gt;τ&lt;/mi&gt;&lt;/math&gt;\)</span>, of each unit was set to 25 ms. <strong><em>WR</em></strong> is the weight matrix representing the recurrent connectivity of the network. The recurrent connectivity was uniformly random (but with no autapses) with a connection probability (<em>pc</em>) of 0.2. The weights of these synapses were initialized from an independent Gaussian distribution with zero mean and SD equal to <span class="arithmatex">\(&lt;math id="inf12"&gt;&lt;mrow&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/mrow&gt;&lt;/math&gt;\)</span>, where <em>g</em> represents the ‘gain’ of the network. RNNs were initialized to a high-gain regime (<em>g</em> = 1.6), which generates chaotic self-perpetuating activity in the absence of external input or noise (<a href="https://elifesciences.org/articles/31134#bib60">Sompolinsky et al., 1988</a>).</p>
<p>The M-dimensional vector <strong><em>y(t)</em></strong> represents the time-varying sensory input to the RNN. The fixed input weight matrix, <strong><em>WI</em></strong>, tonotopically projects this input vector onto the RNN—input channel <em>k</em> is projected onto units (k-1)×N/M + 1 thru k × N/M. The weights of these connections were drawn from an independent Gaussian distribution with zero mean and unit variance. <strong><em>WI y(t)</em></strong> represents the net external input to each RNN. The handwriting was modeled with three output units (<em>o1</em>, <em>o2</em>, <em>o3</em>) that represented the x, y and z co-ordinates of a pen on paper. Finally, each unit of the RNN also received an independent background noise current, <strong><em>Inoise</em></strong>, modeled as additive Gaussian white noise with SD <em>I0</em>.</p>
<p>As is standard, the output neurons were simulated as a weighted linear sum of all the units in the RNN:</p>
<p>(3) <span class="arithmatex">\(&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mstyle displaystyle="true"&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;/msubsup&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;/math&gt;\)</span></p>
<p>where the output weight matrix, <strong><em>Wo</em></strong>, was initialized from an independent Gaussian distribution with zero mean and SD <span class="arithmatex">\(&lt;math id="inf13"&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;msqrt&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/msqrt&gt;&lt;/mrow&gt;&lt;/math&gt;\)</span>. All simulations were performed with a time step of 1 ms.</p>
<h3 id="simulations-and-training">Simulations and training<a class="headerlink" href="#simulations-and-training" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-2">Request a detailed protocol</a></p>
<p>Each trial consisted of a time window comprised of a sensory and a motor epoch. We defined the sensory epoch as the period in which an external stimulus is presented—starting at <em>t</em> = 0 and lasting the duration of the utterance. The motor epoch was defined as a period beginning 300 ms after the sensory epoch ended and lasting the duration of the target motor pattern (the appropriate handwritten digit).</p>
<p>Training proceeded in three steps (described in detail below): (1) target trajectories were generated for each utterance of each digit in the training subset of the dataset; (2) the recurrent units were trained to reproduce the target trajectories; and (3) the output units were trained to produce the handwritten spatiotemporal patterns. The trained network was then tested on novel (and trained) utterances. In steps 2, 3 and during testing, each trial began at <em>t</em>=-100 ms with the network initialized to a random state (<em>xi</em> values drawn from a uniform distribution between −1 and 1). In <a href="https://elifesciences.org/articles/31134#fig1">Figures 1</a> and <a href="https://elifesciences.org/articles/31134#fig7">7</a>, <a href="https://elifesciences.org/articles/31134/figures#fig1s1">Figure 1—figure supplement 1</a> and <a href="https://elifesciences.org/articles/31134/figures#fig8s2">Figure 8—figure supplement 2A–2B</a>, testing was performed with the noise amplitude (<em>I0</em>) set to 0.05. For the perturbation analysis (<a href="https://elifesciences.org/articles/31134#fig2">Figure 2</a>), a 25 ms ‘perturbation pulse’ was introduced during the sensory or motor epoch of each trial, with <em>I0</em> set to the desired perturbation magnitude for the duration of the pulse. Noise was omitted in these simulations to allow for a direct assessment of the effects of the perturbation pulse. Similarly, for the simulations in <a href="https://elifesciences.org/articles/31134#fig3">Figures 3</a>–<a href="https://elifesciences.org/articles/31134#fig6">6</a>, <a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a> and <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplements 1</a> and <a href="https://elifesciences.org/articles/31134/figures#fig8s2">2C</a>–<a href="https://elifesciences.org/articles/31134/figures#fig8s2">2G</a>, noise was omitted (<em>I0</em> = 0) so that the impact of training on the generalization and discriminability of an RNN’s encodings, but not its background noise invariance, could be direct evaluated.</p>
<p>Simulations of the untrained ‘reservoir’ control network skipped steps 1 and 2, while simulations of the motor-trained control network limited recurrent network training (step 2) to a duration starting 150 ms after the end of the sensory epoch and lasting until the end of the motor epoch.</p>
<h3 id="input-structure">Input structure<a class="headerlink" href="#input-structure" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-3">Request a detailed protocol</a></p>
<p>We used spoken digits from the TI-46 spoken word corpus (<a href="https://elifesciences.org/articles/31134#bib41">Mark Liberman et al., 1993</a>) to train and test networks on the transcription task. Specifically, our dataset was composed of the spoken digits ‘zero’ thru ‘nine’, uttered 10 times each, by each of five female subjects. Spoken digits from the corpus were decoded, end-pointed, resampled to 12 kHz, and converted to spectrograms with Matlab’s specgram function. The spectrograms were preprocessed with Lyon’s passive ear model of the human cochlea (<a href="https://elifesciences.org/articles/31134#bib38">Lyon, 1982</a>), as implemented by the auditory toolbox (Malcolm Slaney), to generate analog ‘cochleograms’ composed of 12 analog frequency bands, or channels, ranging from 0 to 6 kHz. Finally, the cochleograms were smoothed with a 20th order 1D median filter (Matlab’s medfilt1 function), normalized to a maximum of 1 (i.e., they were normalized by the maximal value of all utterances and digits), and scaled by an input amplitude. During the sensory epoch of each trial, the input, <strong><em>y(t)</em></strong> (M = 12), took values from the cochleogram corresponding to the utterance that was to be presented to the RNN. At all other times of the trial, <strong><em>y(t)</em></strong> was set to 0. The input amplitude was set to five in all simulations except in <a href="https://elifesciences.org/articles/31134#fig5">Figure 5</a>, where it was parametrically varied. For the temporal warping simulations (<a href="https://elifesciences.org/articles/31134#fig7">Figures 7</a>–<a href="https://elifesciences.org/articles/31134#fig8">8</a>, <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplements 1</a>–<a href="https://elifesciences.org/articles/31134/figures#fig8s2">2</a>) the cochleograms were compressed or dilated by the warping factor <em>α</em> through linear interpolation.</p>
<h3 id="innate-trajectories-and-rnn-training">Innate trajectories and RNN training<a class="headerlink" href="#innate-trajectories-and-rnn-training" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-4">Request a detailed protocol</a></p>
<p>Training was performed with the ‘innate-learning’ approach—which uses the Recursive Least Squares (RLS) rule to train each unit of the recurrent network to match the pattern generated by the untrained network (<a href="https://elifesciences.org/articles/31134#bib30">Laje and Buonomano, 2013</a>). For each subject used in the training set, a single template utterance of each digit was presented to the untrained RNN (the reservoir) in the absence of background noise, and the resulting trajectory served as a target (‘innate’) trajectory. The template utterance of each digit was chosen as one with the median duration among all the utterances of the digit by the subject. Target sensory epoch trajectories for other training utterances of the digit by the same subject were generated by linearly warping this innate trajectory to match the utterance durations.</p>
<p>To achieve the formation of digit-specific dynamic attractors, a single target motor trajectory was adopted across subjects and utterances for each digit. This target, comprising of the sensory-to-motor transition and motor epoch population activity, was generated from the template utterance by a single arbitrarily chosen subject, by allowing the untrained RNN to autonomously generate activity following template stimulus offset, in the absence of background noise, for a duration equal to the sum of the sensory-to-motor transition duration (300 ms) and the motor epoch duration for the digit. Sensorimotor targets for each training utterance were composed by concatenating the common motor target to the end of the corresponding sensory targets. The initial network state was chosen at random while harvesting the target trajectory for each digit. Target trajectories for template utterances of the same digit by different speakers were harvested starting the network at the same initial state.</p>
<p>All networks were trained with three utterances of each digit for each of the subjects in the training set. The networks in <a href="https://elifesciences.org/articles/31134#fig1">Figure 1</a> and <a href="https://elifesciences.org/articles/31134/figures#fig1s1">Figure 1—figure supplement 1</a> were trained on three subjects and tested on five, while those in <a href="https://elifesciences.org/articles/31134#fig2">Figures 2</a>–<a href="https://elifesciences.org/articles/31134#fig8">8</a> and <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplements 1</a>–<a href="https://elifesciences.org/articles/31134/figures#fig8s2">2</a> were trained and tested on one subject. The network size, <em>N</em>, strongly impacted its capacity, particularly for generalization. Accordingly, we trained larger networks to robustly address cross-speaker generalization (<em>N</em> = 4000) relative to those trained for cross-utterance generalization within a single speaker (<em>N</em> = 2100).</p>
<p>Network training was performed by modifying the recurrent weight matrix, <strong><em>WR</em></strong>, with the Recursive Least Squares learning rule (<a href="https://elifesciences.org/articles/31134#bib20">Haykin, 2002</a>). The rule was simultaneously applied to 90% of the units in the network (randomly selected). Training was conducted by iterating through all utterances of the digits in the training set over multiple trials, starting each trial at a random initial condition and continuously injecting the network with background noise (<strong><em>Inoise</em></strong>). Training concluded when the error in the activity of the rate units asymptoted (generally between 100 and 150 trials).</p>
<h3 id="output-training">Output training<a class="headerlink" href="#output-training" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-5">Request a detailed protocol</a></p>
<p>The spatiotemporal target patterns that comprise the handwritten digits were sampled from a Wacom Bamboo Pen Tablet, as the digits ‘0’ thru ‘9’ were individually stenciled on it. For each handwritten digit, the x and y coordinates of the pen were sampled at approximately 50 Hz, low-pass filtered, and resampled with interpolation to 1 kHz (corresponding to the 1 ms simulation time step). The target values for <em>o1</em> and <em>o2</em> were set to 0 from the start of each trial until the beginning of the motor epoch. During the motor epoch, they were set to the pen’s 2D coordinates for the corresponding digit, and reset to 0 between the end of the motor epoch and the end of the trial. The target for <em>o3</em> (z co-ordinate) was a step function, set to one during the motor epoch and 0 at all other times. To train the output units, the Recursive Least Squares learning rule was applied to the readout weights in <strong><em>WO</em></strong> (<a href="https://elifesciences.org/articles/31134#bib20">Haykin, 2002</a>; <a href="https://elifesciences.org/articles/31134#bib26">Jaeger and Haas, 2004</a>; <a href="https://elifesciences.org/articles/31134#bib61">Sussillo and Abbott, 2009</a>; <a href="https://elifesciences.org/articles/31134#bib30">Laje and Buonomano, 2013</a>). Output training was performed for 25 trials per utterance of each digit in the training set, while the RNN was continuously injected with background noise.</p>
<p>In each test trial, the motor output was recorded from the values of <em>o1</em> and <em>o2</em>, whenever the value of <em>o3</em> was greater than 0.5 (i.e. when ‘the pen contacted the paper’). At the end of the trial, a 28 × 28 pixel grayscale image of the ‘handwritten’ output (pen width = 2 pixels) was labeled as the transcription for the corresponding digit. An objective determination of the transcription’s accuracy was made by comparing this label to one assigned to the image by a CNN classifier for handwritten digits. This classification was performed with the LeNet-5 CNN classifier (<a href="https://elifesciences.org/articles/31134#bib33">Lecun et al., 1998</a>) implemented with the Caffe deep learning framework (<a href="https://elifesciences.org/articles/31134#bib27">Jia et al., 2014</a>). The CNN was first trained on the MNIST database of handwritten digits (<a href="https://elifesciences.org/articles/31134#bib34">LeCun et al., 1998</a>), and its output layer was then fine-tuned on the stenciled digits that we used as the output targets.</p>
<h3 id="gradient-descent-training">Gradient descent training<a class="headerlink" href="#gradient-descent-training" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-6">Request a detailed protocol</a></p>
<p>In <a href="https://elifesciences.org/articles/31134/figures#fig8s2">Figure 8—figure supplement 2</a>, we evaluate the mechanism underlying temporal scaling in a network trained with gradient descent. The recurrent rate units and output units were modeled as in <a href="https://elifesciences.org/articles/31134#equ1">Equations 1-3</a>, with weights of the input and output units initialized as in the reservoir network. Target values for the output units were assigned as described above. No target values were specified for the recurrent rate unit activity. Instead, all input, recurrent and output weights of the network were updated at the end of each training trial, with weight update values for the trial determined based on the squared-error of the outputs averaged across time and output units. Specifically, the error was transformed into weight updates via the backpropagation through time (BPTT) algorithm applied via ADAM optimization (<a href="https://elifesciences.org/articles/31134#bib29">Kingma and Ba, 2014</a>). To evade the vanishing and exploding gradients problem that commonly hinder gradient descent training of RNNs, <strong><em>WR</em></strong> was initialized as an all-to-all orthogonal matrix of random values (<a href="https://elifesciences.org/articles/31134#bib31">Le et al., 2015</a>), and gradient magnitudes were restricted via gradient clipping (<a href="https://elifesciences.org/articles/31134#bib18">Graves, 2013</a>). Furthermore, <strong><em>WR</em></strong> was initialized to high-gain regime (<em>g</em> = 1.6), as this lead to faster convergence (5000 trials per utterance). The network was trained with continuous injection of background noise. Training was performed with the Tensorflow library (<a href="https://elifesciences.org/articles/31134#bib1">Abadi et al., 2016</a>), and output performance was evaluated with the CNN classifier described above.</p>
<h3 id="trajectory-analysis">Trajectory analysis<a class="headerlink" href="#trajectory-analysis" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-7">Request a detailed protocol</a></p>
<p>In <a href="https://elifesciences.org/articles/31134#fig4">Figures 4</a>–<a href="https://elifesciences.org/articles/31134#fig5">5</a>, the sensory (motor) epoch within-digit distances were calculated from the Euclidean distance, at each time step, between the sensory (motor) epoch trajectory for each utterance, and its nearest neighbor from among the trajectories produced by the training utterances of the same digit. Similarly, the sensory (motor) epoch between-digit distances were calculated from the Euclidean distance, at each time step, between the sensory (motor) epoch trajectory for each utterance, and its nearest neighbor from among the sensory (motor) epoch trajectories encoding training utterances of all other digits. Similarly, in <a href="https://elifesciences.org/articles/31134#fig6">Figure 6E</a>, sensory epoch within-digit distances were calculated as the Euclidean distance between the sensory epoch trajectory for each tested external input, and the one encoding the template utterance. Finally, trajectory distances in <a href="https://elifesciences.org/articles/31134#fig7">Figure 7B</a> and <a href="https://elifesciences.org/articles/31134/figures#fig8s2">Figure 8—figure supplement 2A</a> were also calculated in a similar fashion: at each time step, the Euclidean distance was calculated between the trajectory encoding an utterance at warp factor <em>α</em> (<em>I0</em> = 0.05), and its nearest neighbor along the trajectory encoding the reference utterance of the same digit (<em>I0</em> = 0). The time-average of these distances were then summarized over 10 trials for the plots in these figures.</p>
<p>The nature and robustness of spectral generalization in trained RNNs was probed in <a href="https://elifesciences.org/articles/31134#fig6">Figure 6</a>, by artificially altering the external inputs. In order to assess spectral generalization independent of temporal invariance, for each digit, the duration of all its utterances were time-normalized by warping the respective cochleograms to their median duration. The RNN and its outputs were trained on three time-normalized utterances for each of the ten digits, and all test simulations were performed with a common initial state. The spectral generalization of an RNN was tested with artificially constructed external inputs to the network that were qualitatively similar to external inputs for time-normalized natural utterances, but with altered spectral noise structure. The spectral noise in an utterance was defined as the difference between the external inputs of the utterance and the respective template utterance (<a href="https://elifesciences.org/articles/31134#fig6">Figure 6A</a>). Network responses to time-normalized trained and untrained natural utterances were compared to two artificial controls: external inputs with shuffled noise and with orthogonal noise. Inputs with shuffled noise were constructed from the Principal Component Analysis (PCA) loadings and scores of the spectral noise in untrained natural utterances as follows: (i) the loading vectors were permuted; (ii) shuffled noise was generated by multiplying the spectral noise scores by the shuffled loading vectors; (iii) this shuffled noise was added to the external input of the corresponding template utterance. Inputs with orthogonal noise were also constructed from the PCA loadings and scores of the spectral noise in untrained natural utterances, except instead of permuting the loading vectors, they were replaced by an orthonormal set of vectors, generated via Gram-Schmidt orthogonalization, each of which was orthogonal to the set of spectral noise PCA loading vectors. For this a random vector was generated and QR factorization was performed on the set of vectors comprised of the PCA loadings and the random vector, producing a new vector that was orthogonal to the PCA loadings. This procedure was repeated to generate a set of such vectors equal in cardinality to the PCA loading set. The random vectors were then orthogonalized relative to each other in a similar manner, and then normalized to produce an orthonormal set. External inputs with shuffled and orthogonal noise were constructed from each untrained natural utterance, with as few PCs as were necessary to explain 99% of the variance in its spectral noise (typically 11 PCs). For each digit, the network was tested with 30 shuffled and orthogonal noise inputs, each based on a randomly chosen untrained natural utterance.</p>
<p>The dimensionality measure shown in <a href="https://elifesciences.org/articles/31134#fig5">Figure 5</a> was calculated as <span class="arithmatex">\(&lt;math id="inf14"&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mstyle displaystyle="true"&gt;&lt;msubsup&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/msubsup&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msubsup&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/math&gt;\)</span>, where <em>λk</em> represents eigenvalues of the equal-time cross-correlation matrix of network activity, expressed as a fraction of their sum (<a href="https://elifesciences.org/articles/31134#bib54">Rajan et al., 2010b</a>). The eigenvalues were calculated on a concatenation of the sensory epoch trajectories for all utterances (trained and novel) of all digits.</p>
<h3 id="rnn-decomposition">RNN decomposition<a class="headerlink" href="#rnn-decomposition" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-8">Request a detailed protocol</a></p>
<p>In <a href="https://elifesciences.org/articles/31134#fig6">Figure 6</a>, <a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a> and <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplements 1</a>–<a href="https://elifesciences.org/articles/31134/figures#fig8s2">2</a>, trajectories and their distances from each other were decomposed into the constituent input and recurrent subspaces of phase space. These are derived from the state variable <strong><em>x(t)</em></strong> (<a href="https://elifesciences.org/articles/31134#equ1">Equation 1</a>), rather than the rate variable <strong><em>r(t)</em></strong> (<a href="https://elifesciences.org/articles/31134#equ2">Equation 2</a>) that was used to measure Euclidean distances:</p>
<p>From Euler’s Method:</p>
<p><span class="arithmatex">\(&lt;math&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt; &lt;mi&gt;&lt;/mi&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;\)</span></p>
<p><span class="arithmatex">\(&lt;math&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;τ&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt; &lt;mi&gt;&lt;/mi&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt; &lt;mi&gt;&lt;/mi&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/math&gt;\)</span></p>
<p>Let <span class="arithmatex">\(&lt;math id="inf15"&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;τ&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;\)</span>,<span class="arithmatex">\(&lt;math id="inf16"&gt; &lt;mi&gt;&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;τ&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;\)</span>, <span class="arithmatex">\(&lt;math id="inf17"&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/math&gt;\)</span>, and <span class="arithmatex">\(&lt;math id="inf18"&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/math&gt;\)</span></p>
<p><span class="arithmatex">\(&lt;math&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt; &lt;mi&gt;&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt; &lt;mi&gt;&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/math&gt;\)</span></p>
<p>Solving this recurrence relationship,</p>
<p>(4) <span class="arithmatex">\(&lt;math&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt; &lt;mi&gt;&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt; &lt;mi&gt;&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/math&gt;\)</span></p>
<p>where <span class="arithmatex">\(&lt;math id="inf19"&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/math&gt;\)</span> is the initial state of the network. We denote the first two terms (<span class="arithmatex">\(&lt;math id="inf20"&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt; &lt;mi&gt;&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/math&gt;\)</span>) as network activity in the recurrent subspace (recurrent subspace trajectory) and the last term (<span class="arithmatex">\(&lt;math id="inf21"&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/math&gt;\)</span>) as network activity in the input subspace (input subspace trajectory).</p>
<p>When the input durations for all utterances of a digit are time-normalized, as in <a href="https://elifesciences.org/articles/31134#fig6">Figure 6</a>, the squared Euclidean distance between the state variables <span class="arithmatex">\(&lt;math id="inf22"&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/math&gt;\)</span> and <span class="arithmatex">\(&lt;math id="inf23"&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt; &lt;mi&gt;&lt;/mi&gt;&lt;/math&gt;\)</span>for two sensory epoch trajectories encoding utterances <span class="arithmatex">\(&lt;math id="inf24"&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/math&gt;\)</span> and <span class="arithmatex">\(&lt;math id="inf25"&gt;&lt;msup&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;/math&gt;\)</span> is given by:</p>
<p><span class="arithmatex">\(&lt;math&gt;&lt;mstyle displaystyle="true" scriptlevel="0"&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/math&gt;\)</span></p>
<p>From <a href="https://elifesciences.org/articles/31134#equ7">Equation 4</a>, it follows that:</p>
<p><span class="arithmatex">\(&lt;math&gt;&lt;mstyle displaystyle="true" scriptlevel="0"&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/math&gt;\)</span></p>
<p>Assuming common initial state and rearranging:</p>
<p><span class="arithmatex">\(&lt;math&gt;&lt;mstyle displaystyle="true" scriptlevel="0"&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/math&gt;\)</span></p>
<p>Let <span class="arithmatex">\(&lt;math id="inf26"&gt;&lt;mstyle displaystyle="true" scriptlevel="0"&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/math&gt;\)</span> and <span class="arithmatex">\(&lt;math id="inf27"&gt;&lt;mstyle displaystyle="true" scriptlevel="0"&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;munderover&gt;&lt;mo movablelimits="false"&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/math&gt;\)</span> (<a href="https://elifesciences.org/articles/31134/figures#fig6s1">Figure 6—figure supplement 1</a>). Then,</p>
<p><span class="arithmatex">\(&lt;math&gt;&lt;mstyle displaystyle="true" scriptlevel="0"&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/math&gt;\)</span></p>
<p>(5) <span class="arithmatex">\(&lt;math&gt;&lt;mstyle displaystyle="true" scriptlevel="0"&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/math&gt;\)</span></p>
<p>where the first (<span class="arithmatex">\(&lt;math id="inf28"&gt;&lt;mstyle displaystyle="true" scriptlevel="0"&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/math&gt;\)</span>) and second (<span class="arithmatex">\(&lt;math id="inf29"&gt;&lt;mstyle displaystyle="true" scriptlevel="0"&gt;&lt;mrow&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/math&gt;\)</span>) terms denote the squared distance in recurrent subspace and input subspace, respectively. The third term (<span class="arithmatex">\(&lt;math id="inf30"&gt;&lt;mstyle displaystyle="true" scriptlevel="0"&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mover&gt;&lt;mrow&gt;&lt;mi mathvariant="normal"&gt;Δ&lt;/mi&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mo accent="false"&gt;¯&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/math&gt;\)</span>) is based on the interaction between the two subspaces: If the recurrent and input subspaces are orthogonal to each other, then this term will be zero; otherwise, it indicates whether the deviations in the recurrent subspace serve to amplify or suppress the spectral noise.</p>
<p>In <a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a> and <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplements 1</a>–<a href="https://elifesciences.org/articles/31134/figures#fig8s2">2</a>, all test simulations were performed with a common initial state. The linear speed of the trajectory in neural phase space, and in its input and recurrent subspaces, were calculated as the time-averaged magnitude, or L2-norm, of the instantaneous change in network state (<span class="arithmatex">\(&lt;math id="inf31"&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mfenced separators="|"&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/math&gt;\)</span>), and its input and recurrent subspaces projections, respectively (<a href="https://elifesciences.org/articles/31134#equ7">Equation 4</a>). Similarly, the total distance traversed in each subspace was calculated as the sum of the magnitude of instantaneous change in network state in the respective subspace, over the duration of the warped utterance.</p>
<h3 id="analysis-of-parallel-trajectories">Analysis of parallel trajectories<a class="headerlink" href="#analysis-of-parallel-trajectories" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-9">Request a detailed protocol</a></p>
<p>In <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplements 1</a>–<a href="https://elifesciences.org/articles/31134/figures#fig8s2">2</a>, we present evidence in support of parallel trajectories produced by the network dynamics in response to warped utterances. For each digit, the trajectories were first temporally aligned to the 100% (1x) warp, by matching the time indices of the respective warped utterances to the 100% reference. The following procedure was then independently applied to the temporally aligned recurrent and input subspace trajectories. One separation vector, <strong>S0.7x</strong>(taligned) (<strong>S1.4x</strong>(taligned)), was calculated at each aligned time point of the trajectory at the fast 0.7x (slow 1.4x) warp, as the difference between the population state (<span class="arithmatex">\(&lt;math id="inf32"&gt;&lt;mi mathvariant="bold-italic"&gt;x&lt;/mi&gt;&lt;/math&gt;\)</span>) of the 0.7x (1.4x) warp and 1x warp trajectories. The separation vectors were then normalized to unit length, denoted as <strong>S0.7x</strong>norm(taligned) (<strong>S1.4x</strong>norm(taligned)). Finally, the projected separations at each fast (slow) warp were generated by calculating the respective separation vectors and projecting them onto the normalized separation vectors of the 0.7x (1.4x) warp trajectory. For example, projected separations at the 0.5x warp, PS0.5x(taligned), were generated by projecting the separation vectors for the 0.5x warp trajectory, onto <strong>S0.7x</strong>norm(taligned), to give PS0.5x(taligned)=<strong>S0.5x</strong>(taligned).<strong>S0.7x</strong>norm(taligned). The variance explained by these projections was calculated as the ratio between the total population variance of the projected and overall separation.</p>
<h3 id="trajectory-visualization">Trajectory visualization<a class="headerlink" href="#trajectory-visualization" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-10">Request a detailed protocol</a></p>
<p>For <a href="https://elifesciences.org/articles/31134#fig3">Figure 3</a>, PCA was performed on a concatenation of the trajectories generated by both the reservoir and the trained network in response to all utterances of the digits ‘six’ and ‘eight’ by a single subject. Trajectories were then individually projected onto three principal components (PCs) and plotted in 3D. The sensory (motor) trajectories were projected onto PCs 2–4 (PCs 1–3). PC one was not used in plotting the sensory trajectories, because it captured features common to both spoken digits. Similarly, in <a href="https://elifesciences.org/articles/31134#fig6">Figure 6</a>, PCA was performed on a concatenation of the external inputs for the template utterance of digit zero, a natural test utterance of digit zero by the same subject, and one artificial test utterance each (shuffled and orthogonal noise) derived from these utterances. The external inputs were then projected on the first three PCs and plotted in 3D. In <a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a>, PCA was performed on concatenations of temporally-aligned 100 ms segments (i.e. segments aligned to 200–300 ms of the 1x warp) of the external input for digit one at warps of 0.57x, 0.7x, 0.87x, 1x, 1.15x, 1.4x and 1.74x. The external input segments where then projected onto the first three PCs and plotted in 3D. The same procedure was followed in plotting the PCA projections of population state responses in <a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a>, and of the recurrent and input subspace population state in <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplements 1</a>–<a href="https://elifesciences.org/articles/31134/figures#fig8s2">2</a>.</p>
<h3 id="source-code">Source code<a class="headerlink" href="#source-code" title="Permanent link">&para;</a></h3>
<p><a href="https://bio-protocol.org/eLIFErap31134?item=s4-11">Request a detailed protocol</a></p>
<p>Code for the simulation and training of the RNN model, cochleogram data and a set of trained weight matrices are available at <a href="https://github.com/vgoudar/SensoriMotorTranscription">https://github.com/vgoudar/SensoriMotorTranscription</a> (<a href="https://elifesciences.org/articles/31134#bib17">Goudar and Buonomano, 2018</a>). A copy is archived at <a href="https://github.com/elifesciences-publications/SensoriMotorTranscription">https://github.com/elifesciences-publications/SensoriMotorTranscription</a>.</p>
<p>[</p>
<h2 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h2>
<p>](https://elifesciences.org/articles/31134#)</p>
<ol>
<li>
<p>Conference</p>
<ol>
<li><a href="https://scholar.google.com/scholar?q=%22author:Lyon+RF%22">Lyon RF</a></li>
</ol>
<p>(1982)</p>
<p>A Computational Model of Filtering, Detection, and Compression in the Cochlea</p>
<p>Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP. pp. 1282–1285.</p>
<ul>
<li><a href="https://scholar.google.com/scholar_lookup?title=A+Computational+Model+of+Filtering%2C+Detection%2C+and+Compression+in+the+Cochlea&amp;conference=Acoustics%2C+Speech%2C+and+Signal+Processing%2C+IEEE+International+Conference+on+ICASSP&amp;author=Lyon+RF&amp;publication_year=1982&amp;pages=pp.+1282%E2%80%931285">Google Scholar</a></li>
</ul>
</li>
</ol>
<p>[</p>
<h2 id="decision-letter">Decision letter<a class="headerlink" href="#decision-letter" title="Permanent link">&para;</a></h2>
<p>](https://elifesciences.org/articles/31134#)</p>
<p>Thank you for submitting your article "Encoding Sensory and Motor Patterns as Time-Invariant Trajectories in Recurrent Neural Networks" for consideration by <em>eLife</em>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Richard Ivry as the Senior Editor. The reviewers have opted to remain anonymous.</p>
<p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p>
<p>This manuscript reports a computational study in which a recurrent neural network was trained to categorize spatio-temporal input stimuli and produce spatio-temporal patterns as responses. More specifically, the study used spoken digits as input stimuli, and transcriptions of these digits as outputs. The authors show that the trained network is robust to variations in the inputs and to external perturbations. In particular, they show that the network generalizes to untrained utterances of digits, and when trained on utterances of different length is able to deal with temporal stretching and compression of the stimuli. These results are interpreted in terms of stimulus-elicited neural trajectories, which show a degree of temporal invariance.</p>
<p>The paper is clearly a well-described, well-thought out computational experiment in artificial recurrent neural networks. However, all reviewers felt that its biological conclusions remain unclear. On a computational level, we know from much work in machine learning, where the task that the authors consider would be called a sequence-to-sequence task, that recurrent neural networks are indeed able to instantiate such computations (e.g., Sutskever et al., 2014). We also know, as the authors themselves report, that alternative mechanisms for dealing with time warping exist.</p>
<p>Accordingly, just the fact that the trained networks could solve the task is not in and of itself a strong biological finding. There are three ways the reviewers feel the paper could be improved, in order of importance:</p>
<p>1) What is the novel biological insight offered by the study? At present there is little detail on this. One prediction appears in the text: "Specifically, the observation that slower stimuli yield trajectories with larger curvature radii implies that the neural population activity should exhibit larger fluctuations in their firing rates in response to slower stimuli". However, in order for that to be a true prediction one would need to show that this is a necessary, or at least generic property, for instance by studying multiple different types of tasks involving temporal warping, or showing somehow that without this increase in curvature radius the trajectories cannot be learned. Moreover, the effect size for this prediction shown in <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplement 1D</a> appears quite mild (25% increase in range across the full span of warping). both generally and at the mechanistic level.</p>
<p>2) What is the extent and nature of the generalization that these networks are capable of. The authors demonstrate some interpolation and extrapolation of time-warping as well as an ability to reject certain kinds of noise. A stronger test might be for instance whether a network given a training set with naturally spoken examples all time-warped to the same duration, would still be able to generalize to stimuli of different durations?</p>
<p>3) How generic are the results? Is this approach different from previous generic deep learning results? Can the authors describe better the underlying mechanism, Can they convincingly say for instance that the mechanism that they describe in <a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a> for example is typical, or necessary? That it would remain the same given different choices about training paradigms, etc.</p>
<p>We realize that these are difficult points to address (especially point three). We feel these will be the best ways to strengthen the biological conclusions of the paper, even if a completely full answer cannot be achieved.</p>
<p>To help you in addressing these three main concerns, please find below more detailed reviewer remarks, culled from the original review. Please don't feel you have to address each of these as separate points, I add them here to help you understand in more detail the three main points to be addressed which we listed above.</p>
<p>Major concerns:</p>
<p>1) The network was trained in two steps in which the recurrent weights were trained and then the output weights were trained. I understand the rationale as it is stated in the main text. My question is whether this two-step training is necessary. In a biological case, the network would likely not be trained in such a way. Training would happen presumably all at once based only on the correctness of the output. It would be interesting to show how the network performs when the recurrent and output weights are trained simultaneously. What are the main differences in functionality the network can achieve? Also, a little more text on the rationale for the training procedure would be helpful to reader in the main text.</p>
<p>2) One of the main novelties of the paper is the temporal invariance of the network. The authors state that other models have been developed that can also account for temporal invariance. However, these other models are not fully introduced, forcing the reader to go to the literature to make a comparison. It would be helpful if the text contained a longer introduction to other models and a discussion of how, in functional terms and experimental predictions, the new model presented here compares to and differs from the published models cited in the text.</p>
<p>3) The paper emphasizes the idea of generalizing to different speeds of stimuli. The current results show that when trained on stimuli of different durations, generalization can occur. However, it is unclear if this generalization is a natural consequence of encoding stimuli as trajectories or requires training on different durations. That is, if the network is given a training set with naturally spoken examples all time-warped to the same duration, would the network be able to generalize to stimuli of different durations? The answer to this question helps the reader better understand the scope of the generalization that can occur.</p>
<p>4) How does the performance of the network differ for things like generalization, robustness to noise, etc. as a function of the size of the network? Different figures seem to use different size networks (n = 2100 in <a href="https://elifesciences.org/articles/31134#fig3">Figure 3 and n</a> = 4000 in <a href="https://elifesciences.org/articles/31134#fig1">Figure 1</a>), but it was not immediately clear how the network size was chosen.</p>
<p>5) One weakness of the paper is that the extent of mechanistic exploration of the RNN and experimental predictions is rather limited, at least in my opinion. I do not have specific suggestions for how to improve on this point. One possibility is further examination of the recurrent weight matrix to look for specific structure and dynamics that could generate additional experimental predictions. Given that I do not have specific questions here, I do not expect that something must be done in this area. I simply note this point because the impact of the paper will be enhanced if more mechanistic insight into how the RNN functions or into experimental predictions could be added.</p>
<p>6) The relation between this work and the substantial progress in deep learning on general sequence-to-sequence tasks (for example, "Sequence to sequence learning with neural networks" by Sutskever et al., 2014 and the dozens of subsequent papers that built upon it) is unclear. Most of these works in deep learning use backpropagation through time (BPTT) to train their networks, an algorithm which is conceptually very distinct from their tamed chaos method. Given the excellent track record of BPTT on many real-world sequence-to-sequence tasks, it seems that the point that the brain can use recurrent dynamics to solve such tasks is already evident. Perhaps the authors feel their approach is more appropriate in some way? If so, it would be important to compare the performance of the tamed chaos method with that of BPTT on more complex tasks and understand the relative advantages and shortcomings between them (for example, is there a task that one method can easily achieve but the other can't? Or is there some feature of the dynamics/networks that are learnt that appears more reasonable for one than the other). Moreover, given these two largely distinct methods to train RNNs, an important question that needs to be addressed is how the mechanisms by which generalization occurs in each method differ from each other. In other words, it is not clear which aspects of the mechanisms they identified in this paper are unique to the tamed chaos method or common to more general classes of algorithms to train RNNs. This paper provides a rather detailed analysis of how their particular training method enables generalization, but, for their analysis to be more useful in understanding how the RNNs in the brain operate, showing that this is a general mechanism in RNNs would be desired.</p>
<p>7) It was unclear how to interpret the fact that the motor-only-training networks were also robust to temporal warping (<a href="https://elifesciences.org/articles/31134#fig7">Figure 7C</a>). In fact, for time warping that is in between trained values, the interpolation regime, as the authors call it the motor-only-training networks were at 100% performance and one of the papers the authors cite (Lerner et al., 2014) shows that there is temporal scaling in human hemodynamic imaging mainly in the behavioral range, that is in the interpolation range. Given the chaotic nature of the networks pre-training wouldn't motor-trained-only networks have initial conditions that are almost as different for within digit than between digit? If this is true and the networks can still learn to be at 100% wouldn't that imply that the sensory training is in some sense redundant? I see the greater separation in <a href="https://elifesciences.org/articles/31134#fig7">Figure 7B</a> but it is hard to evaluate whether the extra separation is important or overkill.</p>
<p>8) In general the treatment of temporal warping somewhat confusing. The text is written as if the solution to a time warped input is necessarily to generate the same trajectory running at a different speed. This doesn't have to be the case, in general all that is needed is that whatever dynamics happen, at the transition between the sensory and motor phases the within digit distance (including time warps, different utterances, etc.) be smaller than the between digit distance. The easiest way for this to be achieved is to arrive at the exact same point for different time warps. However, this is not necessary, nor is it what the network actually ends up doing (<a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a>). It was therefore very difficult for me to interpret the significance of <a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a>, that the network arrives at a mid-way solution between constant speed and constant distance. Is there something particularly interesting about this midpoint? Is there a reason it arrived at this compromise between these two possible mechanisms? Is it influenced by the way the authors generate the target trajectories by scaling?</p>
<p>9) The authors make one main biological prediction: "Specifically, the observation that slower stimuli yield trajectories with larger curvature radii implies that the neural population activity should exhibit larger fluctuations in their firing rates in response to slower stimuli". However, in order for that to be a true prediction at least in my mind one would need to show that this is a necessary, or at least generic property, for instance by studying multiple different types of tasks involving temporal warping, or showing somehow that without this increase in curvature radius the trajectories cannot be learned. Moreover, the effect size for this prediction shown in <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplement 1D</a> appears quite mild (25% increase in range across the full span of warping).</p>
<p>10) Focusing on a specific set of realistic, complex stimuli and outputs is certainly a clear proof of concept of the task. Yet, the shortcoming of such an approach is that it is not immediately clear which part of the reported results are to some extent general, and what is in contrast specific to the particular implementation of the trained network (which relies on a very specific training procedure, and no doubt involves some fine-tuning). I guess what I am missing is a simplified, computational description of the underlying mechanism. Right now, I am left wondering how much details matter, and what happens when some details are changed. For instance, it seems that the specific implementation used in the paper requires that the motor action starts at a fixed time after the stimulus, and that it could not easily accommodate a variable delay between the stimulus and the motor output (e.g. specified by a go cue). Providing a simplified computational description of the mechanism, and examples of extensions/limitations would greatly improve the paper.</p>
<div class="arithmatex">\[Editors' note: further revisions were requested prior to acceptance, as described below.\]</div>
<p>Thank you for submitting a revision of your article "Encoding Sensory and Motor Patterns as Time-Invariant Trajectories in Recurrent Neural Networks" for consideration by <em>eLife</em>.</p>
<p>We found the manuscript improved. In particular, the inclusion of the back propagation trained network results that came up with a similar regime to the intrinsic trajectory training was informative and useful.</p>
<p>However, this addition does not fully address the three summary issues raised in the original decision letter. We recognize that these are very difficult to address, and hence a complete answer may not be possible. However, we think it would be appropriate to be more explicit about the limitations of the current work/approach. As one reviewer noted, the current manuscript presents the problems as more solved than warranted and thought it would be useful to note issues that remain relatively unsolved. Your response letter takes more of an approach along these lines than the Discussion section in the revision. For example, in the biological predictions part, it would be helpful to cleanly separate previously known and relatively generic predictions, such as input driven suppression of variability and generalization being challenging, from those that are more specific to the model such as the larger curvature radii. We think this more tempered approach will make the paper more impactful, helping lay out some issues in need of future exploration</p>
<p><a href="https://doi.org/10.7554/eLife.31134.017">https://doi.org/10.7554/eLife.31134.017</a></p>
<p>[</p>
<h2 id="author-response">Author response<a class="headerlink" href="#author-response" title="Permanent link">&para;</a></h2>
<p>](https://elifesciences.org/articles/31134#)</p>
<blockquote>
<p>There are three ways the reviewers feel the paper could be improved, in order of importance:</p>
<p>1) What is the novel biological insight offered by the study? At present there is little detail on this. One prediction appears in the text: "Specifically, the observation that slower stimuli yield trajectories with larger curvature radii implies that the neural population activity should exhibit larger fluctuations in their firing rates in response to slower stimuli". However, in order for that to be a true prediction one would need to show that this is a necessary, or at least generic property, for instance by studying multiple different types of tasks involving temporal warping, or showing somehow that without this increase in curvature radius the trajectories cannot be learned. Moreover, the effect size for this prediction shown in <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplement 1D</a> appears quite mild (25% increase in range across the full span of warping). both generally and at the mechanistic level.</p>
</blockquote>
<p>It is of course critical for a computational study to generate, and clearly enunciate, predictions, and we have now clarified what we view as the three most important predictions in the Discussion. Specifically:</p>
<p>i) Neural trajectories will be stable in response to local perturbations—potentially administered through optogenetic stimulation—and importantly that the neural trajectories elicited during sensory stimuli will be more resistant to perturbations than the neural trajectories unfolding during the motor epoch of sensory-motor tasks.</p>
<p>ii) Slower stimuli yield trajectories with larger curvature radii, implying that the neural population activity should exhibit larger fluctuations in their firing rates in response to slower stimuli.</p>
<p>iii) Trained networks fail at generalizing to unfamiliar spectral noise patterns, thereby predicting that trajectories in sensory areas will diverge more when presented with stimuli composed of artificial or unfamiliar spectral noise patterns. This prediction could be tested, for example, by training an animal to recognize sounds with noise injected on some principal components of the stimulus spectrogram but not others, and then tested on noise injected along the held-out PC dimensions.</p>
<p>We should clarify that the model does not predict that “without an increase in curvature radius the trajectories cannot be learned”. But rather that temporally invariant encoding of sensory patterns is a result of temporally scaled neural trajectories, wherein the change in the trajectory curvatures radius underlying this temporal scaling is significantly above zero (variable speed/constant distance) and below the warp factor of the sensory pattern (constant speed/variable distance). The reviewer correctly noticed that <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplement 1</a> predicts a change in firing rate of approximately 25% across the range of warps tested. This is because we predict that temporal scaling is a result of both a change in curvature and a change in linear speed (<a href="https://elifesciences.org/articles/31134#fig8">Figure 8A</a>), and therefore the expected change in the curvature radius (and consequently the firing rate range) should be less than the warp factor. While the magnitude of the change, may indeed make this prediction harder to test, detecting changes in firing rates of 25% is well within the range of experimental studies. For example the effects of attention on firing rate generally fall, on average, within this range (Gregoriou et al., 2014; Maunsell and Treue, 2006).</p>
<blockquote>
<p>2) What is the extent and nature of the generalization that these networks are capable of. The authors demonstrate some interpolation and extrapolation of time-warping as well as an ability to reject certain kinds of noise. A stronger test might be for instance whether a network given a training set with naturally spoken examples all time-warped to the same duration, would still be able to generalize to stimuli of different durations?</p>
</blockquote>
<p>This is an important question that is partially addressed in point RC7 (see below) and in the motorepoch only training shown in <a href="https://elifesciences.org/articles/31134#fig7">Figure 7C</a>. Specifically, a strength of the RNN approach is that encoding spatiotemporal stimuli in continuous neural trajectories endows it with some intrinsic sensory temporal invariance. Thus, training the network on utterances of the same duration results in good temporal scaling (similar to the M-trained RNN in <a href="https://elifesciences.org/articles/31134#fig7">Figure 7C</a>, see also the Reservoir control <a href="https://elifesciences.org/articles/31134#fig8">Figure 8D</a>). However, it remains the case that training across different durations significantly improves interpolation and extrapolation (as shown in <a href="https://elifesciences.org/articles/31134#fig7">Figure 7B-C</a>). We have now expanded our discussion of the ability of RNNs to exhibit intrinsic temporal scaling.</p>
<blockquote>
<p>3) How generic are the results? Is this approach different from previous generic deep learning results? Can the authors describe better the underlying mechanism, Can they convincingly say for instance that the mechanism that they describe in <a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a> for example is typical, or necessary? That it would remain the same given different choices about training paradigms, etc.</p>
</blockquote>
<p>This point, raised in more detail under point RC6 below, relates to determining whether our results and predictions are general or specific to the learning rule we used. To test whether our results depend on the “innate” learning framework, we trained a recurrent network, similar to the ones used in our study, on the sensorimotor task with backpropagation through time (BPTT) applied via ADAM optimization (Kingma and Ba, 2014), a common training approach in the deep learning literature. Training and testing the network with temporally warped utterances (as in <a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a> and <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplement 1</a>) yielded qualitatively similar results. Specifically, temporal scaling was observed across a wide range of speeds, however, performance was weaker than that of our innate training approach (compare <a href="https://elifesciences.org/articles/31134/figures#fig8s2">Figure 8—figure supplement 2</a> with <a href="https://elifesciences.org/articles/31134#fig7">Figure 7</a>). As stressed in RC6 below, this result strengthens our prediction relating to the mechanisms underlying temporal scaling.</p>
<p>Regarding the comparison with standard deep-learning approaches we would argue that there are there are fundamental differences. Specifically, standard deep-learning approaches generally do not operate in continuous time nor address the issue of dynamic/transient attractors and chaos. For example, the seminal 2014 paper by Sutskever et al. dealt with translation of sentences from one language to another, the inputs in their case were not auditory and time is non-continuous— as a result, temporal invariance was not addressed in their work. But deep learning has, of course, been extensively applied to the domain of artificial speech recognition (Chan et al., 2016; Graves et al., 2006), either using standard feedforward CNN networks or RNNs. However, the RNN models have focused primarily on LSTM networks, and thus their architecture is farther removed from biological realism:</p>
<p>* LSTM units possess state-dependent input and output gates, effectively yielding statedependent, time-varying and arbitrary effective time-constants per cell. As a result, temporal scaling within these models may result from LSTM gating dynamics, wherein the effective time-constants of the cells are warp-dependent. However, to the best of our knowledge, neurons or neural populations with this state-dependent and time-varying time constants have not been experimentally observed.</p>
<p>* Deep learning models often enlist bidirectional LSTMs to allow for current inputs to be processed in light of past <em>and future</em> context. While this serves to improve efficiency, it is certainly not biologically plausible.</p>
<blockquote>
<p>Major concerns:</p>
<p>1) The network was trained in two steps in which the recurrent weights were trained and then the output weights were trained. I understand the rationale as it is stated in the main text. My question is whether this two-step training is necessary. In a biological case, the network would likely not be trained in such a way. Training would happen presumably all at once based only on the correctness of the output. It would be interesting to show how the network performs when the recurrent and output weights are trained simultaneously. What are the main differences in functionality the network can achieve? Also, a little more text on the rationale for the training procedure would be helpful to reader in the main text.</p>
</blockquote>
<p>This is a good question, although it is not clear if separate stages of training in sensory-motor tasks should be considered less biological. For example, in sensory-motor learning in the song bird, there are clear distinctions between learning of the sensory component (the template) and motor learning—indeed the same is probably true in speech (Doupe and Kuhl, 1999). Nevertheless, it is not the case that learning has to be performed in two steps. Indeed one could interpret our training framework as having parallel plasticity, with learning rates of the recurrent weights being much larger than that of the output weights. Furthermore, we now establish that end-to-end training of the network with BPTT does not alter the mechanism underlying temporal invariance. We have now added text elaborating on this point.</p>
<blockquote>
<p>2) One of the main novelties of the paper is the temporal invariance of the network. The authors state that other models have been developed that can also account for temporal invariance. However, these other models are not fully introduced, forcing the reader to go to the literature to make a comparison. It would be helpful if the text contained a longer introduction to other models and a discussion of how, in functional terms and experimental predictions, the new model presented here compares to and differs from the published models cited in the text.</p>
</blockquote>
<p>We thank the reviewer for this suggestion. We have now updated the Discussion section with a more detailed descriptions of other models. Specifically, the main other biologically realistic model for temporally invariant processing of sensory patterns proposes synaptic shunting as a mechanism that amounts to a modulation of the time constants of the neurons by the warped input—in other words it is more akin to a cellular mechanism than a network mechanism (Gutig and Sompolinsky, 2009).</p>
<blockquote>
<p>3) The paper emphasizes the idea of generalizing to different speeds of stimuli. The current results show that when trained on stimuli of different durations, generalization can occur. However, it is unclear if this generalization is a natural consequence of encoding stimuli as trajectories or requires training on different durations. That is, if the network is given a training set with naturally spoken examples all time-warped to the same duration, would the network be able to generalize to stimuli of different durations? The answer to this question helps the reader better understand the scope of the generalization that can occur.</p>
</blockquote>
<p>Please see response #2 above.</p>
<blockquote>
<p>4) How does the performance of the network differ for things like generalization, robustness to noise, etc. as a function of the size of the network? Different figures seem to use different size networks (n = 2100 in <a href="https://elifesciences.org/articles/31134#fig3">Figure 3 and n</a> = 4000 in <a href="https://elifesciences.org/articles/31134#fig1">Figure 1</a>), but it was not immediately clear how the network size was chosen.</p>
</blockquote>
<p>The size of the network certainly affects its capacity, particularly for generalization. The reason for using a larger network in <a href="https://elifesciences.org/articles/31134#fig1">Figure 1</a> was to address cross-speaker generalization. The smaller network size used in the other figures was not as effective when trained and tested across speakers. We now explain this in Materials and methods section of the paper.</p>
<blockquote>
<p>5) One weakness of the paper is that the extent of mechanistic exploration of the RNN and experimental predictions is rather limited, at least in my opinion. I do not have specific suggestions for how to improve on this point. One possibility is further examination of the recurrent weight matrix to look for specific structure and dynamics that could generate additional experimental predictions. Given that I do not have specific questions here, I do not expect that something must be done in this area. I simply note this point because the impact of the paper will be enhanced if more mechanistic insight into how the RNN functions or into experimental predictions could be added.</p>
</blockquote>
<p>We share the reviewer’s feelings here, and we think the point reflects the deeper question of what it means to “understand” an RNN. Indeed, this was a concern raised in the first review, and we believe the mechanistic analyses including the decomposition analysis that was added to the first revision is a strong approach—but admittedly the field as a whole must address the larger issue at stake.</p>
<blockquote>
<p>6) The relation between this work and the substantial progress in deep learning on general sequence-to-sequence tasks (for example, "Sequence to sequence learning with neural networks" by Sutskever et al., 2014 and the dozens of subsequent papers that built upon it) is unclear. Most of these works in deep learning use backpropagation through time (BPTT) to train their networks, an algorithm which is conceptually very distinct from their tamed chaos method. Given the excellent track record of BPTT on many real-world sequence-to-sequence tasks, it seems that the point that the brain can use recurrent dynamics to solve such tasks is already evident. Perhaps the authors feel their approach is more appropriate in some way? If so, it would be important to compare the performance of the tamed chaos method with that of BPTT on more complex tasks and understand the relative advantages and shortcomings between them (for example, is there a task that one method can easily achieve but the other can't? Or is there some feature of the dynamics/networks that are learnt that appears more reasonable for one than the other). Moreover, given these two largely distinct methods to train RNNs, an important question that needs to be addressed is how the mechanisms by which generalization occurs in each method differ from each other. In other words, it is not clear which aspects of the mechanisms they identified in this paper are unique to the tamed chaos method or common to more general classes of algorithms to train RNNs. This paper provides a rather detailed analysis of how their particular training method enables generalization, but, for their analysis to be more useful in understanding how the RNNs in the brain operate, showing that this is a general mechanism in RNNs would be desired.</p>
</blockquote>
<p>This is a very important point. As mentioned above (Summary point #3), the differences between the two techniques are more than just the training rule. Specifically, in regard to the treatment of time. E.g., in Sutskever <em>et al. 2014,</em> time is not explicitly present, and in many of the other models the temporal structure of the input is “spatialized” (i.e., at time step t discrete time step inputs from t-n, t-n-1, …, t, are presented to the network)—and thus does not capture how the brain represents time. Nevertheless to address the reviewers question we have now trained our network using a version of BPTT. Under some conditions (random orthogonal initialization of weight matrices with a high gain) BPTT resulted in good temporal scaling via similar mechanisms (temporal scaling of neural trajectories by changes in curvature radius)—but overall performance, as measured by CNN “handwritten” classification, was inferior. These results establish that the same solution was arrived at using different training methods, implying that our predictions are fairly general (even if some rules result in better performance than others). This result is consistent with our stance that these models are meant to capture computational principles of biological of recurrent neural networks, but the learning rules by which biological circuits reach these regimes remain to be elucidated.</p>
<p>These results are presented in <a href="https://elifesciences.org/articles/31134/figures#fig8s2">Figure 8—figure supplement 2</a>.</p>
<blockquote>
<p>7) It was unclear how to interpret the fact that the motor-only-training networks were also robust to temporal warping (<a href="https://elifesciences.org/articles/31134#fig7">Figure 7C</a>). In fact, for time warping that is in between trained values, the interpolation regime, as the authors call it the motor-only-training networks were at 100% performance and one of the papers the authors cite (Lerner et al. 2014) shows that there is temporal scaling in human hemodynamic imaging mainly in the behavioral range, that is in the interpolation range. Given the chaotic nature of the networks pre-training wouldn't motor-trained-only networks have initial conditions that are almost as different for within digit than between digit? If this is true and the networks can still learn to be at 100% wouldn't that imply that the sensory training is in some sense redundant? I see the greater separation in <a href="https://elifesciences.org/articles/31134#fig7">Figure 7B</a> but it is hard to evaluate whether the extra separation is important or overkill.</p>
</blockquote>
<p>The network is initialized to a chaotic state which means it is chaotic in the absence of any external input, but as has been described, an external input can suppress this chaotic activity (Rajan et al., 2010). A nice feature of our RNN approach is that it does show some degree of intrinsic temporal scaling because the external input can partially “clamp” the internal dynamics (of course, sensory-epoch training leads to substantial performance improvements in terms of generalization to spectral noise and to different speakers (<a href="https://elifesciences.org/articles/31134#fig1">Figure 1C</a>) as well as improved temporal scaling (<a href="https://elifesciences.org/articles/31134#fig7">Figure 7</a>)). This was discussed in the Results (<em>Stability of the Neural Trajectories</em>), and we now expand upon it in the Discussion section.</p>
<blockquote>
<p>8) In general the treatment of temporal warping somewhat confusing. The text is written as if the solution to a time warped input is necessarily to generate the same trajectory running at a different speed. This doesn't have to be the case, in general all that is needed is that whatever dynamics happen, at the transition between the sensory and motor phases the within digit distance (including time warps, different utterances, etc.) be smaller than the between digit distance. The easiest way for this to be achieved is to arrive at the exact same point for different time warps. However, this is not necessary, nor is it what the network actually ends up doing (<a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a>). It was therefore very difficult for me to interpret the significance of <a href="https://elifesciences.org/articles/31134#fig8">Figure 8</a>, that the network arrives at a mid-way solution between constant speed and constant distance. Is there something particularly interesting about this midpoint? Is there a reason it arrived at this compromise between these two possible mechanisms? Is it influenced by the way the authors generate the target trajectories by scaling?</p>
</blockquote>
<p>This is a fascinating question regarding the nature of the network’s dynamics. The reviewer is certainly correct that other solutions could be used during the sensory-epoch. But it is more complicated than requiring that “at the transition between the sensory and motor phases the within digit distance (including time warps, different utterances, etc.) be smaller than the between digit distance”. Specifically, there is an interaction between this distance and the basin of attraction of the motor dynamic attractor: it is possible that at the end of the sensory epoch, despite being closer to the other within-digit trajectories, a trajectory may not end up within the basin of attraction of the corresponding digit’s motor dynamic attractor. Good performance will depend on the relationship between the size of this basin and the within digit-distance at the end of the sensory epoch. In other words, the size of the basin of attraction poses a stronger constraint on the withindigit distance. Since both of these characteristics of the network’s dynamics are affected by training, it appears that the network finds the best tradeoff. We now further highlight this interaction.</p>
<blockquote>
<p>9) The authors make one main biological prediction: "Specifically, the observation that slower stimuli yield trajectories with larger curvature radii implies that the neural population activity should exhibit larger fluctuations in their firing rates in response to slower stimuli". However, in order for that to be a true prediction at least in my mind one would need to show that this is a necessary, or at least generic property, for instance by studying multiple different types of tasks involving temporal warping, or showing somehow that without this increase in curvature radius the trajectories cannot be learned. Moreover, the effect size for this prediction shown in <a href="https://elifesciences.org/articles/31134/figures#fig8s1">Figure 8—figure supplement 1D</a> appears quite mild (25% increase in range across the full span of warping).</p>
</blockquote>
<p>Please see the response to Summary point #1.</p>
<blockquote>
<p>10) Focusing on a specific set of realistic, complex stimuli and outputs is certainly a clear proof of concept of the task. Yet, the shortcoming of such an approach is that it is not immediately clear which part of the reported results are to some extent general, and what is in contrast specific to the particular implementation of the trained network (which relies on a very specific training procedure, and no doubt involves some fine-tuning). I guess what I am missing is a simplified, computational description of the underlying mechanism. Right now, I am left wondering how much details matter, and what happens when some details are changed. For instance, it seems that the specific implementation used in the paper requires that the motor action starts at a fixed time after the stimulus, and that it could not easily accommodate a variable delay between the stimulus and the motor output (e.g. specified by a go cue). Providing a simplified computational description of the mechanism, and examples of extensions/limitations would greatly improve the paper.</p>
</blockquote>
<p>We thank the reviewer for this comment. The addition of a model using a different learning rule addresses, to some degree, the question of generality (<a href="https://elifesciences.org/articles/31134/figures#fig8s2">Figure 8—figure supplement 2</a>). But the reviewer is correct that in its current implementation the model does not adapt well to a variable sensory-motor delay. Arguably, in biological systems such delayed output invokes additional working memory dynamics, which could be incorporated by training the network to converge to a fixed-point attractor before the go signal. Regarding the presentation of a reduced model, this is something we have struggled with. Specifically, it is challenging to present a reduced model of something that we view as a truly emergent phenomenon (indeed, emergent phenomena can be defined as those that are not easily reducible). Thus, this relates to point RC5: what does it mean to understand the computations that emerge from a RNN. In our view many of the complex computations the brain performs are indeed emergent phenomena, and as such the field will need to address the question of how to study, perturb, establish causality, and understand these networks. Hopefully, this paper takes an initial step in this direction, by highlighting the challenge, showing that RNNs can solve complex sensori-motor tasks, and offering a tool to understand these dynamics (the RNN decomposition).</p>
<div class="arithmatex">\[Editors' note: further revisions were requested prior to acceptance, as described below.\]</div>
<blockquote>
<p>Thank you for submitting a revision of your article "Encoding Sensory and Motor Patterns as Time-Invariant Trajectories in Recurrent Neural Networks" for consideration by eLife.</p>
<p>We found the manuscript improved. In particular, the inclusion of the back propagation trained network results that came up with a similar regime to the intrinsic trajectory training was informative and useful.</p>
<p>However, this addition does not fully address the three summary issues raised in the original decision letter. We recognize that these are very difficult to address, and hence a complete answer may not be possible. However, we think it would be appropriate to be more explicit about the limitations of the current work/approach. As one reviewer noted, the current manuscript presents the problems as more solved than warranted and thought it would be useful to note issues that remain relatively unsolved. Your response letter takes more of an approach along these lines than the Discussion section in the revision. For example, in the biological predictions part, it would be helpful to cleanly separate previously known and relatively generic predictions, such as input driven suppression of variability and generalization being challenging, from those that are more specific to the model such as the larger curvature radii. We think this more tempered approach will make the paper more impactful, helping lay out some issues in need of future exploration</p>
</blockquote>
<p>We thank the reviewers for their further feedback, and for raising the point pertaining to making explicit statements about the limitations of the model, and issues that remain unaddressed. We, of course, did not mean to imply in the text that questions relating to how recurrent neural networks perform sensorimotor computations are solved, and hopefully made that clear in the letter, if not in the Discussion section. We have now added an additional paragraph to the Discussion section about limitations and future directions (see below). Finally, we have also clarified the predictions of the model with the goal of helping the reader understand how specific they are likely to be to the current model.</p>
<p>“These experimental predictions are critical to validate the model’s implementation of complex and invariant sensorimotor computations as stable neural trajectories. However, even if validated a number questions remain to be addressed. Most notably, how can the recurrent synaptic strengths be tuned to develop stable trajectories in a biologically plausible manner? The learning rule used here, coupled with its requirement of an explicit target for each recurrent unit, make it biologically implausible. However, while it is important that the sensorimotor representations are encoded as locally stable trajectories, the structure of the target trajectories themselves are essentially arbitrary. It is therefore conceivable that arbitrary yet locally-stable encoding trajectories may emerge from unsupervised learning. A second related issue is that to achieve strong temporal invariance, our model had to be trained over a range of sensory stimuli speeds. Again, it is not clear if this would represent a biologically plausible scenario—to help address this question, it will be important for future research to determine if the ability to recognize stimuli independent of speed is learned through experience. Finally, questions relating to the learning capacity of networks capable of strong temporal invariance, and the expedience of sensory-epoch training for temporal invariance remain open.”</p>
<p><a href="https://doi.org/10.7554/eLife.31134.018">https://doi.org/10.7554/eLife.31134.018</a></p>
<p>[</p>
<h2 id="article-and-author-information">Article and author information<a class="headerlink" href="#article-and-author-information" title="Permanent link">&para;</a></h2>
<p>](https://elifesciences.org/articles/31134#)</p>
<h3 id="author-details">Author details<a class="headerlink" href="#author-details" title="Permanent link">&para;</a></h3>
<ol>
<li>
<h4 id="dean-v-buonomano">Dean V Buonomano<a class="headerlink" href="#dean-v-buonomano" title="Permanent link">&para;</a></h4>
<ol>
<li>Departments of Neurobiology, University of California, Los Angeles, Los Angeles, United States</li>
<li>Integrative Center for Learning and Memory, University of California, Los Angeles, Los Angeles, United States</li>
<li>Departments of Psychology, University of California, Los Angeles, Los Angeles, United States</li>
</ol>
<h5 id="contribution">Contribution<a class="headerlink" href="#contribution" title="Permanent link">&para;</a></h5>
<p>Conceptualization, Supervision, Funding acquisition, Writing—original draft, Writing—review and editing</p>
<h5 id="for-correspondence">For correspondence<a class="headerlink" href="#for-correspondence" title="Permanent link">&para;</a></h5>
<p><a href="mailto:dbuono@ucla.edu">dbuono@ucla.edu</a></p>
<h5 id="competing-interests">Competing interests<a class="headerlink" href="#competing-interests" title="Permanent link">&para;</a></h5>
<p>No competing interests declared</p>
<p><a href="https://orcid.org/0000-0002-8528-9231"><img alt="orcid.10f6112b.png" src="../Encoding%20sensory%20and%20motor%20patterns%20as%20time-invariant%20trajectories%20in%20recurrent%20neural%20networks/orcid.10f6112b.png" />"This ORCID iD identifies the author of this article:" 0000-0002-8528-9231</a></p>
</li>
</ol>
<h3 id="funding">Funding<a class="headerlink" href="#funding" title="Permanent link">&para;</a></h3>
<h4 id="national-science-foundation-nsf-iis-1420897">National Science Foundation (NSF IIS-1420897)<a class="headerlink" href="#national-science-foundation-nsf-iis-1420897" title="Permanent link">&para;</a></h4>
<ul>
<li>Dean V Buonomano</li>
</ul>
<h4 id="google-google-faculty-research-award">Google (Google Faculty Research Award)<a class="headerlink" href="#google-google-faculty-research-award" title="Permanent link">&para;</a></h4>
<ul>
<li>Dean V Buonomano</li>
</ul>
<h4 id="national-institutes-of-health-mh60163">National Institutes of Health (MH60163)<a class="headerlink" href="#national-institutes-of-health-mh60163" title="Permanent link">&para;</a></h4>
<ul>
<li>Dean V Buonomano</li>
</ul>
<p>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</p>
<h3 id="acknowledgements">Acknowledgements<a class="headerlink" href="#acknowledgements" title="Permanent link">&para;</a></h3>
<p>We thank Nicholas Hardy, Omri Barak, Sean Escola, Alexandre Rivkind and Jonathan Kadmon for helpful discussions, and Dharshan Kumaran for comments on an earlier version of this manuscript.</p>
<h3 id="reviewing-editor">Reviewing Editor<a class="headerlink" href="#reviewing-editor" title="Permanent link">&para;</a></h3>
<ol>
<li>Shaul Druckmann, Janelia Research Campus, Howard Hughes Medical Institute, United States</li>
</ol>
<h3 id="publication-history">Publication history<a class="headerlink" href="#publication-history" title="Permanent link">&para;</a></h3>
<ol>
<li>Received: August 10, 2017</li>
<li>Accepted: February 19, 2018</li>
<li>Version of Record published: <a href="https://elifesciences.org/articles/31134">March 14, 2018 (version 1)</a></li>
</ol>
<h3 id="copyright">Copyright<a class="headerlink" href="#copyright" title="Permanent link">&para;</a></h3>
<p>© 2018, Goudar et al.</p>
<p>This article is distributed under the terms of the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</a>, which permits unrestricted use and redistribution provided that the original author and source are credited.</p>
<p>[</p>
<h2 id="metrics">Metrics<a class="headerlink" href="#metrics" title="Permanent link">&para;</a></h2>
<p>](https://elifesciences.org/articles/31134#)</p>
<ul>
<li>
<p>3,714</p>
<p>Page views</p>
</li>
<li>
<p>517</p>
<p>Downloads</p>
</li>
<li>
<p>33</p>
<p>Citations</p>
</li>
</ul>
<p>Article citation count generated by polling the highest count across the following sources: <a href="https://doi.org/10.7554/eLife.31134">Crossref</a>, <a href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85045625175&amp;origin=inward">Scopus</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5851701/">PubMed Central</a>.</p>
<h2 id="download-links">Download links<a class="headerlink" href="#download-links" title="Permanent link">&para;</a></h2>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.51198bba.min.js"></script>
      
        <script src="../../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
      
    
  </body>
</html>
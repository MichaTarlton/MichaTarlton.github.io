---
aliases: [LSTM,Long Short Term Memory]
type:  topics
status: open
priority: p4
creationtag: 2022-06-13 16:09
infotags:
---
*[[Long Short-Term Memory (LSTM)]]* I think
> [18] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.
![[50 Reading/citations/@voelkerLegendreMemoryUnits2019.md#^msenuo]]
> Long short-memory (LSTM) and gated recurrent unit (GRU) are advanced designs to mitigate shortcomings of RNN. But when the length of input sequence exceeds a certain limit, the gradient will still disappear. Meanwhile, each LSTM cell have four full connection layers, if the time span of LSTM is large and the network is very deep, the calculation will be very heavy and time-consuming. Further, too many parameters will lead to over fitting risk.
- [[Sun 2020]]